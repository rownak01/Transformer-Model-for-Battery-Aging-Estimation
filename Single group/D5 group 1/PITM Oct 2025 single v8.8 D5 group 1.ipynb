{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be1b0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 1 GPU(s) active, memory growth enabled.\n",
      "‚úÖ File map generated: 3 files mapped to base groups.\n",
      "  Example lookup: PBROM_data_cell_D5C77.mat -> D5_Cells_1\n",
      "  Example lookup: PBROM_data_cell_D5C69.mat -> D5_Cells_1\n",
      "  Example lookup: PBROM_data_cell_D5C78.mat -> D5_Cells_1\n",
      "\n",
      "Verifying file availability (optional):\n",
      "[TRAIN] PBROM_data_cell_D5C77.mat: N=1200000\n",
      "[TRAIN] Found/loaded 1/1 files in 'PBROM data'\n",
      "[VAL] PBROM_data_cell_D5C69.mat: N=1200000\n",
      "[VAL] Found/loaded 1/1 files in 'PBROM data'\n",
      "[TEST] PBROM_data_cell_D5C78.mat: N=1200000\n",
      "[TEST] Found/loaded 1/1 files in 'PBROM data'\n",
      "\n",
      "‚úÖ Group ID map generated (1 total groups):\n",
      "  0: D5_Cells_1\n",
      "\n",
      "‚úÖ Cell 1 ready: imports, seeds, GPU setup, dirs, splits, loader.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ‚ö° GPU + XLA acceleration (added at top)\n",
    "# ==========================================\n",
    "import os\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=2\"   # Enable XLA fusion\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"             # suppress TF INFO/WARN\n",
    "os.environ[\"TF_CPP_MAX_VLOG_LEVEL\"] = \"0\"            # suppress verbose C++ logs\n",
    "\n",
    "import logging, absl.logging\n",
    "import tensorflow as tf\n",
    "\n",
    "# üîß Threading config MUST be set before TF runtime initializes\n",
    "tf.config.threading.set_inter_op_parallelism_threads(8)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(8)\n",
    "\n",
    "# Logging levels\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "# XLA JIT\n",
    "tf.config.optimizer.set_jit(True)                    # Just-In-Time compile\n",
    "\n",
    "# Enable full GPU memory and multi-GPU graph\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"‚úÖ {len(gpus)} GPU(s) active, memory growth enabled.\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è CPU mode.\")\n",
    "\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Cell 1 ‚Äî Setup & Splits\n",
    "# =========================\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  # 2=warnings+errors, 3=errors only\n",
    "os.environ[\"TF_NUM_INTEROP_THREADS\"] = \"1\"\n",
    "os.environ[\"TF_NUM_INTRAOP_THREADS\"] = \"1\"\n",
    "\n",
    "import json, random\n",
    "import numpy as np\n",
    "import h5py\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import logging\n",
    "import absl.logging\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "\n",
    "\n",
    "# --- Quiet TF a bit ---\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "# --- Reproducibility ---\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# # --- GPU: enable memory growth if present (safe no-op on CPU) ---\n",
    "# gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         for g in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(g, True)\n",
    "#         print(f\"‚úÖ GPUs: {len(gpus)} | Memory growth enabled\")\n",
    "#     except Exception as e:\n",
    "#         print(\"‚ö†Ô∏è GPU setup issue:\", e)\n",
    "# else:\n",
    "#     print(\"‚ÑπÔ∏è No GPU detected (CPU mode)\")\n",
    "\n",
    "# --- Paths ---\n",
    "DATA_DIR = os.getenv(\"PBROM_DATA_DIR\", \"PBROM data\")  # change if your folder name differs\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "os.makedirs(\"scalers\", exist_ok=True)\n",
    "os.makedirs(\"ablation\", exist_ok=True)\n",
    "os.makedirs(\"figs\", exist_ok=True)\n",
    "\n",
    "# # --- ‚≠êÔ∏è MODIFIED: File lists are now grouped ‚≠êÔ∏è ---\n",
    "# This is now the \"single source of truth\" for all files.\n",
    "# Based on your request for granular, per-cell groups.\n",
    "\n",
    "\n",
    "TRAIN_GROUPS = {\n",
    "    \"D5_Cells_1\": [\n",
    "        \"PBROM_data_cell_D5C77.mat\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "VAL_GROUPS = {\n",
    "    \"D5_Cells_1_Val\": [\n",
    "        \"PBROM_data_cell_D5C69.mat\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "TEST_GROUPS = {\n",
    "    \"D5_Cells_1_Test\": [\n",
    "        \"PBROM_data_cell_D5C78.mat\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# --- ‚≠êÔ∏è NEW: Auto-generate flat lists and lookup map ‚≠êÔ∏è ---\n",
    "# (This code builds all the helper lists we need)\n",
    "\n",
    "TRAIN_FILES = [f for files in TRAIN_GROUPS.values() for f in files]\n",
    "VAL_FILES = [f for files in VAL_GROUPS.values() for f in files]\n",
    "TEST_FILES = [f for files in TEST_GROUPS.values() for f in files]\n",
    "\n",
    "# This is our critical \"lookup map\"\n",
    "# It maps every single file to a group name, which we use to load the correct scaler\n",
    "FILE_TO_GROUP_MAP = {}\n",
    "all_groups = {**TRAIN_GROUPS, **VAL_GROUPS, **TEST_GROUPS}\n",
    "for group, files in all_groups.items():\n",
    "    for f in files:\n",
    "        # We find the \"base\" name for the scaler (e.g., \"PBROM_Cells_1\")\n",
    "        # This allows \"PBROM_Cells_1_Val\" to use the \"PBROM_Cells_1\" scaler\n",
    "        base_group = group.split('_Val')[0].split('_Test')[0]\n",
    "        FILE_TO_GROUP_MAP[f] = base_group\n",
    "\n",
    "print(f\"‚úÖ File map generated: {len(FILE_TO_GROUP_MAP)} files mapped to base groups.\")\n",
    "print(f\"  Example lookup: {TRAIN_FILES[0]} -> {FILE_TO_GROUP_MAP.get(TRAIN_FILES[0])}\")\n",
    "print(f\"  Example lookup: {VAL_FILES[0]} -> {FILE_TO_GROUP_MAP.get(VAL_FILES[0])}\")\n",
    "print(f\"  Example lookup: {TEST_FILES[0]} -> {FILE_TO_GROUP_MAP.get(TEST_FILES[0])}\")\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "\n",
    "# --- Helper: robust HDF5 .mat loader (squeezes to 1D/2D np arrays) ---\n",
    "def _read_field(f, key, required=True):\n",
    "    if key not in f:\n",
    "        if required:\n",
    "            raise KeyError(f\"Missing key '{key}' in MAT file.\")\n",
    "        return None\n",
    "    arr = np.array(f[key])\n",
    "    # MATLAB often stores column vectors as (1, N) or (N, 1); squeeze safely\n",
    "    return np.squeeze(arr)\n",
    "\n",
    "def load_mat(file_name):\n",
    "    \"\"\"\n",
    "    Loads a PBROM/NASA cell .mat file and returns a dict of numpy arrays:\n",
    "      I_p, SOC_p, Time_s_p, Q_exp_p, Q_total_p, V_cum_p, Temp_cum_p,\n",
    "      C_rate_profile, Bat_cap_profile, R_ch_profile, V_max_profile, V_min_profile,\n",
    "      Cap_Nom, t_exp\n",
    "    \"\"\"\n",
    "    path = os.path.join(DATA_DIR, file_name)\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Couldn't find: {path}\")\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        data = {\n",
    "            \"I_p\":                 _read_field(f, \"I_p\"),\n",
    "            \"SOC_p\":               _read_field(f, \"SOC_p\"),\n",
    "            \"Time_s_p\":            _read_field(f, \"Time_s_p\"),\n",
    "            \"Q_exp_p\":             _read_field(f, \"Q_exp_p\"),\n",
    "            \"Q_total_p\":           _read_field(f, \"Q_total_p\"),\n",
    "            \"V_cum_p\":             _read_field(f, \"V_cum_p\"),\n",
    "            \"Temp_cum_p\":          _read_field(f, \"Temp_cum_p\"),\n",
    "            \"C_rate_profile\":      _read_field(f, \"C_rate_profile\"),\n",
    "            \"Bat_cap_profile\":     _read_field(f, \"Bat_cap_profile\"),\n",
    "            \"R_ch_profile\":        _read_field(f, \"R_ch_profile\"),\n",
    "            \"V_max_profile\":       _read_field(f, \"V_max_profile\"),\n",
    "            \"V_min_profile\":       _read_field(f, \"V_min_profile\"),\n",
    "            \"Cap_Nom\":             _read_field(f, \"Cap_Nom\"),\n",
    "            \"t_exp\":               _read_field(f, \"t_exp\"),\n",
    "        }\n",
    "    return data\n",
    "\n",
    "# --- Quick sanity: print counts and peek sizes if files exist ---\n",
    "def _peek(files, tag):\n",
    "    ok = 0\n",
    "    for fn in files:\n",
    "        try:\n",
    "            d = load_mat(fn)\n",
    "            n = len(np.atleast_1d(d[\"Time_s_p\"]))\n",
    "            print(f\"[{tag}] {fn}: N={n}\")\n",
    "            ok += 1\n",
    "        except Exception as e:\n",
    "            print(f\"[{tag}] {fn}: ({e})\")\n",
    "    print(f\"[{tag}] Found/loaded {ok}/{len(files)} files in '{DATA_DIR}'\")\n",
    "\n",
    "print(\"\\nVerifying file availability (optional):\")\n",
    "# _peek now uses the new auto-generated flat lists\n",
    "_peek(TRAIN_FILES, \"TRAIN\")\n",
    "_peek(VAL_FILES,   \"VAL\")\n",
    "_peek(TEST_FILES,  \"TEST\")\n",
    "\n",
    "# =========================\n",
    "# ADD TO END OF CELL 1\n",
    "# =========================\n",
    "\n",
    "# Get all unique \"base\" group names from the file map\n",
    "# This ensures all groups (train, val, test) are included\n",
    "ALL_BASE_GROUPS = sorted(list(set(FILE_TO_GROUP_MAP.values())))\n",
    "\n",
    "# Create the ID mapping\n",
    "GROUP_TO_ID_MAP = {group_name: i for i, group_name in enumerate(ALL_BASE_GROUPS)}\n",
    "NUM_GROUPS = len(ALL_BASE_GROUPS)\n",
    "\n",
    "print(f\"\\n‚úÖ Group ID map generated ({NUM_GROUPS} total groups):\")\n",
    "for group_name, idx in GROUP_TO_ID_MAP.items():\n",
    "    print(f\"  {idx}: {group_name}\")\n",
    "\n",
    "# This map will now be available to all other cells\n",
    "\n",
    "print(\"\\n‚úÖ Cell 1 ready: imports, seeds, GPU setup, dirs, splits, loader.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b77357cd-923a-4bfe-b4c9-ac3e909a93d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Diagnosing Time Steps (dt) across 1 training files...\n",
      "\n",
      "========================================\n",
      "‚è±Ô∏è  TRAINING DATA TIME-SCALE REPORT\n",
      "========================================\n",
      "Total Steps Analyzed: 1,199,999\n",
      "Mean dt:   11.15876 s\n",
      "Median dt: 1.00000 s\n",
      "Min dt:    0.00000 s\n",
      "Max dt:    251.19000 s\n",
      "99th %ile: 100.00000 s\n",
      "----------------------------------------\n",
      "üí° INTERPRETATION FOR SIMULATOR:\n",
      "‚úÖ  PERFECT MATCH.\n",
      "    Training dt (~1.0s) matches Sim dt (1.0s).\n",
      "    Set TIME_SCALE_FACTOR = 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure we have the list of files (from Cell 1)\n",
    "if 'TRAIN_FILES' not in globals():\n",
    "    raise ValueError(\"Please run Cell 1 of your training script first to define TRAIN_FILES.\")\n",
    "\n",
    "print(f\"üîç Diagnosing Time Steps (dt) across {len(TRAIN_FILES)} training files...\")\n",
    "\n",
    "all_dts = []\n",
    "gaps_count = 0\n",
    "\n",
    "for fn in TRAIN_FILES:\n",
    "    try:\n",
    "        # Load using the helper from your script\n",
    "        d = load_mat(fn)\n",
    "        t = d[\"Time_s_p\"].flatten()\n",
    "        \n",
    "        if len(t) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Calculate time differences\n",
    "        dt = np.diff(t)\n",
    "        \n",
    "        # Store for analysis\n",
    "        all_dts.append(dt)\n",
    "        \n",
    "        # Check for gaps > 2.0s (potential discontinuity)\n",
    "        if np.any(dt > 2.0):\n",
    "            gaps_count += np.sum(dt > 2.0)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not load {fn}: {e}\")\n",
    "\n",
    "# Flatten list\n",
    "all_dts = np.concatenate(all_dts)\n",
    "\n",
    "# --- STATISTICS REPORT ---\n",
    "mean_dt = np.mean(all_dts)\n",
    "median_dt = np.median(all_dts)\n",
    "min_dt = np.min(all_dts)\n",
    "max_dt = np.max(all_dts)\n",
    "p99_dt = np.percentile(all_dts, 99)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"‚è±Ô∏è  TRAINING DATA TIME-SCALE REPORT\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Total Steps Analyzed: {len(all_dts):,}\")\n",
    "print(f\"Mean dt:   {mean_dt:.5f} s\")\n",
    "print(f\"Median dt: {median_dt:.5f} s\")\n",
    "print(f\"Min dt:    {min_dt:.5f} s\")\n",
    "print(f\"Max dt:    {max_dt:.5f} s\")\n",
    "print(f\"99th %ile: {p99_dt:.5f} s\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# --- INTERPRETATION ---\n",
    "print(\"üí° INTERPRETATION FOR SIMULATOR:\")\n",
    "sim_dt = 1.0 # Your simulator step\n",
    "\n",
    "if median_dt < 0.1:\n",
    "    ratio = sim_dt / median_dt\n",
    "    print(f\"‚ö†Ô∏è  HIGH FREQUENCY DATA DETECTED.\")\n",
    "    print(f\"    Your training data is ~{median_dt}s, but Sim is {sim_dt}s.\")\n",
    "    print(f\"    The model might treat 'dt={sim_dt}' as a large gap or Out-Of-Distribution.\")\n",
    "    print(f\"    Calculated Time Ratio: {ratio:.1f}x\")\n",
    "elif 0.9 <= median_dt <= 1.1:\n",
    "    print(f\"‚úÖ  PERFECT MATCH.\")\n",
    "    print(f\"    Training dt (~{median_dt}s) matches Sim dt ({sim_dt}s).\")\n",
    "    print(f\"    Set TIME_SCALE_FACTOR = 1.0\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è  Variable dt detected. Mean: {mean_dt:.2f}s\")\n",
    "\n",
    "# --- PLOT ---\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(all_dts, bins=50, range=(0, max(p99_dt * 1.5, 2.0)), log=True, color='skyblue', edgecolor='black')\n",
    "plt.axvline(x=1.0, color='r', linestyle='--', linewidth=2, label='Simulator Step (1.0s)')\n",
    "plt.title(\"Distribution of dt in Training Data\")\n",
    "plt.xlabel(\"Time Step (seconds)\")\n",
    "plt.ylabel(\"Count (Log Scale)\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab54ef5d-c9f6-4ad7-9e79-0563b9a1d4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Pass-0] Computing global time percentiles ...\n",
      "  p95_t  = 1.239591e+07\n",
      "  p95_dt = 9.902000e+01\n",
      "\n",
      "[Pass-0] Sampling dynamic rows for *global* feature scaler fit ...\n",
      "  Pooled dynamic sample shape: (1200000, 7)\n",
      "  ‚úì Saved *global* feature scaler ‚Üí scalers/feature_scaler.pkl\n",
      "\n",
      "[Pass-0] Fitting *per-group* delta PercentileScaler (auto-clipping)...\n",
      "  Fitting for group: D5_Cells_1 (1 files)\n",
      "  ‚úì Saved 'D5_Cells_1' scaler (scale_=5.8535e-02, clip_at_scaled_val=4.2804) ‚Üí scalers/delta_scaler_D5_Cells_1.pkl\n",
      "\n",
      "[Pass-0] Fitting *global* static scaler (StandardScaler) ...\n",
      "  ‚úì Saved *global* static scaler ‚Üí scalers/static_scaler.pkl\n",
      "  means = [1.  1.  4.2 2.8], scale = [1. 1. 1. 1.]\n",
      "  ‚úì Saved time stats ‚Üí scalers/time_stats.json\n",
      "\n",
      "[Pass-0] Diagnostics\n",
      "  SOC         min=0 max=1.047\n",
      "  V_norm      min=-0.1271 max=1.129\n",
      "  T_norm      min=2 max=2\n",
      "  t_abs_norm  min=0 max=1.08\n",
      "  dt_norm     min=0 max=2.537\n",
      "  C_rate      min=-2.904 max=2.799\n",
      "  win_pos     min=0 max=1\n",
      "\n",
      "[Pass-0] Extracting raw scaler parameters for high-speed pipeline...\n",
      "‚úÖ Raw scaler params (incl. clip limits) saved to ‚Üí scalers/scaler_params.npz\n",
      "‚úÖ Cell 2 complete.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Cell 2 ‚Äî Pass-0 (v2 - Automatic Clipping Scaler)\n",
    "# ==========================================================\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib  # <-- ‚≠êÔ∏è FIX: Corrected typo here\n",
    "\n",
    "# ---- Targets scaling constant (keep consistent everywhere) ----\n",
    "SCALE_DELTA = 1e5\n",
    "# ---- Normalization constants ----\n",
    "T_MIN = 10.0  # Common-sense min operating temp (C)\n",
    "T_MAX = 50.0  # Common-sense max operating temp (C)\n",
    "\n",
    "# ---- ‚≠êÔ∏è REPLACED: Robust PercentileScaler with Automatic Clipping ‚≠êÔ∏è ----\n",
    "class PercentileScaler:\n",
    "    \"\"\"\n",
    "    (Upgraded)\n",
    "    Scales data by dividing by the 'p_scale' percentile.\n",
    "    Automatically clips the output at the 'p_clip' percentile\n",
    "    to prevent extreme outliers from poisoning the optimizer.\n",
    "    \"\"\"\n",
    "    def __init__(self, p_scale=95, p_clip=99.9, eps=1e-6, min_pos=20):\n",
    "        self.p_scale = p_scale\n",
    "        self.p_clip = p_clip\n",
    "        self.eps = eps\n",
    "        self.min_pos = min_pos\n",
    "        self.scale_ = 1.0\n",
    "        self.clip_limit_ = 1e9 # Default to a huge number\n",
    "\n",
    "    def fit(self, x):\n",
    "        x = np.asarray(x).reshape(-1)\n",
    "        x_pos = x[x > 0] # Only fit on positive values\n",
    "\n",
    "        if x_pos.size < self.min_pos:\n",
    "            # Not enough data, use fallback\n",
    "            if x.size > 0:\n",
    "                p_scale_val = np.percentile(x, max(self.p_scale, 99))\n",
    "                p_clip_val = np.percentile(x, max(self.p_clip, 99.9))\n",
    "            else:\n",
    "                p_scale_val = 1.0\n",
    "                p_clip_val = 1.0\n",
    "        else:\n",
    "            # We have enough positive data to get good percentiles\n",
    "            p_scale_val = np.percentile(x_pos, self.p_scale)\n",
    "            p_clip_val = np.percentile(x_pos, self.p_clip)\n",
    "\n",
    "        self.scale_ = max(float(p_scale_val), self.eps)\n",
    "        \n",
    "        # --- This is the new part ---\n",
    "        # Calculate the scaled clip limit\n",
    "        # e.g., if p_clip (3.55) / p_scale (2.39) = 1.48\n",
    "        self.clip_limit_ = max(float(p_clip_val) / self.scale_, 1.0) # Must be at least 1.0\n",
    "        # ---\n",
    "\n",
    "    def transform(self, x):\n",
    "        x_scaled = np.asarray(x).reshape(-1, 1) / self.scale_\n",
    "        \n",
    "        # --- This is the new part ---\n",
    "        # Automatically apply the per-group clipping\n",
    "        x_clipped = np.clip(x_scaled, 0.0, self.clip_limit_)\n",
    "        # ---\n",
    "        return x_clipped\n",
    "\n",
    "    def inverse_transform(self, x):\n",
    "        # Inverse transform should not be clipped\n",
    "        return np.asarray(x).reshape(-1, 1) * self.scale_\n",
    "\n",
    "\n",
    "# ---- Utilities for Pass-0 ----\n",
    "# (No changes needed in _grab_scalar, compute_global_time_percentiles,\n",
    "# or collect_positive_deltas_scaled)\n",
    "\n",
    "def _grab_scalar(x, default=0.0):\n",
    "    arr = np.asarray(x).reshape(-1)\n",
    "    return float(arr[0]) if arr.size else default\n",
    "\n",
    "def compute_global_time_percentiles(train_files):\n",
    "    elapsed_pool = []\n",
    "    dt_pool = []\n",
    "    for fn in train_files:\n",
    "        d = load_mat(fn)\n",
    "        t = d[\"Time_s_p\"].astype(np.float64).flatten()\n",
    "        if t.size == 0:\n",
    "            continue\n",
    "        elapsed = t - t[0]\n",
    "        dt = np.diff(t, prepend=t[0])\n",
    "        elapsed_pool.append(elapsed)\n",
    "        if dt.size > 1:\n",
    "            dt_pool.append(dt[1:])  # skip the very first zero\n",
    "    elapsed_all = np.concatenate(elapsed_pool) if elapsed_pool else np.array([1.0])\n",
    "    dt_all = np.concatenate(dt_pool) if dt_pool else np.array([1.0])\n",
    "    p95_t = float(np.percentile(elapsed_all, 95))\n",
    "    p95_dt = float(np.percentile(dt_all, 95))\n",
    "    return p95_t, p95_dt\n",
    "\n",
    "\n",
    "def sample_dynamic_rows_for_scaler(train_files, p95_t, p95_dt,\n",
    "                                    target_rows_total=2_000_000, include_winpos=True,\n",
    "                                    window_size_for_winpos=100):\n",
    "    per_file_target = max(50_000, target_rows_total // max(1, len(train_files)))\n",
    "    rows = []\n",
    "    for fn in train_files:\n",
    "        d = load_mat(fn)\n",
    "        SOC = np.atleast_1d(d[\"SOC_p\"]).astype(np.float64).flatten()\n",
    "        V   = np.atleast_1d(d[\"V_cum_p\"]).astype(np.float64).flatten()\n",
    "        T   = np.atleast_1d(d[\"Temp_cum_p\"]).astype(np.float64).flatten()\n",
    "        t   = np.atleast_1d(d[\"Time_s_p\"]).astype(np.float64).flatten()\n",
    "        # --- ‚≠êÔ∏è MODIFICATION: Load C-Rate ---\n",
    "        Cr = np.atleast_1d(d[\"C_rate_profile\"]).astype(np.float64).flatten()\n",
    "\n",
    "        V_max = _grab_scalar(d[\"V_max_profile\"], 4.2)\n",
    "        V_min = _grab_scalar(d[\"V_min_profile\"], 2.5)\n",
    "\n",
    "        if t.size == 0: continue\n",
    "        elapsed = t - t[0]\n",
    "        dt = np.diff(t, prepend=t[0])\n",
    "        t_abs_norm = np.clip(elapsed / max(p95_t, 1e-12), 0.0, 4.0)\n",
    "        dt_norm    = np.clip(dt      / max(p95_dt, 1e-12), 0.0, 4.0)\n",
    "        V_norm = np.clip((V - V_min) / max(V_max - V_min, 1e-6), -1.0, 2.0)\n",
    "        T_norm = np.clip((T - T_MIN) / (T_MAX - T_MIN), -1.0, 2.0)\n",
    "\n",
    "        # --- ‚≠êÔ∏è MODIFICATION: Add Cr to min size check ---\n",
    "        N = min(SOC.size, V_norm.size, T_norm.size, t_abs_norm.size, dt_norm.size, Cr.size)\n",
    "        if N <= 0: continue\n",
    "\n",
    "        if N <= per_file_target: idx = np.arange(N)\n",
    "        else: idx = np.linspace(0, N - 1, per_file_target).astype(int)\n",
    "\n",
    "        if include_winpos:\n",
    "            wp_vec = np.linspace(0, 1, window_size_for_winpos)\n",
    "            win_pos_approx = np.resize(wp_vec, idx.size)\n",
    "            # --- ‚≠êÔ∏è MODIFICATION: Add Cr (6th feature) to stack ---\n",
    "            dyn = np.stack([ SOC[idx], V_norm[idx], T_norm[idx], t_abs_norm[idx], dt_norm[idx], Cr[idx], win_pos_approx ], axis=1)\n",
    "        else:\n",
    "            # --- ‚≠êÔ∏è MODIFICATION: Add Cr (6th feature) to stack ---\n",
    "            dyn = np.stack([ SOC[idx], V_norm[idx], T_norm[idx], t_abs_norm[idx], dt_norm[idx], Cr[idx] ], axis=1)\n",
    "        rows.append(dyn)\n",
    "\n",
    "    # --- ‚≠êÔ∏è MODIFICATION: Update fallback shape to 7 columns ---\n",
    "    if not rows: return np.zeros((10, 7), dtype=np.float64)\n",
    "    return np.vstack(rows)\n",
    "\n",
    "\n",
    "def collect_positive_deltas_scaled(train_files):\n",
    "    \"\"\"Collect positive (ŒîQ_exp_norm, ŒîQ_PB_norm) * SCALE_DELTA across a list of files.\"\"\"\n",
    "    buf = []\n",
    "    for fn in train_files:\n",
    "        d = load_mat(fn)\n",
    "        # --- Q values are ALREADY NORMALIZED ---\n",
    "        Qe_norm = np.atleast_1d(d[\"Q_exp_p\"]).astype(np.float64).flatten()\n",
    "        Qp_norm = np.atleast_1d(d[\"Q_total_p\"]).astype(np.float64).flatten()\n",
    "\n",
    "        if Qe_norm.size < 2 or Qp_norm.size < 2:\n",
    "            continue\n",
    "\n",
    "        dq_e_norm = np.maximum(Qe_norm[1:] - Qe_norm[:-1], 0.0)\n",
    "        dq_p_norm = np.maximum(Qp_norm[1:] - Qp_norm[:-1], 0.0)\n",
    "        \n",
    "        dq_e = dq_e_norm * SCALE_DELTA\n",
    "        dq_p = dq_p_norm * SCALE_DELTA\n",
    "\n",
    "        if dq_e.size: buf.append(dq_e)\n",
    "        if dq_p.size: buf.append(dq_p)\n",
    "\n",
    "    if not buf: return np.array([1.0])\n",
    "    return np.concatenate(buf)\n",
    "\n",
    "# ---- Execute Pass-0 ----\n",
    "print(\"\\n[Pass-0] Computing global time percentiles ...\")\n",
    "p95_t, p95_dt = compute_global_time_percentiles(TRAIN_FILES)\n",
    "print(f\"  p95_t  = {p95_t:.6e}\")\n",
    "print(f\"  p95_dt = {p95_dt:.6e}\")\n",
    "\n",
    "print(\"\\n[Pass-0] Sampling dynamic rows for *global* feature scaler fit ...\")\n",
    "# THIS IS THE CORRECT LINE\n",
    "dyn_rows = sample_dynamic_rows_for_scaler(TRAIN_FILES, p95_t, p95_dt)\n",
    "print(f\"  Pooled dynamic sample shape: {dyn_rows.shape}\")\n",
    "\n",
    "feature_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "feature_scaler.fit(dyn_rows)\n",
    "joblib.dump(feature_scaler, os.path.join(\"scalers\", \"feature_scaler.pkl\"))\n",
    "print(\"  ‚úì Saved *global* feature scaler ‚Üí scalers/feature_scaler.pkl\")\n",
    "\n",
    "\n",
    "# --- ‚≠êÔ∏è MODIFIED: Fit one auto-clipping scaler PER GROUP ‚≠êÔ∏è ---\n",
    "print(\"\\n[Pass-0] Fitting *per-group* delta PercentileScaler (auto-clipping)...\")\n",
    "for group_name, file_list in TRAIN_GROUPS.items():\n",
    "    if not file_list: continue\n",
    "    \n",
    "    print(f\"  Fitting for group: {group_name} ({len(file_list)} files)\")\n",
    "    dq_group = collect_positive_deltas_scaled(file_list)\n",
    "    \n",
    "    # Use the new scaler class\n",
    "    delta_scaler_group = PercentileScaler(p_scale=95, p_clip=99.9, eps=1e-6, min_pos=20)\n",
    "    delta_scaler_group.fit(dq_group)\n",
    "    \n",
    "    scaler_filename = f\"delta_scaler_{group_name}.pkl\"\n",
    "    scaler_path = os.path.join(\"scalers\", scaler_filename)\n",
    "    joblib.dump(delta_scaler_group, scaler_path)\n",
    "    # ‚≠êÔ∏è (Added clip_limit_ to the print statement) ‚≠êÔ∏è\n",
    "    print(f\"  ‚úì Saved '{group_name}' scaler (scale_={delta_scaler_group.scale_:.4e}, clip_at_scaled_val={delta_scaler_group.clip_limit_:.4f}) ‚Üí {scaler_path}\")\n",
    "# --- END MODIFICATION ---\n",
    "\n",
    "\n",
    "# (Static scaler is unchanged)\n",
    "def collect_static_rows(train_files):\n",
    "    rows = []\n",
    "    for fn in train_files:\n",
    "        d = load_mat(fn)\n",
    "        rows.append([ _grab_scalar(d[\"Bat_cap_profile\"]), _grab_scalar(d[\"R_ch_profile\"]), _grab_scalar(d[\"V_max_profile\"]), _grab_scalar(d[\"V_min_profile\"]) ])\n",
    "    return np.array(rows, dtype=np.float64) if rows else np.zeros((1,4), dtype=np.float64)\n",
    "\n",
    "print(\"\\n[Pass-0] Fitting *global* static scaler (StandardScaler) ...\")\n",
    "static_rows = collect_static_rows(TRAIN_FILES)\n",
    "static_scaler = StandardScaler()\n",
    "static_scaler.fit(static_rows)\n",
    "joblib.dump(static_scaler, os.path.join(\"scalers\", \"static_scaler.pkl\"))\n",
    "print(\"  ‚úì Saved *global* static scaler ‚Üí scalers/static_scaler.pkl\")\n",
    "print(f\"  means = {static_scaler.mean_}, scale = {static_scaler.scale_}\")\n",
    "\n",
    "time_stats = {\"p95_t\": p95_t, \"p95_dt\": p95_dt}\n",
    "with open(os.path.join(\"scalers\", \"time_stats.json\"), \"w\") as f: json.dump(time_stats, f, indent=2)\n",
    "print(\"  ‚úì Saved time stats ‚Üí scalers/time_stats.json\")\n",
    "\n",
    "print(\"\\n[Pass-0] Diagnostics\")\n",
    "mins = dyn_rows.min(axis=0); maxs = dyn_rows.max(axis=0)\n",
    "# --- ‚≠êÔ∏è MODIFICATION: Add \"C_rate\" to colnames ---\n",
    "colnames = [\"SOC\", \"V_norm\", \"T_norm\", \"t_abs_norm\", \"dt_norm\", \"C_rate\", \"win_pos\"]\n",
    "for i, name in enumerate(colnames): print(f\"  {name:<11} min={mins[i]:.4g} max={maxs[i]:.4g}\")\n",
    "\n",
    "print(\"\\n[Pass-0] Extracting raw scaler parameters for high-speed pipeline...\")\n",
    "# (This part is unchanged, but we'll add the clip limit to the npz)\n",
    "fs = joblib.load(os.path.join(\"scalers\", \"feature_scaler.pkl\"))\n",
    "ss = joblib.load(os.path.join(\"scalers\", \"static_scaler.pkl\"))\n",
    "scaler_params = {\n",
    "    \"feature_min\": fs.min_,\n",
    "    \"feature_scale\": fs.scale_,\n",
    "    \"static_mean\": ss.mean_,\n",
    "    \"static_scale\": ss.scale_,\n",
    "}\n",
    "for group_name in TRAIN_GROUPS.keys():\n",
    "    scaler_path = os.path.join(\"scalers\", f\"delta_scaler_{group_name}.pkl\")\n",
    "    if os.path.exists(scaler_path):\n",
    "        ds = joblib.load(scaler_path)\n",
    "        scaler_params[f\"delta_scale_{group_name}\"] = ds.scale_\n",
    "        scaler_params[f\"delta_clip_{group_name}\"] = ds.clip_limit_ # ‚≠êÔ∏è NEW\n",
    "\n",
    "scaler_npz_path = os.path.join(\"scalers\", \"scaler_params.npz\")\n",
    "np.savez_compressed(scaler_npz_path, **scaler_params)\n",
    "print(f\"‚úÖ Raw scaler params (incl. clip limits) saved to ‚Üí {scaler_npz_path}\")\n",
    "print(\"‚úÖ Cell 2 complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca944d9f-1f2f-4e5a-8045-375b74a8ef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Hyperparameters registered.\n",
      "‚úÖ ARCHITECTURE: 2 Layers, 64 Embed Dim\n",
      "‚úÖ REGULARIZATION: DROPOUT=0.2, L2_REG=0.0005, NOISE_STDDEV=0.001\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# Cell 3 ‚Äî Main Hyperparameters (central)\n",
    "# ======================================\n",
    "\n",
    "# --- Windowing / dataset ---\n",
    "WINDOW_SIZE = 150    # using 25-step window\n",
    "STRIDE      = 1\n",
    "BATCH_SIZE  = 512   # (legacy; training actually uses BATCH_PER_DEVICE)\n",
    "\n",
    "# --- ‚≠êÔ∏è MODIFIED: Simplified Architecture ---\n",
    "EMBED_DIM       = 64    # Reduced from 64\n",
    "NUM_HEADS       = 4\n",
    "FF_DIM          = 64    # Reduced from 128\n",
    "NUM_LAYERS      = 2     # Reduced from 2\n",
    "SOFTPLUS_BETA   = 1.0\n",
    "GROUP_EMBED_DIM = 8\n",
    "\n",
    "# --- Regularization (Keep these) ---\n",
    "DROPOUT         = 0.20\n",
    "L2_REG          = 5e-4\n",
    "GAUSSIAN_NOISE_STDDEV = 0.001\n",
    "\n",
    "# --- Training / optimization ---\n",
    "BATCH_PER_DEVICE = 512  # effective batch size per GPU\n",
    "EPOCHS           = 50   # you rarely need 50 with early stopping\n",
    "LR               = 1e-5 # same stable LR that worked well for you\n",
    "CLIPNORM         = 1.0\n",
    "AMSGRAD          = True\n",
    "\n",
    "# --- Loss weights ---\n",
    "LAMBDA_DATA = 1.0\n",
    "LAMBDA_PHYS = 0.672023\n",
    "LAMBDA_ZERO = 0.0\n",
    "HUBER_DELTA = 1.0 \n",
    "\n",
    "# --- Scheduler / early stopping ---\n",
    "VAL_FREQ            = 2   # validate more often to catch best epoch\n",
    "EARLY_STOP_PATIENCE = 5   # 5√ó2=10 epochs of no improvement allowed\n",
    "LR_PATIENCE         = 3\n",
    "LR_FACTOR           = 0.5\n",
    "LR_MIN              = 1e-6\n",
    "\n",
    "# --- Constants ---\n",
    "SCALE_DELTA = 1e5\n",
    "\n",
    "print(\"‚úÖ Hyperparameters registered.\")\n",
    "print(f\"‚úÖ ARCHITECTURE: {NUM_LAYERS} Layers, {EMBED_DIM} Embed Dim\")\n",
    "print(f\"‚úÖ REGULARIZATION: DROPOUT={DROPOUT}, L2_REG={L2_REG}, NOISE_STDDEV={GAUSSIAN_NOISE_STDDEV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06539e03-ec55-4bc2-9693-b1e6c2be2261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with v7 'Input Modulation' architecture (single-group variant):\n",
      "Model: \"PITM_DeltaTransformer_v7_Modulated_SingleGroup\"\n",
      "________________________________________________________________________________________________________________________\n",
      " Layer (type)                          Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      " dyn_in (InputLayer)                   [(None, 150, 7)]           0             []                                      \n",
      "                                                                                                                        \n",
      " dyn_gaussian_noise (GaussianNoise)    (None, 150, 7)             0             ['dyn_in[0][0]']                        \n",
      "                                                                                                                        \n",
      " dyn_physics_projection (TimeDistribut  (None, 150, 64)           512           ['dyn_gaussian_noise[0][0]']            \n",
      " ed)                                                                                                                    \n",
      "                                                                                                                        \n",
      " shared_pos_enc (SharedPositionalEncod  (None, 150, 64)           9600          ['dyn_physics_projection[0][0]']        \n",
      " ing)                                                                                                                   \n",
      "                                                                                                                        \n",
      " layer_normalization (LayerNormalizati  (None, 150, 64)           128           ['shared_pos_enc[0][0]']                \n",
      " on)                                                                                                                    \n",
      "                                                                                                                        \n",
      " multi_head_attention (MultiHeadAttent  (None, 150, 64)           16640         ['layer_normalization[0][0]',           \n",
      " ion)                                                                            'layer_normalization[0][0]']           \n",
      "                                                                                                                        \n",
      " dropout (Dropout)                     (None, 150, 64)            0             ['multi_head_attention[0][0]']          \n",
      "                                                                                                                        \n",
      " add (Add)                             (None, 150, 64)            0             ['shared_pos_enc[0][0]',                \n",
      "                                                                                 'dropout[0][0]']                       \n",
      "                                                                                                                        \n",
      " layer_normalization_1 (LayerNormaliza  (None, 150, 64)           128           ['add[0][0]']                           \n",
      " tion)                                                                                                                  \n",
      "                                                                                                                        \n",
      " dense_1 (Dense)                       (None, 150, 64)            4160          ['layer_normalization_1[0][0]']         \n",
      "                                                                                                                        \n",
      " dropout_1 (Dropout)                   (None, 150, 64)            0             ['dense_1[0][0]']                       \n",
      "                                                                                                                        \n",
      " dense_2 (Dense)                       (None, 150, 64)            4160          ['dropout_1[0][0]']                     \n",
      "                                                                                                                        \n",
      " add_1 (Add)                           (None, 150, 64)            0             ['add[0][0]',                           \n",
      "                                                                                 'dense_2[0][0]']                       \n",
      "                                                                                                                        \n",
      " layer_normalization_2 (LayerNormaliza  (None, 150, 64)           128           ['add_1[0][0]']                         \n",
      " tion)                                                                                                                  \n",
      "                                                                                                                        \n",
      " multi_head_attention_1 (MultiHeadAtte  (None, 150, 64)           16640         ['layer_normalization_2[0][0]',         \n",
      " ntion)                                                                          'layer_normalization_2[0][0]']         \n",
      "                                                                                                                        \n",
      " dropout_2 (Dropout)                   (None, 150, 64)            0             ['multi_head_attention_1[0][0]']        \n",
      "                                                                                                                        \n",
      " add_2 (Add)                           (None, 150, 64)            0             ['add_1[0][0]',                         \n",
      "                                                                                 'dropout_2[0][0]']                     \n",
      "                                                                                                                        \n",
      " layer_normalization_3 (LayerNormaliza  (None, 150, 64)           128           ['add_2[0][0]']                         \n",
      " tion)                                                                                                                  \n",
      "                                                                                                                        \n",
      " dense_3 (Dense)                       (None, 150, 64)            4160          ['layer_normalization_3[0][0]']         \n",
      "                                                                                                                        \n",
      " dropout_3 (Dropout)                   (None, 150, 64)            0             ['dense_3[0][0]']                       \n",
      "                                                                                                                        \n",
      " dense_4 (Dense)                       (None, 150, 64)            4160          ['dropout_3[0][0]']                     \n",
      "                                                                                                                        \n",
      " add_3 (Add)                           (None, 150, 64)            0             ['add_2[0][0]',                         \n",
      "                                                                                 'dense_4[0][0]']                       \n",
      "                                                                                                                        \n",
      " take_last_token (Lambda)              (None, 64)                 0             ['add_3[0][0]']                         \n",
      "                                                                                                                        \n",
      " dense_5 (Dense)                       (None, 64)                 4160          ['take_last_token[0][0]']               \n",
      "                                                                                                                        \n",
      " dense_6 (Dense)                       (None, 32)                 2080          ['dense_5[0][0]']                       \n",
      "                                                                                                                        \n",
      " raw_pre_softplus (Dense)              (None, 1)                  33            ['dense_6[0][0]']                       \n",
      "                                                                                                                        \n",
      " static_in (InputLayer)                [(None, 4)]                0             []                                      \n",
      "                                                                                                                        \n",
      " group_id_in (InputLayer)              [(None, 1)]                0             []                                      \n",
      "                                                                                                                        \n",
      " delta_hat (Lambda)                    (None, 1)                  0             ['raw_pre_softplus[0][0]']              \n",
      "                                                                                                                        \n",
      "========================================================================================================================\n",
      "Total params: 66,817\n",
      "Trainable params: 66,817\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________________________________________________\n",
      "\n",
      "‚úÖ Cell 4 ready: v7 'Modulated' single-group model built (uncompiled).\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# Cell 4 ‚Äî Model Builder (v7 - \"Input Modulation\" + L2 Reg + Noise)\n",
    "# (Single-group variant: static features & group ID are ignored,\n",
    "#  but inputs are kept for full compatibility with the pipeline.)\n",
    "# ==========================================================\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, LayerNormalization, MultiHeadAttention,\n",
    "    Add, Concatenate, TimeDistributed, Embedding, Lambda,\n",
    "    Flatten, GaussianNoise\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "\n",
    "# (transformer_encoder_prenorm is unchanged from before)\n",
    "def transformer_encoder_prenorm(x, head_size, num_heads, ff_dim, dropout, l2_reg):\n",
    "    x_ln1 = LayerNormalization(epsilon=1e-6)(x)\n",
    "    attn  = MultiHeadAttention(num_heads=num_heads, key_dim=head_size, dropout=dropout)(x_ln1, x_ln1)\n",
    "    attn  = Dropout(dropout)(attn)\n",
    "    x     = Add()([x, attn])\n",
    "    x_ln2 = LayerNormalization(epsilon=1e-6)(x)\n",
    "    ff    = Dense(ff_dim, activation=\"relu\", kernel_regularizer=regularizers.l2(l2_reg))(x_ln2)\n",
    "    ff    = Dropout(dropout)(ff)\n",
    "    ff    = Dense(x.shape[-1], kernel_regularizer=regularizers.l2(l2_reg))(ff)\n",
    "    x     = Add()([x, ff])\n",
    "    return x\n",
    "\n",
    "# (SharedPositionalEncoding is unchanged)\n",
    "class SharedPositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, window_size, embedding_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.window_size = int(window_size)\n",
    "        self.embedding_dim = int(embedding_dim)\n",
    "        self.embedding_layer = Embedding(\n",
    "            input_dim=self.window_size,\n",
    "            output_dim=self.embedding_dim,\n",
    "            name=\"shared_pos_embedding\"\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        T = tf.shape(x)[1]\n",
    "        positions = tf.range(start=0, limit=T, delta=1)\n",
    "        pos_enc = self.embedding_layer(positions)\n",
    "        pos_enc = tf.expand_dims(pos_enc, axis=0)\n",
    "        pos_enc = tf.tile(pos_enc, [tf.shape(x)[0], 1, 1])\n",
    "        return x + pos_enc\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        cfg.update({\n",
    "            \"window_size\": self.window_size,\n",
    "            \"embedding_dim\": self.embedding_dim\n",
    "        })\n",
    "        return cfg\n",
    "\n",
    "# ---- Model builder (v7, single-group variant) ----\n",
    "def build_pitm_model(\n",
    "    window_size,\n",
    "    num_groups,                       # kept for API compatibility\n",
    "    group_embed_dim=GROUP_EMBED_DIM,  # kept for API compatibility\n",
    "    embed_dim=EMBED_DIM,\n",
    "    num_heads=NUM_HEADS,\n",
    "    ff_dim=FF_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    l2_reg=L2_REG,\n",
    "    noise_stddev=GAUSSIAN_NOISE_STDDEV\n",
    "):\n",
    "    \"\"\"\n",
    "    Physics-Informed Transformer Model (PITM) for ŒîQ.\n",
    "\n",
    "    Single-group variant:\n",
    "    - Still accepts three inputs: dyn_in, static_in, group_id_in\n",
    "      to match the existing training / testing / random-search pipeline.\n",
    "    - Internally, the model now *ignores* static_in and group_id_in,\n",
    "      so behavior is driven purely by dynamic features.\n",
    "    \"\"\"\n",
    "    head_size = max(1, embed_dim // num_heads)\n",
    "\n",
    "    # ----- 1. Define Inputs (3 total, unchanged signature) -----\n",
    "    dyn_in      = Input(shape=(window_size, 7), name=\"dyn_in\")\n",
    "    static_in   = Input(shape=(4,),           name=\"static_in\")\n",
    "    group_id_in = Input(shape=(1,),           name=\"group_id_in\", dtype=\"int32\")\n",
    "\n",
    "    # ----- 2. Data augmentation on dynamic input (unchanged) -----\n",
    "    dyn_noised = GaussianNoise(noise_stddev, name=\"dyn_gaussian_noise\")(dyn_in)\n",
    "\n",
    "    # ----- 3. Ignore static and group ID in the computation -----\n",
    "    # We keep static_in and group_id_in as inputs so that all upstream\n",
    "    # code (build_training_arrays, stream_windows_from_files, predict_cell,\n",
    "    # random search) can remain exactly the same.\n",
    "    #\n",
    "    # For the forward path, we simply use dyn_noised as-is.\n",
    "    dyn_combined = dyn_noised  # no static concatenation anymore\n",
    "\n",
    "    # ----- 4. Physics projection on dynamic-only features -----\n",
    "    dyn_proj = TimeDistributed(\n",
    "        Dense(\n",
    "            embed_dim,\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=regularizers.l2(l2_reg)\n",
    "        ),\n",
    "        name=\"dyn_physics_projection\"\n",
    "    )(dyn_combined)\n",
    "\n",
    "    # We still instantiate the group embedding layer for compatibility,\n",
    "    # but we DO NOT add it to dyn_proj (i.e., no modulation).\n",
    "    group_embed = Embedding(\n",
    "        input_dim=num_groups,\n",
    "        output_dim=embed_dim,\n",
    "        embeddings_regularizer=regularizers.l2(l2_reg),\n",
    "        name=\"group_embedding\"\n",
    "    )(group_id_in)\n",
    "    # Old behaviour (multi-group modulation) was:\n",
    "    #   dyn_modulated = Add(name=\"dyn_modulation\")([dyn_proj, group_embed])\n",
    "    # For single-group use, we now ignore group_embed:\n",
    "    dyn_modulated = dyn_proj\n",
    "\n",
    "    # ----- 5. Shared Transformer body (unchanged) -----\n",
    "    shared_pos = SharedPositionalEncoding(window_size, embed_dim, name=\"shared_pos_enc\")\n",
    "    x = shared_pos(dyn_modulated)\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        x = transformer_encoder_prenorm(\n",
    "            x,\n",
    "            head_size=head_size,\n",
    "            num_heads=num_heads,\n",
    "            ff_dim=ff_dim,\n",
    "            dropout=dropout,\n",
    "            l2_reg=l2_reg\n",
    "        )\n",
    "\n",
    "    take_last = Lambda(lambda t: t[:, -1, :], name=\"take_last_token\")\n",
    "    x_last = take_last(x)\n",
    "\n",
    "    # ----- 6. Output head (unchanged) -----\n",
    "    fused = x_last\n",
    "    fused_head = Dense(\n",
    "        64,\n",
    "        activation=\"relu\",\n",
    "        kernel_regularizer=regularizers.l2(l2_reg)\n",
    "    )(fused)\n",
    "    fused_head = Dense(\n",
    "        32,\n",
    "        activation=\"relu\",\n",
    "        kernel_regularizer=regularizers.l2(l2_reg)\n",
    "    )(fused_head)\n",
    "\n",
    "    raw = Dense(\n",
    "        1,\n",
    "        name=\"raw_pre_softplus\",\n",
    "        bias_initializer=initializers.Constant(0.0),\n",
    "        kernel_regularizer=regularizers.l2(l2_reg),\n",
    "    )(fused_head)\n",
    "\n",
    "    # --- 7. Final Activation (unchanged) ---\n",
    "    def softplus32(z, beta=1.0):\n",
    "        z32 = tf.cast(z, tf.float32)\n",
    "        out32 = tf.nn.softplus(beta * z32) / beta\n",
    "        return tf.cast(out32, z.dtype)\n",
    "\n",
    "    delta_hat = Lambda(\n",
    "        lambda z: softplus32(z, beta=SOFTPLUS_BETA),\n",
    "        name=\"delta_hat\"\n",
    "    )(raw)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[dyn_in, static_in, group_id_in],\n",
    "        outputs=delta_hat,\n",
    "        name=\"PITM_DeltaTransformer_v7_Modulated_SingleGroup\"\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# (Loss function is unchanged)\n",
    "def pitm_delta_loss(lambda_data=1.0, lambda_phys=1.0, lambda_zero=0.0, huber_delta=1.5):\n",
    "    def huber(e, delta):\n",
    "        a = tf.abs(e)\n",
    "        return tf.where(\n",
    "            a <= delta,\n",
    "            0.5 * tf.square(e),\n",
    "            delta * (a - 0.5 * delta)\n",
    "        )\n",
    "\n",
    "    def _loss(y_true, y_pred):\n",
    "        dq_exp = y_true[:, 0:1]\n",
    "        dq_pb  = y_true[:, 1:2]\n",
    "        dq_hat = y_pred\n",
    "\n",
    "        pos_mask  = tf.cast(tf.logical_or(dq_exp > 0.0, dq_pb > 0.0), tf.float32)\n",
    "        zero_mask = 1.0 - pos_mask\n",
    "\n",
    "        l_data = tf.reduce_mean(huber(dq_exp - dq_hat, huber_delta))\n",
    "        l_phys = tf.reduce_mean(huber(dq_pb  - dq_hat, huber_delta))\n",
    "        l_zero = tf.reduce_mean(zero_mask * dq_hat)\n",
    "\n",
    "        return lambda_data*l_data + lambda_phys*l_phys + lambda_zero*l_zero\n",
    "\n",
    "    return _loss\n",
    "\n",
    "# ---- Build model to check summary ----\n",
    "print(\"Building model with v7 'Input Modulation' architecture (single-group variant):\")\n",
    "model = build_pitm_model(\n",
    "    window_size=WINDOW_SIZE,\n",
    "    num_groups=NUM_GROUPS,  # From Cell 1 (still passed, but not used for modulation)\n",
    "    embed_dim=EMBED_DIM,\n",
    "    num_heads=NUM_HEADS,\n",
    "    ff_dim=FF_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "model.summary(line_length=120)\n",
    "print(\"\\n‚úÖ Cell 4 ready: v7 'Modulated' single-group model built (uncompiled).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b578f63-82a3-4e29-834b-eea4600bfb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ‚öôÔ∏è Cell 4.5 ready: use build_training_arrays(window_size, stride) to create in-memory training data ---\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "# ===============================================\n",
    "# Cell 4.5 ‚Äî Pass 1.5 as a reusable function\n",
    "# Pre-process all training data (v3.1 - SAMPLE WEIGHTING)\n",
    "# ===============================================\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "print(\"--- ‚öôÔ∏è Cell 4.5 ready: use build_training_arrays(window_size, stride) to create in-memory training data ---\")\n",
    "\n",
    "def build_training_arrays(window_size, stride):\n",
    "    \"\"\"\n",
    "    Build the in-memory, unbalanced training arrays with sample weights\n",
    "    for a given window_size and stride.\n",
    "    \n",
    "    After calling this, the following globals are created:\n",
    "        X_train_dyn, X_train_st, X_train_gid, y_train, train_sample_weights\n",
    "    \"\"\"\n",
    "    global X_train_dyn, X_train_st, X_train_gid, y_train, train_sample_weights\n",
    "\n",
    "    print(f\"\\n--- ‚öôÔ∏è Pass 1.5: Building training arrays (window_size={window_size}, stride={stride}) ---\")\n",
    "    print(\"This will create one giant, UNBALANCED, shuffled training set WITH SAMPLE WEIGHTS.\")\n",
    "\n",
    "    # --- Local helpers (same as before) ---\n",
    "    def _grab_scalar(x, default=0.0):\n",
    "        arr = np.asarray(x).reshape(-1)\n",
    "        return float(arr[0]) if arr.size else default\n",
    "\n",
    "    def _read_field(f, key, required=True):\n",
    "        if key not in f:\n",
    "            if required: \n",
    "                raise KeyError(f\"Missing key '{key}' in MAT file.\")\n",
    "            return None\n",
    "        arr = np.array(f[key])\n",
    "        return np.squeeze(arr)\n",
    "\n",
    "    def load_mat_local(file_name):\n",
    "        path = os.path.join(DATA_DIR, file_name)\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"Couldn't find: {path}\")\n",
    "        with h5py.File(path, \"r\") as f:\n",
    "            data = {\n",
    "                \"I_p\":              _read_field(f, \"I_p\"),\n",
    "                \"SOC_p\":            _read_field(f, \"SOC_p\"),\n",
    "                \"Time_s_p\":         _read_field(f, \"Time_s_p\"),\n",
    "                \"Q_exp_p\":          _read_field(f, \"Q_exp_p\"),\n",
    "                \"Q_total_p\":        _read_field(f, \"Q_total_p\"),\n",
    "                \"V_cum_p\":          _read_field(f, \"V_cum_p\"),\n",
    "                \"Temp_cum_p\":       _read_field(f, \"Temp_cum_p\"),\n",
    "                \"C_rate_profile\":   _read_field(f, \"C_rate_profile\"),\n",
    "                \"Bat_cap_profile\":  _read_field(f, \"Bat_cap_profile\"),\n",
    "                \"R_ch_profile\":     _read_field(f, \"R_ch_profile\"),\n",
    "                \"V_max_profile\":    _read_field(f, \"V_max_profile\"),\n",
    "                \"V_min_profile\":    _read_field(f, \"V_min_profile\"),\n",
    "                \"Cap_Nom\":          _read_field(f, \"Cap_Nom\"),\n",
    "                \"t_exp\":            _read_field(f, \"t_exp\"),\n",
    "            }\n",
    "        return data\n",
    "\n",
    "    def compute_global_time_percentiles_local(train_files):\n",
    "        elapsed_pool = []\n",
    "        dt_pool = []\n",
    "        for fn in train_files:\n",
    "            d = load_mat_local(fn)\n",
    "            t = d[\"Time_s_p\"].astype(np.float64).flatten()\n",
    "            if t.size == 0: \n",
    "                continue\n",
    "            elapsed = t - t[0]\n",
    "            dt = np.diff(t, prepend=t[0])\n",
    "            elapsed_pool.append(elapsed)\n",
    "            if dt.size > 1: \n",
    "                dt_pool.append(dt[1:])\n",
    "        elapsed_all = np.concatenate(elapsed_pool) if elapsed_pool else np.array([1.0])\n",
    "        dt_all = np.concatenate(dt_pool) if dt_pool else np.array([1.0])\n",
    "        p95_t = float(np.percentile(elapsed_all, 95))\n",
    "        p95_dt = float(np.percentile(dt_all, 95))\n",
    "        return p95_t, p95_dt\n",
    "\n",
    "    def _make_time_channels_np(Time_s, p95_t_in, p95_dt_in):\n",
    "        t = np.asarray(Time_s, np.float64).flatten()\n",
    "        elapsed = t - t[0]\n",
    "        dt = np.diff(t, prepend=t[0])\n",
    "        t_abs_norm = np.clip(elapsed / max(p95_t_in,  1e-12), 0.0, 4.0)\n",
    "        dt_norm    = np.clip(dt      / max(p95_dt_in, 1e-12), 0.0, 4.0)\n",
    "        return t_abs_norm.astype(np.float64), dt_norm.astype(np.float64)\n",
    "\n",
    "    def _positive_deltas_scaled_np(Q_norm, scale_delta_in):\n",
    "        Q_norm = np.asarray(Q_norm, np.float64).flatten()\n",
    "        if Q_norm.size < 2: \n",
    "            return np.zeros(0, np.float64)\n",
    "        dq_norm = np.maximum(Q_norm[1:] - Q_norm[:-1], 0.0)\n",
    "        dq_scaled = dq_norm * scale_delta_in\n",
    "        return dq_scaled.astype(np.float64)\n",
    "\n",
    "    def _window_count(N, T, s):\n",
    "        return int(max(0, (N - T) // s + 1))\n",
    "\n",
    "    def load_numpy_series_local(file_name, p95_t_in, p95_dt_in, scale_delta_in, t_min_in, t_max_in):\n",
    "        d = load_mat_local(file_name)\n",
    "        SOC = np.asarray(d[\"SOC_p\"], np.float64).flatten()\n",
    "        V   = np.asarray(d[\"V_cum_p\"], np.float64).flatten()\n",
    "        T   = np.asarray(d[\"Temp_cum_p\"], np.float64).flatten()\n",
    "        Cr  = np.asarray(d[\"C_rate_profile\"], np.float64).flatten()\n",
    "        t_s = np.asarray(d[\"Time_s_p\"], np.float64).flatten()\n",
    "\n",
    "        Bat = float(np.asarray(d[\"Bat_cap_profile\"]).reshape(-1)[0])\n",
    "        Rch = float(np.asarray(d[\"R_ch_profile\"]).reshape(-1)[0])\n",
    "        Vmx = float(np.asarray(d[\"V_max_profile\"]).reshape(-1)[0])\n",
    "        Vmn = float(np.asarray(d[\"V_min_profile\"]).reshape(-1)[0])\n",
    "        Cap_Nom = float(np.asarray(d[\"Cap_Nom\"]).reshape(-1)[0]) if \"Cap_Nom\" in d else 1.0\n",
    "\n",
    "        Qe_norm = np.asarray(d[\"Q_exp_p\"], np.float64).flatten()\n",
    "        Qp_norm = np.asarray(d[\"Q_total_p\"], np.float64).flatten()\n",
    "\n",
    "        t_abs_norm, dt_norm = _make_time_channels_np(t_s, p95_t_in, p95_dt_in)\n",
    "        V_norm = np.clip((V - Vmn) / max(Vmx - Vmn, 1e-6), -1.0, 2.0)\n",
    "        T_norm = np.clip((T - t_min_in) / (t_max_in - t_min_in), -1.0, 2.0)\n",
    "\n",
    "        N = min(SOC.size, V_norm.size, T_norm.size, Cr.size, t_abs_norm.size, dt_norm.size)\n",
    "\n",
    "        return {\n",
    "            \"SOC\": SOC[:N],\n",
    "            \"V_norm\": V_norm[:N],\n",
    "            \"T_norm\": T_norm[:N],\n",
    "            \"Cr\": Cr[:N],\n",
    "            \"t_abs_norm\": t_abs_norm[:N],\n",
    "            \"dt_norm\": dt_norm[:N],\n",
    "            \"static\": np.array([Bat, Rch, Vmx, Vmn], dtype=np.float32),\n",
    "            \"Cap_Nom\": Cap_Nom,\n",
    "            \"Q_exp_norm\": Qe_norm,\n",
    "            \"Q_total_norm\": Qp_norm,\n",
    "            \"dq_exp_scaled\": _positive_deltas_scaled_np(Qe_norm, scale_delta_in),\n",
    "            \"dq_pb_scaled\":  _positive_deltas_scaled_np(Qp_norm, scale_delta_in),\n",
    "            \"N\": N\n",
    "        }\n",
    "\n",
    "    # --- Re-compute p95_t/dt locally ---\n",
    "    print(\"Calculating local time percentiles (p95_t, p95_dt)...\")\n",
    "    local_p95_t, local_p95_dt = compute_global_time_percentiles_local(TRAIN_FILES)\n",
    "    local_scale_delta = SCALE_DELTA\n",
    "    local_t_min = T_MIN\n",
    "    local_t_max = T_MAX\n",
    "    print(f\"  p95_t={local_p95_t:.4e}, p95_dt={local_p95_dt:.4e}\")\n",
    "\n",
    "    # Lists to hold all windows from all groups\n",
    "    all_X_dyn  = []\n",
    "    all_X_st   = []\n",
    "    all_X_gid  = []\n",
    "    all_y      = []\n",
    "    all_sample_weights = [] # ‚≠êÔ∏è NEW: To hold sample weights\n",
    "\n",
    "    # --- ‚≠êÔ∏è MODIFIED: Find group sizes for weighting (was Pass 1.5a) ---\n",
    "    print(\"\\n--- Pass 1.5a: Finding group sizes for weighting ---\")\n",
    "    group_window_counts = {}\n",
    "    for group_name, file_list in TRAIN_GROUPS.items():\n",
    "        if not file_list:\n",
    "            continue\n",
    "        group_windows = 0\n",
    "        for fn in file_list:\n",
    "            try:\n",
    "                p = load_numpy_series_local(fn, local_p95_t, local_p95_dt,\n",
    "                                            local_scale_delta, local_t_min, local_t_max)\n",
    "                group_windows += _window_count(p[\"N\"], window_size, stride)\n",
    "            except Exception as e:\n",
    "                print(f\"  (Warning: could not peek {fn}: {e})\")\n",
    "        print(f\"  Group '{group_name}' has {group_windows:,} windows.\")\n",
    "        group_window_counts[group_name] = group_windows\n",
    "    \n",
    "    # --- ‚≠êÔ∏è NEW: Calculate sample weights ---\n",
    "    total_windows_unbalanced = sum(group_window_counts.values())\n",
    "    num_groups = len(group_window_counts)\n",
    "    # This is the \"ideal\" number of windows per group if everything was balanced\n",
    "    ideal_size = total_windows_unbalanced / max(num_groups, 1) \n",
    "    group_sample_weights = {}\n",
    "    print(\"\\n--- Calculating Sample Weights ---\")\n",
    "    for group_name, count in group_window_counts.items():\n",
    "        # Weight = (ideal size) / (actual size)\n",
    "        # A rare group (small count) gets a high weight > 1.0\n",
    "        # A common group (large count) gets a low weight < 1.0\n",
    "        weight = ideal_size / max(count, 1) \n",
    "        group_sample_weights[group_name] = weight\n",
    "        print(f\"  Group '{group_name}' (count={count:,}): weight = {weight:.4f}\")\n",
    "    # --- END NEW ---\n",
    "\n",
    "    print(\"\\n--- Pass 1.5b: Processing and all groups (NO oversampling) ---\")\n",
    "    for group_name, file_list in TRAIN_GROUPS.items():\n",
    "        if not file_list:\n",
    "            continue\n",
    "\n",
    "        group_id = GROUP_TO_ID_MAP[group_name]\n",
    "        # --- ‚≠êÔ∏è NEW: Get the weight for this group ---\n",
    "        sample_weight = group_sample_weights.get(group_name, 1.0) # Default to 1.0 if missing\n",
    "        \n",
    "        scaler_path = os.path.join(\"scalers\", f\"delta_scaler_{group_name}.pkl\")\n",
    "        delta_scaler_group = joblib.load(scaler_path)\n",
    "        print(f\"\\nProcessing Group: {group_name} (ID={group_id})\")\n",
    "\n",
    "        group_X_dyn, group_X_st, group_X_gid, group_y = [], [], [], []\n",
    "\n",
    "        for fn in tqdm(file_list, desc=f\"  Files for {group_name}\"):\n",
    "            try:\n",
    "                p = load_numpy_series_local(fn, local_p95_t, local_p95_dt,\n",
    "                                            local_scale_delta, local_t_min, local_t_max)\n",
    "                if p[\"N\"] < window_size:\n",
    "                    continue\n",
    "\n",
    "                # (Data prep is the same)\n",
    "                rows6 = np.stack(\n",
    "                    [p[\"SOC\"], p[\"V_norm\"], p[\"T_norm\"],\n",
    "                     p[\"t_abs_norm\"], p[\"dt_norm\"], p[\"Cr\"]],\n",
    "                    axis=1\n",
    "                )\n",
    "                rows7_placeholder = np.concatenate(\n",
    "                    [rows6, np.zeros((rows6.shape[0], 1), np.float64)],\n",
    "                    axis=1\n",
    "                )\n",
    "                rows_scaled = feature_scaler.transform(rows7_placeholder).astype(np.float32)[:, :6]\n",
    "                win_pos = np.linspace(0, 1, window_size, dtype=np.float32).reshape(-1, 1)\n",
    "                static_raw = np.array(p[\"static\"], dtype=np.float32).reshape(1, -1)\n",
    "                static_scaled = static_scaler.transform(static_raw).astype(np.float32)[0]\n",
    "                dq_exp_raw = p[\"dq_exp_scaled\"]\n",
    "                dq_pb_raw  = p[\"dq_pb_scaled\"]\n",
    "\n",
    "                for end in range(window_size, p[\"N\"], stride):\n",
    "                    sl = slice(end - window_size, end)\n",
    "                    w6 = rows_scaled[sl, :]\n",
    "                    w7 = np.concatenate([w6, win_pos], axis=1)\n",
    "                    group_X_dyn.append(w7)\n",
    "                    group_X_st.append(static_scaled)\n",
    "                    group_X_gid.append([group_id])\n",
    "\n",
    "                    idx_end = end - 1\n",
    "                    y0 = delta_scaler_group.transform([dq_exp_raw[idx_end]])[0, 0] if idx_end < dq_exp_raw.size else 0.0\n",
    "                    y1 = delta_scaler_group.transform([dq_pb_raw[idx_end]])[0, 0] if idx_end < dq_pb_raw.size else 0.0\n",
    "                    group_y.append([y0, y1])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n  WARNING: Skipping file {fn} due to error: {e}\")\n",
    "\n",
    "        num_created = len(group_X_dyn)\n",
    "        if num_created == 0:\n",
    "            print(\"  No windows created for this group. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # --- ‚≠êÔ∏è MODIFIED: Create a parallel list of weights ---\n",
    "        group_weights_list = [sample_weight] * num_created\n",
    "        print(f\"  Created {num_created:,} windows (weight: {sample_weight:.4f}).\")\n",
    "\n",
    "        # --- ‚≠êÔ∏è MODIFIED: Append arrays directly (NO OVERSAMPLING) ---\n",
    "        all_X_dyn.append(np.asarray(group_X_dyn, dtype=np.float32))\n",
    "        all_X_st.append(np.asarray(group_X_st, dtype=np.float32))\n",
    "        all_X_gid.append(np.asarray(group_X_gid, dtype=np.int32))\n",
    "        all_y.append(np.asarray(group_y, dtype=np.float32))\n",
    "        all_sample_weights.append(np.asarray(group_weights_list, dtype=np.float32))\n",
    "\n",
    "    print(f\"\\n--- ‚úÖ Pre-processing complete ---\")\n",
    "    print(\"Converting to numpy arrays...\")\n",
    "\n",
    "    X_train_dyn = np.concatenate(all_X_dyn, axis=0)\n",
    "    X_train_st  = np.concatenate(all_X_st, axis=0)\n",
    "    X_train_gid = np.concatenate(all_X_gid, axis=0)\n",
    "    y_train     = np.concatenate(all_y, axis=0)\n",
    "    # --- ‚≠êÔ∏è NEW: Concatenate weights ---\n",
    "    train_sample_weights = np.concatenate(all_sample_weights, axis=0)\n",
    "\n",
    "    total_windows = X_train_dyn.shape[0]\n",
    "    print(f\"Total windows generated (unbalanced): {total_windows:,}\")\n",
    "    print(f\"X_dyn shape: {X_train_dyn.shape}\")\n",
    "    print(f\"X_st shape:  {X_train_st.shape}\")\n",
    "    print(f\"X_gid shape: {X_train_gid.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    print(f\"weights shape: {train_sample_weights.shape}\") # ‚≠êÔ∏è NEW\n",
    "\n",
    "    print(\"Generating and applying global shuffle...\")\n",
    "    indices = np.arange(total_windows)\n",
    "    np.random.seed(SEED)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    X_train_dyn = X_train_dyn[indices]\n",
    "    X_train_st  = X_train_st[indices]\n",
    "    X_train_gid = X_train_gid[indices]\n",
    "    y_train     = y_train[indices]\n",
    "    train_sample_weights = train_sample_weights[indices] # ‚≠êÔ∏è NEW: Shuffle weights too\n",
    "\n",
    "    print(\"--- üî¨ Verifying Shuffle ---\")\n",
    "    unique, counts = np.unique(X_train_gid[:1000], return_counts=True)\n",
    "    print(f\"Group mix in first 1000 samples (unbalanced is OK): {dict(zip(unique, counts))}\")\n",
    "    if total_windows > 0 and len(unique) > 1:\n",
    "        print(\"‚úÖ Shuffle is successful.\")\n",
    "    else:\n",
    "        print(\"‚ùå SHUFFLE FAILED. Check warnings above.\")\n",
    "\n",
    "    # Set globals\n",
    "    globals()[\"X_train_dyn\"] = X_train_dyn\n",
    "    globals()[\"X_train_st\"]  = X_train_st\n",
    "    globals()[\"X_train_gid\"] = X_train_gid\n",
    "    globals()[\"y_train\"]     = y_train\n",
    "    globals()[\"train_sample_weights\"] = train_sample_weights # ‚≠êÔ∏è NEW\n",
    "\n",
    "    print(\"\\n‚úÖ build_training_arrays() complete with sample weights.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6805055e-b343-48a2-a401-462b3bac70fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# Cell 5a ‚Äî Training Setup + train_one_model helper\n",
    "# ==========================================================\n",
    "import os, csv, math, json, random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import mixed_precision\n",
    "import joblib\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Load globals (unchanged) ---\n",
    "feature_scaler = joblib.load(os.path.join(\"scalers\", \"feature_scaler.pkl\"))\n",
    "static_scaler  = joblib.load(os.path.join(\"scalers\", \"static_scaler.pkl\"))\n",
    "with open(os.path.join(\"scalers\", \"time_stats.json\"), \"r\") as f:\n",
    "    time_stats = json.load(f)\n",
    "P95_T  = float(time_stats[\"p95_t\"])\n",
    "P95_DT = float(time_stats[\"p95_dt\"])\n",
    "T_MIN = 10.0\n",
    "T_MAX = 50.0\n",
    "\n",
    "# --- Loss (unchanged) ---\n",
    "def pitm_delta_loss_mp(lambda_data=LAMBDA_DATA, lambda_phys=LAMBDA_PHYS,\n",
    "                       lambda_zero=LAMBDA_ZERO, huber_delta=HUBER_DELTA):\n",
    "    @tf.function\n",
    "    def huber(e, delta):\n",
    "        e = tf.cast(e, tf.float32)\n",
    "        delta = tf.cast(delta, tf.float32)\n",
    "        a = tf.abs(e)\n",
    "        return tf.where(a <= delta, 0.5 * tf.square(e),\n",
    "                        delta * (a - 0.5 * delta))\n",
    "    @tf.function\n",
    "    def _loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        dq_exp = y_true[:, 0:1]\n",
    "        dq_pb  = y_true[:, 1:2]\n",
    "        dq_hat = y_pred\n",
    "        pos_mask  = tf.cast(tf.logical_or(dq_exp > 0.0, dq_pb > 0.0), tf.float32)\n",
    "        zero_mask = 1.0 - pos_mask\n",
    "        l_data = tf.reduce_mean(huber(dq_exp - dq_hat, huber_delta))\n",
    "        l_phys = tf.reduce_mean(huber(dq_pb  - dq_hat, huber_delta))\n",
    "        l_zero = tf.reduce_mean(zero_mask * dq_hat)\n",
    "        return tf.cast(lambda_data*l_data + lambda_phys*l_phys + lambda_zero*l_zero,\n",
    "                       tf.float32)\n",
    "    return _loss\n",
    "\n",
    "loss_fn = pitm_delta_loss_mp()\n",
    "\n",
    "# --- Validation/Test pipeline (unchanged) ---\n",
    "def _make_time_channels_np(Time_s):\n",
    "    t = np.asarray(Time_s, np.float64).flatten()\n",
    "    elapsed = t - t[0]\n",
    "    dt = np.diff(t, prepend=t[0])\n",
    "    t_abs_norm = np.clip(elapsed / max(P95_T,  1e-12), 0.0, 4.0)\n",
    "    dt_norm    = np.clip(dt      / max(P95_DT, 1e-12), 0.0, 4.0)\n",
    "    return t_abs_norm.astype(np.float64), dt_norm.astype(np.float64)\n",
    "\n",
    "def _positive_deltas_scaled_np(Q_norm):\n",
    "    Q_norm = np.asarray(Q_norm, np.float64).flatten()\n",
    "    if Q_norm.size < 2:\n",
    "        return np.zeros(0, np.float64)\n",
    "    dq_norm   = np.maximum(Q_norm[1:] - Q_norm[:-1], 0.0)\n",
    "    dq_scaled = dq_norm * SCALE_DELTA\n",
    "    return dq_scaled.astype(np.float64)\n",
    "\n",
    "def _window_count(N, T, s):\n",
    "    return int(max(0, (N - T) // s + 1))\n",
    "\n",
    "def load_numpy_series(file_name):\n",
    "    d   = load_mat(file_name)\n",
    "    SOC = np.asarray(d[\"SOC_p\"], np.float64).flatten()\n",
    "    V   = np.asarray(d[\"V_cum_p\"], np.float64).flatten()\n",
    "    T   = np.asarray(d[\"Temp_cum_p\"], np.float64).flatten()\n",
    "    Cr  = np.asarray(d[\"C_rate_profile\"], np.float64).flatten()\n",
    "    t_s = np.asarray(d[\"Time_s_p\"], np.float64).flatten()\n",
    "\n",
    "    Bat = float(np.asarray(d[\"Bat_cap_profile\"]).reshape(-1)[0])\n",
    "    Rch = float(np.asarray(d[\"R_ch_profile\"]).reshape(-1)[0])\n",
    "    Vmx = float(np.asarray(d[\"V_max_profile\"]).reshape(-1)[0])\n",
    "    Vmn = float(np.asarray(d[\"V_min_profile\"]).reshape(-1)[0])\n",
    "    Cap_Nom = float(np.asarray(d[\"Cap_Nom\"]).reshape(-1)[0]) if \"Cap_Nom\" in d else 1.0\n",
    "\n",
    "    Qe_norm = np.asarray(d[\"Q_exp_p\"], np.float64).flatten()\n",
    "    Qp_norm = np.asarray(d[\"Q_total_p\"], np.float64).flatten()\n",
    "\n",
    "    t_abs_norm, dt_norm = _make_time_channels_np(t_s)\n",
    "    V_norm = np.clip((V - Vmn) / max(Vmx - Vmn, 1e-6), -1.0, 2.0)\n",
    "    T_norm = np.clip((T - T_MIN) / (T_MAX - T_MIN), -1.0, 2.0)\n",
    "\n",
    "    N = min(SOC.size, V_norm.size, T_norm.size,\n",
    "            Cr.size, t_abs_norm.size, dt_norm.size)\n",
    "\n",
    "    return {\n",
    "        \"SOC\": SOC[:N],\n",
    "        \"V_norm\": V_norm[:N],\n",
    "        \"T_norm\": T_norm[:N],\n",
    "        \"Cr\": Cr[:N],\n",
    "        \"t_abs_norm\": t_abs_norm[:N],\n",
    "        \"dt_norm\": dt_norm[:N],\n",
    "        \"static\": np.array([Bat, Rch, Vmx, Vmn], dtype=np.float32),\n",
    "        \"Cap_Nom\": Cap_Nom,\n",
    "        \"Q_exp_norm\": Qe_norm,\n",
    "        \"Q_total_norm\": Qp_norm,\n",
    "        \"dq_exp_scaled\": _positive_deltas_scaled_np(Qe_norm),\n",
    "        \"dq_pb_scaled\":  _positive_deltas_scaled_np(Qp_norm),\n",
    "        \"N\": N\n",
    "    }\n",
    "\n",
    "def stream_windows_from_files(file_list, window_size, stride,\n",
    "                              need_targets=True, shuffle=True,\n",
    "                              infinite=False, batch_size=128, seed=None):\n",
    "    delta_scaler_group = None\n",
    "    group_id = -1\n",
    "    group_name = \"\"\n",
    "\n",
    "    if file_list:\n",
    "        fn_first = file_list[0]\n",
    "        if fn_first in FILE_TO_GROUP_MAP:\n",
    "            group_name = FILE_TO_GROUP_MAP[fn_first]\n",
    "            if group_name in GROUP_TO_ID_MAP:\n",
    "                group_id = GROUP_TO_ID_MAP[group_name]\n",
    "            else:\n",
    "                print(f\"FATAL: (stream) Group '{group_name}' not in GROUP_TO_ID_MAP.\")\n",
    "                return\n",
    "            scaler_path = os.path.join(\"scalers\", f\"delta_scaler_{group_name}.pkl\")\n",
    "            try:\n",
    "                delta_scaler_group = joblib.load(scaler_path)\n",
    "            except Exception as e:\n",
    "                print(f\"FATAL: (stream) Could not load scaler at {scaler_path}: {e}\")\n",
    "                return\n",
    "        else:\n",
    "            print(f\"FATAL: (stream) File {fn_first} not in FILE_TO_GROUP_MAP.\")\n",
    "            return\n",
    "\n",
    "    if delta_scaler_group is None and need_targets:\n",
    "        print(f\"FATAL: (stream) No delta_scaler could be loaded.\")\n",
    "        return\n",
    "\n",
    "    rng = random.Random(seed)\n",
    "    meta = []\n",
    "    for fn in file_list:\n",
    "        p = load_numpy_series(fn)\n",
    "        n_win = _window_count(p[\"N\"], window_size, stride)\n",
    "        if n_win > 0:\n",
    "            meta.append((fn, n_win))\n",
    "\n",
    "    total_windows = int(sum(n for _, n in meta))\n",
    "    steps_per_epoch = int(math.ceil(total_windows / batch_size))\n",
    "    print(f\"  ‚Üí STREAM: {len(meta)} files, {total_windows:,} windows (Group: '{group_name}', ID: {group_id})\")\n",
    "\n",
    "    def one_pass_yield():\n",
    "        series = []\n",
    "\n",
    "        def _grab1(x, default=0.0):\n",
    "            arr = np.asarray(x).reshape(-1)\n",
    "            return float(arr[0]) if arr.size else default\n",
    "\n",
    "        file_order = meta\n",
    "        if shuffle:\n",
    "            file_order = rng.sample(meta, k=len(meta))\n",
    "\n",
    "        for fn, _ in file_order:\n",
    "            p = load_numpy_series(fn)\n",
    "            if (\"dq_exp_scaled\" not in p) or (\"dq_pb_scaled\" not in p):\n",
    "                dmat = load_mat(fn)\n",
    "                Qe_norm = np.asarray(dmat[\"Q_exp_p\"], np.float64).flatten()\n",
    "                Qp_norm = np.asarray(dmat[\"Q_total_p\"], np.float64).flatten()\n",
    "                p[\"dq_exp_scaled\"] = _positive_deltas_scaled_np(Qe_norm)\n",
    "                p[\"dq_pb_scaled\"]  = _positive_deltas_scaled_np(Qp_norm)\n",
    "            if \"static\" not in p:\n",
    "                dmat = dmat if \"dmat\" in locals() else load_mat(fn)\n",
    "                p[\"static\"] = np.array([\n",
    "                    _grab1(dmat[\"Bat_cap_profile\"]),\n",
    "                    _grab1(dmat[\"R_ch_profile\"]),\n",
    "                    _grab1(dmat[\"V_max_profile\"]),\n",
    "                    _grab1(dmat[\"V_min_profile\"])\n",
    "                ], dtype=np.float32)\n",
    "\n",
    "            rows6 = np.stack(\n",
    "                [p[\"SOC\"], p[\"V_norm\"], p[\"T_norm\"],\n",
    "                 p[\"t_abs_norm\"], p[\"dt_norm\"], p[\"Cr\"]],\n",
    "                axis=1\n",
    "            )\n",
    "            rows7_placeholder = np.concatenate(\n",
    "                [rows6, np.zeros((rows6.shape[0], 1), np.float64)],\n",
    "                axis=1\n",
    "            )\n",
    "            rows_scaled = feature_scaler.transform(rows7_placeholder).astype(np.float32)[:, :6]\n",
    "            win_pos = np.linspace(0, 1, window_size, dtype=np.float32).reshape(-1, 1)\n",
    "\n",
    "            static_raw = np.array(p[\"static\"], dtype=np.float32).reshape(1, -1)\n",
    "            static_scaled = static_scaler.transform(static_raw).astype(np.float32)[0]\n",
    "\n",
    "            series.append({\n",
    "                \"p\": p,\n",
    "                \"rows\": rows_scaled,\n",
    "                \"win_pos\": win_pos,\n",
    "                \"static_scaled\": static_scaled,\n",
    "                \"i\": window_size,\n",
    "                \"n\": p[\"N\"],\n",
    "                \"done\": False\n",
    "            })\n",
    "\n",
    "        X_dyn_batch, X_st_batch, X_id_batch = [], [], []\n",
    "        Y_batch = [] if need_targets else None\n",
    "        alive = sum(1 for b in series if not b[\"done\"])\n",
    "\n",
    "        while alive > 0:\n",
    "            for b in series:\n",
    "                if b[\"done\"]:\n",
    "                    continue\n",
    "                end = b[\"i\"]\n",
    "                if end > b[\"n\"]:\n",
    "                    b[\"done\"] = True\n",
    "                    continue\n",
    "                sl = slice(end - window_size, end)\n",
    "                w6 = b[\"rows\"][sl, :]\n",
    "                w7 = np.concatenate([w6, b[\"win_pos\"]], axis=1)\n",
    "\n",
    "                X_dyn_batch.append(w7)\n",
    "                X_st_batch.append(b[\"static_scaled\"])\n",
    "                X_id_batch.append(group_id)\n",
    "\n",
    "                if need_targets:\n",
    "                    idx_end = end - 1\n",
    "                    p = b[\"p\"]\n",
    "                    y0 = delta_scaler_group.transform([p[\"dq_exp_scaled\"][idx_end]])[0, 0] if idx_end < p[\"dq_exp_scaled\"].size else 0.0\n",
    "                    y1 = delta_scaler_group.transform([p[\"dq_pb_scaled\"][idx_end]])[0, 0] if idx_end < p[\"dq_pb_scaled\"].size else 0.0\n",
    "                    Y_batch.append([y0, y1])\n",
    "\n",
    "                b[\"i\"] += stride\n",
    "\n",
    "                if len(X_dyn_batch) == batch_size:\n",
    "                    X_dyn_arr = np.asarray(X_dyn_batch, np.float32)\n",
    "                    X_st_arr  = np.asarray(X_st_batch,  np.float32)\n",
    "                    X_id_arr  = np.asarray(X_id_batch,  np.int32).reshape(-1, 1)\n",
    "                    if need_targets:\n",
    "                        Y_arr = np.asarray(Y_batch, np.float32)\n",
    "                        Y_arr = np.nan_to_num(Y_arr, nan=0.0, posinf=1e6, neginf=0.0)\n",
    "                        yield (X_dyn_arr, X_st_arr, X_id_arr, Y_arr)\n",
    "                        Y_batch = []\n",
    "                    else:\n",
    "                        yield (X_dyn_arr, X_st_arr, X_id_arr)\n",
    "                    X_dyn_batch, X_st_batch, X_id_batch = [], [], []\n",
    "            alive = sum(1 for b in series if not b[\"done\"])\n",
    "\n",
    "        if len(X_dyn_batch) > 0:\n",
    "            X_dyn_arr = np.asarray(X_dyn_batch, np.float32)\n",
    "            X_st_arr  = np.asarray(X_st_batch,  np.float32)\n",
    "            X_id_arr  = np.asarray(X_id_batch,  np.int32).reshape(-1, 1)\n",
    "            if need_targets:\n",
    "                Y_arr = np.asarray(Y_batch, np.float32)\n",
    "                Y_arr = np.nan_to_num(Y_arr, nan=0.0, posinf=1e6, neginf=0.0)\n",
    "                yield (X_dyn_arr, X_st_arr, X_id_arr, Y_arr)\n",
    "            else:\n",
    "                yield (X_dyn_arr, X_st_arr, X_id_arr)\n",
    "\n",
    "    def gen():\n",
    "        if infinite:\n",
    "            while True:\n",
    "                yield from one_pass_yield()\n",
    "        else:\n",
    "            yield from one_pass_yield()\n",
    "\n",
    "    if need_targets:\n",
    "        output_signature = (\n",
    "            tf.TensorSpec(shape=(None, window_size, 7), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, 4), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, 1), dtype=tf.int32),\n",
    "            tf.TensorSpec(shape=(None, 2), dtype=tf.float32),\n",
    "        )\n",
    "    else:\n",
    "        output_signature = (\n",
    "            tf.TensorSpec(shape=(None, window_size, 7), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, 4), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, 1), dtype=tf.int32),\n",
    "        )\n",
    "\n",
    "    ds = tf.data.Dataset.from_generator(gen, output_signature=output_signature)\n",
    "    if need_targets:\n",
    "        ds = ds.map(lambda dyn, st, gid, y: ((dyn, st, gid), y),\n",
    "                    num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    else:\n",
    "        ds = ds.map(lambda dyn, st, gid: (dyn, st, gid),\n",
    "                    num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    if infinite:\n",
    "        ds = ds.repeat()\n",
    "    ds = ds.prefetch(1)\n",
    "    return ds, steps_per_epoch\n",
    "\n",
    "# --- Validation callback (unchanged) ---\n",
    "BEST_CKPT = \"\"\n",
    "CSV_PATH = \"\"\n",
    "\n",
    "class MacroValStream(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, val_files, window_size, stride, freq=VAL_FREQ):\n",
    "        super().__init__()\n",
    "        self.val_files = val_files\n",
    "        self.freq = freq\n",
    "        self.best = np.inf\n",
    "        self.wait = 0\n",
    "        self.lr_wait = 0\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        ep = epoch + 1\n",
    "        train_loss = float(logs.get(\"loss\", np.nan))\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        global CSV_PATH\n",
    "\n",
    "        if ep % self.freq != 0:\n",
    "            if CSV_PATH:\n",
    "                with open(CSV_PATH, \"a\", newline=\"\") as f:\n",
    "                    csv.writer(f).writerow([ep, f\"{train_loss:.6f}\", \"\", f\"{lr:.6g}\"])\n",
    "            return\n",
    "\n",
    "        per_cell = []\n",
    "        num_gpus = max(1, len(tf.config.list_physical_devices(\"GPU\")))\n",
    "        GLOBAL_BATCH = BATCH_PER_DEVICE * num_gpus\n",
    "        for fn in self.val_files:\n",
    "            ds_cell, steps = stream_windows_from_files(\n",
    "                [fn],\n",
    "                window_size=self.window_size,\n",
    "                stride=self.stride,\n",
    "                need_targets=True,\n",
    "                shuffle=False,\n",
    "                infinite=False,\n",
    "                batch_size=int(GLOBAL_BATCH),\n",
    "                seed=SEED\n",
    "            )\n",
    "            loss = float(self.model.evaluate(ds_cell, steps=steps, verbose=0))\n",
    "            per_cell.append(loss)\n",
    "\n",
    "        macro = float(np.mean(per_cell)) if per_cell else np.nan\n",
    "        print(f\"\\n[Val @ epoch {ep}] macro={macro:.6f}  (per-cell: {', '.join(f'{x:.4f}' for x in per_cell)})\")\n",
    "        logs['val_loss_macro'] = macro\n",
    "\n",
    "        global BEST_CKPT\n",
    "        if BEST_CKPT:\n",
    "            if macro < self.best:\n",
    "                self.best = macro\n",
    "                self.wait = 0\n",
    "                self.lr_wait = 0\n",
    "                self.model.save(BEST_CKPT)\n",
    "                print(f\"  ‚úì Saved BEST checkpoint ‚Üí {BEST_CKPT}\")\n",
    "            else:\n",
    "                self.wait += 1\n",
    "                self.lr_wait += 1\n",
    "                if self.lr_wait >= LR_PATIENCE:\n",
    "                    new_lr = max(lr * LR_FACTOR, LR_MIN)\n",
    "                    tf.keras.backend.set_value(self.model.optimizer.learning_rate, new_lr)\n",
    "                    print(f\"  ‚Üí LR reduced: {lr:.6g} ‚Üí {new_lr:.6g}\")\n",
    "                    self.lr_wait = 0\n",
    "                if self.wait >= EARLY_STOP_PATIENCE:\n",
    "                    print(\"  ‚Üí Early stopping.\")\n",
    "                    self.model.stop_training = True\n",
    "\n",
    "        if CSV_PATH:\n",
    "            with open(CSV_PATH, \"a\", newline=\"\") as f:\n",
    "                csv.writer(f).writerow([ep, f\"{train_loss:.6f}\", f\"{macro:.6f}\", f\"{lr:.6g}\"])\n",
    "\n",
    "# --- LivePlotCallback (unchanged) ---\n",
    "class LivePlotCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, val_freq=1):\n",
    "        super().__init__()\n",
    "        self.val_freq = val_freq\n",
    "        self.history = {'loss': [], 'val_loss_macro': []}\n",
    "        self.best_val_loss = np.inf\n",
    "        self.best_val_epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.history['loss'].append(logs.get('loss'))\n",
    "        if 'val_loss_macro' in logs:\n",
    "            val_loss = logs.get('val_loss_macro')\n",
    "            self.history['val_loss_macro'].append(val_loss)\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.best_val_epoch = epoch + 1\n",
    "        else:\n",
    "            self.history['val_loss_macro'].append(np.nan)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        epochs_ran = range(1, len(self.history['loss']) + 1)\n",
    "\n",
    "        ax1.plot(epochs_ran, self.history['loss'], label='Training Loss')\n",
    "        ax1.set_title('Training Loss per Epoch')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "        val_loss_clean = [v if not np.isnan(v) else None for v in self.history['val_loss_macro']]\n",
    "        ax2.plot(epochs_ran, val_loss_clean,\n",
    "                 label='Macro Validation Loss', marker='o', linestyle='--')\n",
    "        if self.best_val_epoch > 0:\n",
    "            ax2.scatter(self.best_val_epoch, self.best_val_loss,\n",
    "                        s=100, zorder=5, label=f\"Best: {self.best_val_loss:.4f} at Epoch {self.best_val_epoch}\")\n",
    "        ax2.set_title('Macro Validation Loss per Epoch')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Macro Loss')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# --- ‚≠êÔ∏è MODIFIED: Training dataset from in-memory arrays (with weights) ---\n",
    "def create_balanced_training_dataset(batch_size, seed):\n",
    "    \"\"\"\n",
    "    Create the tf.data training dataset from X_train_dyn/st/gid/y_train\n",
    "    and train_sample_weights.\n",
    "    Assumes build_training_arrays(...) has already been run.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        _ = X_train_dyn\n",
    "        _ = train_sample_weights # ‚≠êÔ∏è NEW: Check for sample weights\n",
    "    except NameError:\n",
    "        print(\"üî• FATAL: Training arrays (X_train_dyn, train_sample_weights, etc.) not found.\")\n",
    "        print(\"Please call build_training_arrays(window_size, stride) *before* this.\")\n",
    "        return None, 0\n",
    "\n",
    "    print(\"--- ‚ö°Ô∏è Creating fast in-memory training dataset (with weights) ---\")\n",
    "    \n",
    "    # ‚≠êÔ∏è MODIFIED: Pass weights as the 3rd element\n",
    "    # (inputs, targets, sample_weights)\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        ((X_train_dyn, X_train_st, X_train_gid), y_train, train_sample_weights)\n",
    "    )\n",
    "\n",
    "    total_windows = X_train_dyn.shape[0]\n",
    "    steps_per_epoch = int(math.ceil(total_windows / batch_size))\n",
    "    print(f\"  Total windows: {total_windows:,}\")\n",
    "    print(f\"  Steps per epoch: {steps_per_epoch:,}\")\n",
    "\n",
    "    SHUFFLE_BUFFER_SIZE = total_windows\n",
    "    \n",
    "    # ‚≠êÔ∏è MODIFIED: The .map is now required to label the 3 parts\n",
    "    # Keras will automatically interpret the 3rd item as sample_weight\n",
    "    train_ds = train_ds.map(\n",
    "        lambda inputs, targets, weights: (inputs, targets, weights),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    \n",
    "    train_ds = train_ds.shuffle(SHUFFLE_BUFFER_SIZE, seed=seed)\n",
    "    train_ds = train_ds.repeat()\n",
    "    train_ds = train_ds.batch(batch_size)\n",
    "    train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    print(\"‚úÖ Training dataset (with sample weights) is ready.\")\n",
    "    return train_ds, steps_per_epoch\n",
    "\n",
    "# --- NEW: unified training function used by main run and random search ---\n",
    "def train_one_model(run_name,\n",
    "                    window_size,\n",
    "                    embed_dim,\n",
    "                    num_layers,\n",
    "                    batch_per_device,\n",
    "                    learning_rate,\n",
    "                    lambda_phys,\n",
    "                    do_plot=True):\n",
    "    \"\"\"\n",
    "    Unified training function.\n",
    "    - Builds training arrays for the given window_size (now with weights)\n",
    "    - Creates training & validation datasets\n",
    "    - Builds & compiles the model\n",
    "    - Trains with MacroValStream\n",
    "    - Returns the trained Keras model and history\n",
    "    \"\"\"\n",
    "\n",
    "    global BEST_CKPT, CSV_PATH\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.keras.utils.set_random_seed(SEED)  # fixed seed everywhere\n",
    "\n",
    "    # Mixed precision policy\n",
    "    policy = mixed_precision.Policy('mixed_float16')\n",
    "    mixed_precision.set_global_policy(policy)\n",
    "    print(f\"Mixed precision policy: {mixed_precision.global_policy().name}\")\n",
    "\n",
    "    # Strategy / devices\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    num_gpus = len(gpus)\n",
    "    if num_gpus > 1:\n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "        REPLICAS = strategy.num_replicas_in_sync\n",
    "        print(f\"Using MirroredStrategy across {REPLICAS} replicas.\")\n",
    "    else:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "        REPLICAS = 1\n",
    "        print(\"Using default strategy (1 GPU or CPU).\")\n",
    "\n",
    "    GLOBAL_BATCH = batch_per_device * REPLICAS\n",
    "    print(f\"Batch per device: {batch_per_device} | Global batch: {GLOBAL_BATCH}\")\n",
    "\n",
    "    # ‚≠êÔ∏è This function now builds arrays WITH weights\n",
    "    build_training_arrays(window_size, STRIDE)\n",
    "\n",
    "    # ‚≠êÔ∏è This function now creates a dataset WITH weights\n",
    "    train_ds, train_steps = create_balanced_training_dataset(\n",
    "        batch_size=GLOBAL_BATCH,\n",
    "        seed=SEED\n",
    "    )\n",
    "    if train_ds is None:\n",
    "        raise RuntimeError(\"Failed to create training dataset.\")\n",
    "\n",
    "    # Validation dataset (unchanged, doesn't need weights)\n",
    "    val_ds, val_steps = stream_windows_from_files(\n",
    "        VAL_FILES,\n",
    "        window_size=window_size,\n",
    "        stride=STRIDE,\n",
    "        need_targets=True,\n",
    "        shuffle=False,\n",
    "        infinite=False,\n",
    "        batch_size=GLOBAL_BATCH,\n",
    "        seed=SEED\n",
    "    )\n",
    "\n",
    "    # Sharding options\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "    train_ds = train_ds.with_options(options)\n",
    "    val_ds   = val_ds.with_options(options)\n",
    "\n",
    "    # Paths for this run\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "    os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "    if run_name == \"main_pitm\":\n",
    "        CSV_PATH  = os.path.join(\"logs\", \"train_val.csv\")\n",
    "        BEST_CKPT = os.path.join(\"checkpoints\", \"main_pitm_best_macro.h5\")\n",
    "    else:\n",
    "        CSV_PATH  = os.path.join(\"logs\", f\"train_val_{run_name}.csv\")\n",
    "        BEST_CKPT = os.path.join(\"checkpoints\", f\"{run_name}_best.h5\")\n",
    "\n",
    "    if os.path.exists(CSV_PATH):\n",
    "        os.remove(CSV_PATH)\n",
    "    with open(CSV_PATH, \"w\", newline=\"\") as f:\n",
    "        csv.writer(f).writerow([\"epoch\", \"loss\", \"val_loss_macro\", \"lr\"])\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        MacroValStream(VAL_FILES, window_size=window_size,\n",
    "                       stride=STRIDE, freq=VAL_FREQ),\n",
    "        tf.keras.callbacks.TerminateOnNaN()\n",
    "    ]\n",
    "    if do_plot:\n",
    "        callbacks.insert(1, LivePlotCallback(val_freq=VAL_FREQ))\n",
    "\n",
    "    # Build & compile model\n",
    "    with strategy.scope():\n",
    "        model = build_pitm_model(\n",
    "            window_size=window_size,\n",
    "            num_groups=NUM_GROUPS,\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=NUM_HEADS,\n",
    "            ff_dim=FF_DIM,\n",
    "            num_layers=num_layers,\n",
    "            dropout=DROPOUT # This uses the value from Cell 3\n",
    "        )\n",
    "\n",
    "        loss_fn_local = pitm_delta_loss_mp(\n",
    "            lambda_data=LAMBDA_DATA,\n",
    "            lambda_phys=lambda_phys,\n",
    "            lambda_zero=LAMBDA_ZERO,\n",
    "            huber_delta=HUBER_DELTA\n",
    "        )\n",
    "\n",
    "        optimizer = Adam(\n",
    "            learning_rate=learning_rate,\n",
    "            amsgrad=AMSGRAD,\n",
    "            clipnorm=CLIPNORM\n",
    "        )\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss=loss_fn_local)\n",
    "\n",
    "    print(f\"\\nStarting training for {EPOCHS} epochs \"\n",
    "          f\"(train steps/epoch ‚âà {train_steps:,}, batch={GLOBAL_BATCH})\")\n",
    "\n",
    "    # ‚≠êÔ∏è No change needed here. model.fit automatically uses \n",
    "    # the sample weights from the tf.data.Dataset\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=EPOCHS,\n",
    "        steps_per_epoch=train_steps,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=val_ds,\n",
    "        validation_steps=val_steps,\n",
    "        validation_freq=VAL_FREQ\n",
    "    )\n",
    "\n",
    "    print(f\"\\n‚úÖ Training complete for run '{run_name}'. Best checkpoint: {BEST_CKPT}\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1c906c-e423-4ad3-b653-95c60b834092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ======================================\n",
    "# # Cell 5b ‚Äî Main Training Run (uses train_one_model)\n",
    "# # ======================================\n",
    "# import os\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Use hyperparameters from Cell 3\n",
    "# RUN_WINDOW_SIZE = WINDOW_SIZE\n",
    "# RUN_STRIDE      = STRIDE\n",
    "# RUN_EPOCHS      = EPOCHS\n",
    "\n",
    "# # Run the unified training pipeline\n",
    "# run_name = \"main_pitm\"\n",
    "# model, history = train_one_model(\n",
    "#     run_name=run_name,\n",
    "#     window_size=RUN_WINDOW_SIZE,\n",
    "#     embed_dim=EMBED_DIM,\n",
    "#     num_layers=NUM_LAYERS,\n",
    "#     batch_per_device=BATCH_PER_DEVICE,\n",
    "#     learning_rate=LR,\n",
    "#     lambda_phys=LAMBDA_PHYS,\n",
    "#     do_plot=True\n",
    "# )\n",
    "\n",
    "# # Save final weights (optional, as in your original code)\n",
    "# MODEL_WEIGHTS_FINAL = \"checkpoints/main_pitm_final_weights.h5\"\n",
    "# model.save_weights(MODEL_WEIGHTS_FINAL)\n",
    "# print(f\"‚úÖ Saved FINAL run weights ‚Üí {MODEL_WEIGHTS_FINAL}\")\n",
    "# print(f\"Best model was saved to ‚Üí {BEST_CKPT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef6ff0f9-8a29-4060-90ba-7db1b732bcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cell 6a (Group-Conditioned) testing pipeline ready.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Cell 6a ‚Äî Testing Setup (Group-Conditioned) [FIXED]\n",
    "# ==========================================================\n",
    "import os, json, joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----- Load GLOBAL scalers ----\n",
    "# Per-group scalers are loaded inside predict_cell\n",
    "feature_scaler = joblib.load(os.path.join(\"scalers\", \"feature_scaler.pkl\"))\n",
    "static_scaler  = joblib.load(os.path.join(\"scalers\", \"static_scaler.pkl\"))\n",
    "with open(os.path.join(\"scalers\", \"time_stats.json\"), \"r\") as f: time_stats = json.load(f)\n",
    "P95_T  = float(time_stats[\"p95_t\"]); P95_DT = float(time_stats[\"p95_dt\"])\n",
    "T_MIN = 10.0; T_MAX = 50.0\n",
    "\n",
    "# ----- Constants -----\n",
    "PRED_BATCH  = 1024\n",
    "SCALE_DELTA = 1e5 # Make sure this matches Cell 3\n",
    "\n",
    "# ----- ‚≠êÔ∏è FIX 1: Make Cell 6a self-contained ‚≠êÔ∏è -----\n",
    "# This function was missing, forcing Cell 6a to rely on\n",
    "# a global function from Cell 5a, which is fragile.\n",
    "def _make_time_channels_np(Time_s):\n",
    "    t = np.asarray(Time_s, np.float64).flatten(); elapsed = t - t[0]; dt = np.diff(t, prepend=t[0])\n",
    "    # This now correctly uses the P95_T and P95_DT loaded at the top of THIS cell\n",
    "    t_abs_norm = np.clip(elapsed / max(P95_T,  1e-12), 0.0, 4.0)\n",
    "    dt_norm = np.clip(dt / max(P95_DT, 1e-12), 0.0, 4.0)\n",
    "    return t_abs_norm.astype(np.float64), dt_norm.astype(np.float64)\n",
    "# ----- (End of Fix 1) -----\n",
    "\n",
    "\n",
    "# ----- Helpers (unchanged) -----\n",
    "def nearest_indices(ts_dense, t_sparse):\n",
    "    ts = np.asarray(ts_dense, np.float64); te = np.asarray(t_sparse, np.float64); idx = np.searchsorted(ts, te); idx = np.clip(idx, 0, len(ts)-1); left = np.maximum(idx - 1, 0); take_left = (idx > 0) & (np.abs(ts[left] - te) <= np.abs(ts[idx] - te)); idx[take_left] = left[take_left]; return idx\n",
    "\n",
    "\n",
    "# ----- ‚≠êÔ∏è FIX 2: Use the CORRECT version of load_numpy_series ‚≠êÔ∏è -----\n",
    "# The old one in Cell 6a was outdated. This is the correct\n",
    "# one from Cell 5a, which includes the _positive_deltas_scaled_np helper.\n",
    "\n",
    "def _positive_deltas_scaled_np(Q_norm): \n",
    "    \"\"\" Helper just for the function below \"\"\"\n",
    "    Q_norm = np.asarray(Q_norm, np.float64).flatten()\n",
    "    if Q_norm.size < 2: return np.zeros(0, np.float64)\n",
    "    dq_norm = np.maximum(Q_norm[1:] - Q_norm[:-1], 0.0)\n",
    "    dq_scaled = dq_norm * SCALE_DELTA\n",
    "    return dq_scaled.astype(np.float64)\n",
    "\n",
    "def load_numpy_series(file_name):\n",
    "    d = load_mat(file_name); SOC = np.asarray(d[\"SOC_p\"], np.float64).flatten(); V = np.asarray(d[\"V_cum_p\"], np.float64).flatten(); T = np.asarray(d[\"Temp_cum_p\"], np.float64).flatten(); Cr = np.asarray(d[\"C_rate_profile\"], np.float64).flatten(); t_s = np.asarray(d[\"Time_s_p\"], np.float64).flatten()\n",
    "    Bat = float(np.asarray(d[\"Bat_cap_profile\"]).reshape(-1)[0]); Rch = float(np.asarray(d[\"R_ch_profile\"]).reshape(-1)[0]); Vmx = float(np.asarray(d[\"V_max_profile\"]).reshape(-1)[0]); Vmn = float(np.asarray(d[\"V_min_profile\"]).reshape(-1)[0]); Cap_Nom = float(np.asarray(d[\"Cap_Nom\"]).reshape(-1)[0]) if \"Cap_Nom\" in d else 1.0\n",
    "    Qe_norm = np.asarray(d[\"Q_exp_p\"], np.float64).flatten(); Qp_norm = np.asarray(d[\"Q_total_p\"], np.float64).flatten()\n",
    "    \n",
    "    # This call now safely uses the helper from Fix 1\n",
    "    t_abs_norm, dt_norm = _make_time_channels_np(t_s); \n",
    "    \n",
    "    V_norm = np.clip((V - Vmn) / max(Vmx - Vmn, 1e-6), -1.0, 2.0); T_norm = np.clip((T - T_MIN) / (T_MAX - T_MIN), -1.0, 2.0)\n",
    "    N = min(SOC.size, V_norm.size, T_norm.size, Cr.size, t_abs_norm.size, dt_norm.size)\n",
    "    \n",
    "    # This returns the FULL dictionary, including the 'dq_' keys\n",
    "    return { \n",
    "        \"SOC\": SOC[:N], \"V_norm\": V_norm[:N], \"T_norm\": T_norm[:N], \n",
    "        \"Cr\": Cr[:N], \"t_abs_norm\": t_abs_norm[:N], \"dt_norm\": dt_norm[:N], \n",
    "        \"static\": np.array([Bat, Rch, Vmx, Vmn], dtype=np.float32), \n",
    "        \"Cap_Nom\": Cap_Nom, \n",
    "        \"Q_exp_norm\": Qe_norm, \"Q_total_norm\": Qp_norm, \n",
    "        \"dq_exp_scaled\": _positive_deltas_scaled_np(Qe_norm), \n",
    "        \"dq_pb_scaled\":  _positive_deltas_scaled_np(Qp_norm), \n",
    "        \"N\": N \n",
    "    }\n",
    "# ----- (End of Fix 2) -----\n",
    "\n",
    "\n",
    "# --- ‚≠êÔ∏è MODIFIED: predict_cell now finds and passes group_id ‚≠êÔ∏è ---\n",
    "def predict_cell(model, file_name, window_size, stride):\n",
    "    \n",
    "    # --- NEW: Get group_id and per-group scaler ---\n",
    "    delta_scaler_group = None\n",
    "    group_id = -1\n",
    "    group_name = \"\"\n",
    "    if file_name in FILE_TO_GROUP_MAP:\n",
    "        group_name = FILE_TO_GROUP_MAP[file_name]\n",
    "        if group_name in GROUP_TO_ID_MAP:\n",
    "            group_id = GROUP_TO_ID_MAP[group_name]\n",
    "        else:\n",
    "            print(f\"FATAL: (Testing {file_name}) Group '{group_name}' not in GROUP_TO_ID_MAP.\")\n",
    "            return (np.array([]),)*8\n",
    "        \n",
    "        scaler_path = os.path.join(\"scalers\", f\"delta_scaler_{group_name}.pkl\")\n",
    "        try:\n",
    "            delta_scaler_group = joblib.load(scaler_path)\n",
    "            print(f\"  (Testing {file_name}: using '{group_name}' scaler, ID: {group_id})\")\n",
    "        except Exception as e:\n",
    "            print(f\"FATAL: (Testing {file_name}) Could not load scaler at {scaler_path}: {e}\")\n",
    "            return (np.array([]),)*8\n",
    "    else:\n",
    "        print(f\"FATAL: (Testing {file_name}) File not in FILE_TO_GROUP_MAP (Cell 1).\")\n",
    "        return (np.array([]),)*8\n",
    "    # --- END NEW ---\n",
    "    \n",
    "    # (Prepare input data - unchanged)\n",
    "    p = load_numpy_series(file_name) \n",
    "    # --- ‚≠êÔ∏è MODIFICATION: Stack 6 features (SOC, V, T, t, dt, Cr) ---\n",
    "    rows6 = np.stack([p[\"SOC\"], p[\"V_norm\"], p[\"T_norm\"], p[\"t_abs_norm\"], p[\"dt_norm\"], p[\"Cr\"]], axis=1)\n",
    "    # --- ‚≠êÔ∏è MODIFICATION: Placeholder is (N, 7) for scaler ---\n",
    "    rows7_placeholder = np.concatenate([rows6, np.zeros((rows6.shape[0], 1), np.float64)], axis=1)\n",
    "    # --- ‚≠êÔ∏è MODIFICATION: Take first 6 scaled features ---\n",
    "    rows_scaled = feature_scaler.transform(rows7_placeholder).astype(np.float32)[:, :6]\n",
    "    # --- ‚≠êÔ∏è MODIFICATION: cr_seq removed ---\n",
    "    win_pos = np.linspace(0, 1, window_size, dtype=np.float32).reshape(-1, 1); static_vec = p[\"static\"].astype(np.float32).reshape(1, -1)\n",
    "    ends = np.arange(window_size, p[\"N\"] + 1, stride, dtype=np.int64); num = ends.size\n",
    "    if num == 0: return (np.array([]),)*8\n",
    "\n",
    "    # --- ‚≠êÔ∏è MODIFICATION: dyn_win is (N_win, T, 7) ---\n",
    "    dyn_win = np.asarray([np.concatenate([rows_scaled[e-window_size:e, :], win_pos], axis=1) for e in ends], dtype=np.float32)\n",
    "    # --- ‚≠êÔ∏è MODIFICATION: cr_win removed ---\n",
    "    static_scaled = static_scaler.transform(static_vec).astype(np.float32); st_win = np.repeat(static_scaled, num, axis=0)\n",
    "    \n",
    "    # --- ‚≠êÔ∏è NEW: Create the group_id input array ---\n",
    "    # It must be repeated for every window in the batch\n",
    "    # group_id_arr = np.full(shape=(num,), fill_value=group_id, dtype=np.int32)\n",
    "    group_id_arr = np.full(shape=(num, 1), fill_value=group_id, dtype=np.int32)\n",
    "    # ---\n",
    "\n",
    "    # --- ‚≠êÔ∏è MODIFIED: Model prediction (pass 3 inputs) ---\n",
    "    y_hat_norm = model.predict(\n",
    "        (dyn_win, st_win, group_id_arr),\n",
    "        batch_size=PRED_BATCH,\n",
    "        verbose=0\n",
    "    ).reshape(-1, 1)\n",
    "\n",
    "    # (Inverse transform is unchanged, uses the per-group scaler)\n",
    "    dq_hat_scaled_norm = delta_scaler_group.inverse_transform(y_hat_norm).flatten()\n",
    "    dq_hat_norm = np.maximum(dq_hat_scaled_norm / SCALE_DELTA, 0.0)\n",
    "    q_hat_norm = np.cumsum(dq_hat_norm) # Output is NORMALIZED cumulative loss\n",
    "\n",
    "    # (Get ground truth data - unchanged)\n",
    "    dmat = load_mat(file_name) \n",
    "    Time_s = np.asarray(dmat[\"Time_s_p\"], np.float64).flatten()\n",
    "    t_exp = np.asarray(dmat[\"t_exp\"], np.float64).flatten() if \"t_exp\" in dmat else np.array([])\n",
    "    Cap_Nom = p[\"Cap_Nom\"]\n",
    "    q_exp_norm = p[\"Q_exp_norm\"]\n",
    "    Q_total_norm = p[\"Q_total_norm\"]\n",
    "    dq_pb_norm = np.maximum(np.diff(Q_total_norm, prepend=Q_total_norm[0]), 0.0)\n",
    "    q_pb_norm = np.cumsum(dq_pb_norm)\n",
    "    \n",
    "    L = len(q_hat_norm)\n",
    "    if L == 0: return (np.array([]),)*8\n",
    "    t_dense = Time_s[ends-1]\n",
    "    q_exp_norm_d = q_exp_norm[ends-1]\n",
    "    q_pb_norm_d = q_pb_norm[ends-1]\n",
    "\n",
    "    return t_dense, q_exp_norm_d, q_pb_norm_d, q_hat_norm, Cap_Nom, Time_s, t_exp \n",
    "\n",
    "# --- ‚≠êÔ∏è MODIFICATION: Added 'do_plot=True' argument ---\n",
    "def evaluate_model_on_test(model, window_size, stride, plot_suffix=\"\", do_plot=True):\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    results = []\n",
    "\n",
    "    for fn in tqdm(TEST_FILES, desc=\"Evaluating test cells\", ncols=90):\n",
    "        # This call now uses the MODIFIED predict_cell\n",
    "        t_dense, q_exp_norm_d, q_pb_norm_d, q_hat_norm_d, cap_nom, Time_s_full, t_exp = predict_cell(model, fn, window_size, stride)\n",
    "\n",
    "        if t_dense.size == 0: print(f\"Warning: no windows for {fn}\"); continue\n",
    "\n",
    "        ts_dense = t_dense\n",
    "        t_exp_use = t_exp[(t_exp >= ts_dense[0]) & (t_exp <= ts_dense[-1])]\n",
    "        idx = nearest_indices(ts_dense, t_exp_use)\n",
    "        if idx.size == 0: print(f\"Warning: no matching experimental time points for {fn}\"); continue\n",
    "\n",
    "        Q_exp_norm_stamp = q_exp_norm_d[idx]\n",
    "        Q_pb_norm_stamp = q_pb_norm_d[idx]\n",
    "        Q_pred_norm_stamp = q_hat_norm_d[idx]\n",
    "        \n",
    "        Q_exp_n = Q_exp_norm_stamp.copy()\n",
    "        Q_pred_n = Q_pred_norm_stamp.copy()\n",
    "        Q_pb_n = Q_pb_norm_stamp.copy()\n",
    "\n",
    "        # (Metrics calculation is unchanged)\n",
    "        mse_pitm_norm = float(np.mean((Q_exp_n - Q_pred_n)**2)) \n",
    "        denom_norm = float(np.sum(Q_exp_n**2))\n",
    "        rsep_pitm = 100.0 * np.sqrt(np.sum((Q_exp_n - Q_pred_n)**2) / denom_norm) if denom_norm > 1e-12 else np.nan\n",
    "        mask = np.abs(Q_exp_n) > 1e-9 \n",
    "        mape_pitm = 100.0 * np.mean(np.abs((Q_exp_n[mask] - Q_pred_n[mask]) / Q_exp_n[mask])) if np.any(mask) else np.nan\n",
    "        mse_pb_norm = float(np.mean((Q_exp_n - Q_pb_n)**2)) \n",
    "        rsep_pb = 100.0 * np.sqrt(np.sum((Q_exp_n - Q_pb_n)**2) / denom_norm) if denom_norm > 1e-12 else np.nan\n",
    "        mape_pb = 100.0 * np.mean(np.abs((Q_exp_n[mask] - Q_pb_n[mask]) / Q_pb_n[mask])) if np.any(mask) else np.nan\n",
    "        mse_pitm_abs = mse_pitm_norm * (cap_nom**2)\n",
    "        mse_pb_abs = mse_pb_norm * (cap_nom**2)\n",
    "        \n",
    "        results.append((os.path.basename(fn), mse_pitm_abs, mape_pitm, rsep_pitm, mse_pb_abs, mape_pb, rsep_pb))\n",
    "\n",
    "        # --- ‚≠êÔ∏è MODIFICATION: Plotting is now conditional ---\n",
    "        if do_plot:\n",
    "            plt.figure(figsize=(6.8, 3.2))\n",
    "            cap_nom_safe = max(cap_nom, 1e-6)\n",
    "            plt.scatter(t_exp_use / 3600.0, 100.0 * Q_exp_norm_stamp, s=18, label=\"Experimental\", zorder=3)\n",
    "            plt.plot(t_dense / 3600.0, 100.0 * q_pb_norm_d, lw=1.2, label=\"PB-ROM\", zorder=2)\n",
    "            plt.plot(t_dense / 3600.0, 100.0 * q_hat_norm_d, lw=1.8, label=\"PITM\", zorder=2)\n",
    "            plt.xlabel(\"Time (h)\"); plt.ylabel(\"Capacity degradation (%)\"); plt.title(os.path.basename(fn))\n",
    "            plt.legend(); plt.grid(alpha=0.3); plt.tight_layout()\n",
    "            suffix = f\"_{plot_suffix}\" if plot_suffix else \"\"; out_pct = f\"plots/{os.path.basename(fn).replace('.mat', '')}_pred_pct{suffix}.png\"\n",
    "            plt.savefig(out_pct, dpi=300); plt.show(); plt.close()\n",
    "            print(f\"Saved ‚Üí {out_pct}\")\n",
    "        # --- End of modification ---\n",
    "\n",
    "    print(\"\\nüìä PITM Testing Results (per cell)\")\n",
    "    for name, mse_pitm, mape_pitm, rsep_pitm, mse_pb, mape_pb, rsep_pb in results:\n",
    "        print(f\"  {name:35s}   \"\n",
    "              f\"[PITM] MSE={mse_pitm:.3e} RSEP={rsep_pitm:.2f}% MAPE={mape_pitm:.2f}%    \" \n",
    "              # f\"[PB] MSE={mse_pb:.3e} RSEP={rsep_pb:.2f}% MAPE={mape_pb:.2f}%\"\n",
    "        )    \n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Cell 6a (Group-Conditioned) testing pipeline ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca226fad-5b93-4d7b-ada6-cae83cb71e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ======================================\n",
    "# # Cell 6b ‚Äî Test the Best Model\n",
    "# # ======================================\n",
    "\n",
    "# # --- Load the BEST checkpoint from training ---\n",
    "# MODEL_TO_TEST = os.path.join(\"checkpoints\", \"main_pitm_best_macro.h5\")\n",
    "# # MODEL_TO_TEST = os.path.join(\"checkpoints\", \"main_pitm_final_weights.h5\")\n",
    "\n",
    "# if not os.path.exists(MODEL_TO_TEST):\n",
    "#     print(f\"‚ö†Ô∏è Warning: Best checkpoint not found at {MODEL_TO_TEST}.\")\n",
    "#     print(\"Falling back to final weights. Re-run 5b if this is wrong.\")\n",
    "#     MODEL_TO_TEST = \"checkpoints/main_pitm_final_weights.h5\"\n",
    "#     if not os.path.exists(MODEL_TO_TEST):\n",
    "#         raise FileNotFoundError(\"No model weights found to test.\")\n",
    "\n",
    "# # --- Use the same hyperparams as training ---\n",
    "# RUN_WINDOW_SIZE = WINDOW_SIZE\n",
    "# RUN_STRIDE = STRIDE\n",
    "\n",
    "# # --- Rebuild the EXACT same architecture (v4) ---\n",
    "# print(\"Rebuilding v4 model architecture...\")\n",
    "# model = build_pitm_model(\n",
    "#     window_size=RUN_WINDOW_SIZE,\n",
    "#     num_groups=NUM_GROUPS,  # <-- From Cell 1\n",
    "#     embed_dim=EMBED_DIM,\n",
    "#     num_heads=NUM_HEADS,\n",
    "#     ff_dim=FF_DIM,\n",
    "#     num_layers=NUM_LAYERS,\n",
    "#     dropout=DROPOUT # Note: dropout is inactive during inference\n",
    "# )\n",
    "\n",
    "# # Load the trained weights\n",
    "# model.load_weights(MODEL_TO_TEST)\n",
    "# print(f\"‚úÖ Loaded BEST run weights from {MODEL_TO_TEST}\")\n",
    "\n",
    "# # --- Run evaluation using the new (Cell 6a) pipeline ---\n",
    "# _ = evaluate_model_on_test(\n",
    "#     model, \n",
    "#     window_size=RUN_WINDOW_SIZE, \n",
    "#     stride=RUN_STRIDE, \n",
    "#     plot_suffix=\"best_model\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a3ebb0-844f-4d19-9649-538aaacad6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605daef-2574-44f6-8b76-b01d4f9d9560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc7137-c253-4768-b363-eebf17b07031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c734a90-153e-4c49-a4fc-80e6a667c611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc16b19-87ba-46a4-8607-84d16531ee8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62755977-fe9e-4ed2-a064-baf3108ace8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d719dbc-f30b-4d76-ad9e-634986ebaa5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c13b432b-0bb8-4801-b9f2-63b32f353fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage 2 Random Search defined: 20 total runs.\n",
      "   window_size candidates:   [10, 50, 100, 20, 150]\n",
      "   batch_size candidates:    [64, 256, 512, 768, 1024]\n",
      "   num_layers candidates:    [1, 2, 3, 4, 5]\n",
      "   embed_dim candidates:     [32, 64, 96, 128]\n",
      "   lambda_phys range:        [0.0, 1.1]\n",
      "   learning_rate log-range:  [1.0e-08, 3.0e-04]\n",
      "   Using the unified training pipeline (train_one_model).\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# Cell 10a ‚Äî Random Search (Stage 2) Definitions\n",
    "# (tuned around the current best config)\n",
    "# ===============================================\n",
    "import numpy as np\n",
    "\n",
    "# --- Number of random runs ---\n",
    "# Increase this (e.g. 10‚Äì20) once you're happy with the space\n",
    "N_RANDOM_RUNS = 20  # or 10+ for a more thorough search\n",
    "\n",
    "RANDOM_SEARCH_SPACE_STAGE2 = {\n",
    "    # Discrete choices (random.choice)\n",
    "    \"window_size\":  [10, 50, 100, 20, 150],       # around 70\n",
    "    \"batch_size\":   [64, 256, 512, 768, 1024],        # around 512 (watch GPU memory)\n",
    "    \"num_layers\":   [1, 2, 3, 4, 5],              # shallow to moderately deep\n",
    "    \"embed_dim\":    [32, 64, 96, 128],           # around 64\n",
    "\n",
    "    # Continuous ranges (random.uniform / log-uniform)\n",
    "    \"lambda_phys\":  [0.0, 1.1],             # narrow band around ~0.67\n",
    "    \"learning_rate\": [1e-8, 3e-4],          # around 8e-7, still some room\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Stage 2 Random Search defined: {N_RANDOM_RUNS} total runs.\")\n",
    "print(f\"   window_size candidates:   {RANDOM_SEARCH_SPACE_STAGE2['window_size']}\")\n",
    "print(f\"   batch_size candidates:    {RANDOM_SEARCH_SPACE_STAGE2['batch_size']}\")\n",
    "print(f\"   num_layers candidates:    {RANDOM_SEARCH_SPACE_STAGE2['num_layers']}\")\n",
    "print(f\"   embed_dim candidates:     {RANDOM_SEARCH_SPACE_STAGE2['embed_dim']}\")\n",
    "print(f\"   lambda_phys range:        {RANDOM_SEARCH_SPACE_STAGE2['lambda_phys']}\")\n",
    "print(f\"   learning_rate log-range:  [{RANDOM_SEARCH_SPACE_STAGE2['learning_rate'][0]:.1e}, \"\n",
    "      f\"{RANDOM_SEARCH_SPACE_STAGE2['learning_rate'][1]:.1e}]\")\n",
    "print(f\"   Using the unified training pipeline (train_one_model).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c130729-ba3e-4bbb-a383-9f728b1b8c1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 1 / 20\n",
      "  window_size   = 10\n",
      "  lambda_phys   = 0.2455\n",
      "  batch_size    = 64\n",
      "  learning_rate = 1.98e-05\n",
      "  num_layers    = 3\n",
      "  embed_dim     = 64\n",
      "==================================================\n",
      "Mixed precision policy: mixed_float16\n",
      "Using default strategy (1 GPU or CPU).\n",
      "Batch per device: 64 | Global batch: 64\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (window_size=10, stride=1) ---\n",
      "This will create one giant, UNBALANCED, shuffled training set WITH SAMPLE WEIGHTS.\n",
      "Calculating local time percentiles (p95_t, p95_dt)...\n",
      "  p95_t=1.2396e+07, p95_dt=9.9020e+01\n",
      "\n",
      "--- Pass 1.5a: Finding group sizes for weighting ---\n",
      "  Group 'D5_Cells_1' has 1,199,991 windows.\n",
      "\n",
      "--- Calculating Sample Weights ---\n",
      "  Group 'D5_Cells_1' (count=1,199,991): weight = 1.0000\n",
      "\n",
      "--- Pass 1.5b: Processing and all groups (NO oversampling) ---\n",
      "\n",
      "Processing Group: D5_Cells_1 (ID=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Files for D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:16<00:00, 16.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created 1,199,990 windows (weight: 1.0000).\n",
      "\n",
      "--- ‚úÖ Pre-processing complete ---\n",
      "Converting to numpy arrays...\n",
      "Total windows generated (unbalanced): 1,199,990\n",
      "X_dyn shape: (1199990, 10, 7)\n",
      "X_st shape:  (1199990, 4)\n",
      "X_gid shape: (1199990, 1)\n",
      "y_train shape: (1199990, 2)\n",
      "weights shape: (1199990,)\n",
      "Generating and applying global shuffle...\n",
      "--- üî¨ Verifying Shuffle ---\n",
      "Group mix in first 1000 samples (unbalanced is OK): {0: 1000}\n",
      "‚ùå SHUFFLE FAILED. Check warnings above.\n",
      "\n",
      "‚úÖ build_training_arrays() complete with sample weights.\n",
      "--- ‚ö°Ô∏è Creating fast in-memory training dataset (with weights) ---\n",
      "  Total windows: 1,199,990\n",
      "  Steps per epoch: 18,750\n",
      "‚úÖ Training dataset (with sample weights) is ready.\n",
      "  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "Starting training for 50 epochs (train steps/epoch ‚âà 18,750, batch=64)\n",
      "Epoch 1/50\n",
      "18750/18750 [==============================] - 213s 10ms/step - loss: 0.2119\n",
      "Epoch 2/50\n",
      "18747/18750 [============================>.] - ETA: 0s - loss: 0.1218  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 2] macro=0.116468  (per-cell: 0.1165)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run1_best.h5\n",
      "18750/18750 [==============================] - 263s 14ms/step - loss: 0.1218 - val_loss: 0.1165 - val_loss_macro: 0.1165\n",
      "Epoch 3/50\n",
      "18750/18750 [==============================] - 190s 10ms/step - loss: 0.0887\n",
      "Epoch 4/50\n",
      "18745/18750 [============================>.] - ETA: 0s - loss: 0.0707  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 4] macro=0.082651  (per-cell: 0.0827)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run1_best.h5\n",
      "18750/18750 [==============================] - 257s 14ms/step - loss: 0.0707 - val_loss: 0.0826 - val_loss_macro: 0.0827\n",
      "Epoch 5/50\n",
      "18750/18750 [==============================] - 190s 10ms/step - loss: 0.0577\n",
      "Epoch 6/50\n",
      "18746/18750 [============================>.] - ETA: 0s - loss: 0.0489  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 6] macro=0.071772  (per-cell: 0.0718)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run1_best.h5\n",
      "18750/18750 [==============================] - 257s 14ms/step - loss: 0.0489 - val_loss: 0.0718 - val_loss_macro: 0.0718\n",
      "Epoch 7/50\n",
      "18750/18750 [==============================] - 192s 10ms/step - loss: 0.0430\n",
      "Epoch 8/50\n",
      "18747/18750 [============================>.] - ETA: 0s - loss: 0.0389  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 8] macro=0.065347  (per-cell: 0.0653)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run1_best.h5\n",
      "18750/18750 [==============================] - 256s 14ms/step - loss: 0.0389 - val_loss: 0.0653 - val_loss_macro: 0.0653\n",
      "Epoch 9/50\n",
      "18750/18750 [==============================] - 191s 10ms/step - loss: 0.0359\n",
      "Epoch 10/50\n",
      "18750/18750 [==============================] - ETA: 0s - loss: 0.0335  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 10] macro=0.062155  (per-cell: 0.0622)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run1_best.h5\n",
      "18750/18750 [==============================] - 257s 14ms/step - loss: 0.0335 - val_loss: 0.0622 - val_loss_macro: 0.0622\n",
      "Epoch 11/50\n",
      "18750/18750 [==============================] - 178s 9ms/step - loss: 0.0315\n",
      "Epoch 12/50\n",
      "18745/18750 [============================>.] - ETA: 0s - loss: 0.0300  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 12] macro=0.059181  (per-cell: 0.0592)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run1_best.h5\n",
      "18750/18750 [==============================] - 236s 13ms/step - loss: 0.0300 - val_loss: 0.0592 - val_loss_macro: 0.0592\n",
      "Epoch 13/50\n",
      "18750/18750 [==============================] - 169s 9ms/step - loss: 0.0287\n",
      "Epoch 14/50\n",
      "18750/18750 [==============================] - ETA: 0s - loss: 0.0275  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 14] macro=0.056828  (per-cell: 0.0568)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run1_best.h5\n",
      "18750/18750 [==============================] - 238s 13ms/step - loss: 0.0275 - val_loss: 0.0568 - val_loss_macro: 0.0568\n",
      "Epoch 15/50\n",
      "18750/18750 [==============================] - 169s 9ms/step - loss: 0.0266\n",
      "Epoch 16/50\n",
      "18745/18750 [============================>.] - ETA: 0s - loss: 0.0258  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 16] macro=0.056938  (per-cell: 0.0569)\n",
      "18750/18750 [==============================] - 233s 12ms/step - loss: 0.0258 - val_loss: 0.0569 - val_loss_macro: 0.0569\n",
      "Epoch 17/50\n",
      "18750/18750 [==============================] - 171s 9ms/step - loss: 0.0251\n",
      "Epoch 18/50\n",
      "18745/18750 [============================>.] - ETA: 0s - loss: 0.0245  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 18] macro=0.056366  (per-cell: 0.0564)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run1_best.h5\n",
      "18750/18750 [==============================] - 234s 12ms/step - loss: 0.0245 - val_loss: 0.0564 - val_loss_macro: 0.0564\n",
      "Epoch 19/50\n",
      "18750/18750 [==============================] - 168s 9ms/step - loss: 0.0239\n",
      "Epoch 20/50\n",
      "18747/18750 [============================>.] - ETA: 0s - loss: 0.0235  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 20] macro=0.056630  (per-cell: 0.0566)\n",
      "18750/18750 [==============================] - 231s 12ms/step - loss: 0.0235 - val_loss: 0.0566 - val_loss_macro: 0.0566\n",
      "Epoch 21/50\n",
      "18750/18750 [==============================] - 170s 9ms/step - loss: 0.0231\n",
      "Epoch 22/50\n",
      "18746/18750 [============================>.] - ETA: 0s - loss: 0.0227  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 22] macro=0.055982  (per-cell: 0.0560)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run1_best.h5\n",
      "18750/18750 [==============================] - 235s 13ms/step - loss: 0.0227 - val_loss: 0.0560 - val_loss_macro: 0.0560\n",
      "Epoch 23/50\n",
      "18750/18750 [==============================] - 167s 9ms/step - loss: 0.0223\n",
      "Epoch 24/50\n",
      "18748/18750 [============================>.] - ETA: 0s - loss: 0.0220  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 24] macro=0.055824  (per-cell: 0.0558)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run1_best.h5\n",
      "18750/18750 [==============================] - 232s 12ms/step - loss: 0.0220 - val_loss: 0.0558 - val_loss_macro: 0.0558\n",
      "Epoch 25/50\n",
      "18750/18750 [==============================] - 174s 9ms/step - loss: 0.0217\n",
      "Epoch 26/50\n",
      "18746/18750 [============================>.] - ETA: 0s - loss: 0.0215  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 26] macro=0.053800  (per-cell: 0.0538)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run1_best.h5\n",
      "18750/18750 [==============================] - 234s 13ms/step - loss: 0.0215 - val_loss: 0.0538 - val_loss_macro: 0.0538\n",
      "Epoch 27/50\n",
      "18750/18750 [==============================] - 174s 9ms/step - loss: 0.0213\n",
      "Epoch 28/50\n",
      "18746/18750 [============================>.] - ETA: 0s - loss: 0.0210  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 28] macro=0.054309  (per-cell: 0.0543)\n",
      "18750/18750 [==============================] - 232s 12ms/step - loss: 0.0210 - val_loss: 0.0543 - val_loss_macro: 0.0543\n",
      "Epoch 29/50\n",
      "18750/18750 [==============================] - 168s 9ms/step - loss: 0.0208\n",
      "Epoch 30/50\n",
      "18749/18750 [============================>.] - ETA: 0s - loss: 0.0207  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 30] macro=0.055716  (per-cell: 0.0557)\n",
      "18750/18750 [==============================] - 228s 12ms/step - loss: 0.0207 - val_loss: 0.0557 - val_loss_macro: 0.0557\n",
      "Epoch 31/50\n",
      "18750/18750 [==============================] - 166s 9ms/step - loss: 0.0205\n",
      "Epoch 32/50\n",
      "18745/18750 [============================>.] - ETA: 0s - loss: 0.0203  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 32] macro=0.056681  (per-cell: 0.0567)\n",
      "  ‚Üí LR reduced: 1.98276e-05 ‚Üí 9.91382e-06\n",
      "18750/18750 [==============================] - 236s 13ms/step - loss: 0.0203 - val_loss: 0.0567 - val_loss_macro: 0.0567\n",
      "Epoch 33/50\n",
      "18750/18750 [==============================] - 167s 9ms/step - loss: 0.0201\n",
      "Epoch 34/50\n",
      "18746/18750 [============================>.] - ETA: 0s - loss: 0.0200  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 34] macro=0.056219  (per-cell: 0.0562)\n",
      "18750/18750 [==============================] - 229s 12ms/step - loss: 0.0200 - val_loss: 0.0562 - val_loss_macro: 0.0562\n",
      "Epoch 35/50\n",
      "18750/18750 [==============================] - 168s 9ms/step - loss: 0.0199\n",
      "Epoch 36/50\n",
      "18745/18750 [============================>.] - ETA: 0s - loss: 0.0198  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 36] macro=0.056648  (per-cell: 0.0566)\n",
      "  ‚Üí Early stopping.\n",
      "18750/18750 [==============================] - 228s 12ms/step - loss: 0.0198 - val_loss: 0.0566 - val_loss_macro: 0.0566\n",
      "\n",
      "‚úÖ Training complete for run 'rs2_run1'. Best checkpoint: checkpoints/rs2_run1_best.h5\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run1_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells:   0%|                                        | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Testing PBROM_data_cell_D5C78.mat: using 'D5_Cells_1' scaler, ID: 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_D5C78.mat             [PITM] MSE=2.197e-05 RSEP=6.23% MAPE=7.00%    \n",
      "[RandomSearch] Run 1 ‚Üí avg_rsep_pitm=6.2261\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 2 / 20\n",
      "  window_size   = 10\n",
      "  lambda_phys   = 0.4069\n",
      "  batch_size    = 512\n",
      "  learning_rate = 1.34e-05\n",
      "  num_layers    = 2\n",
      "  embed_dim     = 128\n",
      "==================================================\n",
      "Mixed precision policy: mixed_float16\n",
      "Using default strategy (1 GPU or CPU).\n",
      "Batch per device: 512 | Global batch: 512\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (window_size=10, stride=1) ---\n",
      "This will create one giant, UNBALANCED, shuffled training set WITH SAMPLE WEIGHTS.\n",
      "Calculating local time percentiles (p95_t, p95_dt)...\n",
      "  p95_t=1.2396e+07, p95_dt=9.9020e+01\n",
      "\n",
      "--- Pass 1.5a: Finding group sizes for weighting ---\n",
      "  Group 'D5_Cells_1' has 1,199,991 windows.\n",
      "\n",
      "--- Calculating Sample Weights ---\n",
      "  Group 'D5_Cells_1' (count=1,199,991): weight = 1.0000\n",
      "\n",
      "--- Pass 1.5b: Processing and all groups (NO oversampling) ---\n",
      "\n",
      "Processing Group: D5_Cells_1 (ID=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Files for D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:16<00:00, 16.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created 1,199,990 windows (weight: 1.0000).\n",
      "\n",
      "--- ‚úÖ Pre-processing complete ---\n",
      "Converting to numpy arrays...\n",
      "Total windows generated (unbalanced): 1,199,990\n",
      "X_dyn shape: (1199990, 10, 7)\n",
      "X_st shape:  (1199990, 4)\n",
      "X_gid shape: (1199990, 1)\n",
      "y_train shape: (1199990, 2)\n",
      "weights shape: (1199990,)\n",
      "Generating and applying global shuffle...\n",
      "--- üî¨ Verifying Shuffle ---\n",
      "Group mix in first 1000 samples (unbalanced is OK): {0: 1000}\n",
      "‚ùå SHUFFLE FAILED. Check warnings above.\n",
      "\n",
      "‚úÖ build_training_arrays() complete with sample weights.\n",
      "--- ‚ö°Ô∏è Creating fast in-memory training dataset (with weights) ---\n",
      "  Total windows: 1,199,990\n",
      "  Steps per epoch: 2,344\n",
      "‚úÖ Training dataset (with sample weights) is ready.\n",
      "  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "Starting training for 50 epochs (train steps/epoch ‚âà 2,344, batch=512)\n",
      "Epoch 1/50\n",
      "2344/2344 [==============================] - 34s 7ms/step - loss: 0.2906\n",
      "Epoch 2/50\n",
      "2340/2344 [============================>.] - ETA: 0s - loss: 0.2344  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 2] macro=0.230666  (per-cell: 0.2307)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 61s 26ms/step - loss: 0.2344 - val_loss: 0.2307 - val_loss_macro: 0.2307\n",
      "Epoch 3/50\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 0.2037\n",
      "Epoch 4/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.1807  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 4] macro=0.188742  (per-cell: 0.1887)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.1807 - val_loss: 0.1887 - val_loss_macro: 0.1887\n",
      "Epoch 5/50\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 0.1622\n",
      "Epoch 6/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.1472  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 6] macro=0.162660  (per-cell: 0.1627)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.1472 - val_loss: 0.1627 - val_loss_macro: 0.1627\n",
      "Epoch 7/50\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 0.1350\n",
      "Epoch 8/50\n",
      "2339/2344 [============================>.] - ETA: 0s - loss: 0.1248  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 8] macro=0.144145  (per-cell: 0.1441)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.1248 - val_loss: 0.1441 - val_loss_macro: 0.1441\n",
      "Epoch 9/50\n",
      "2344/2344 [==============================] - 19s 8ms/step - loss: 0.1160\n",
      "Epoch 10/50\n",
      "2338/2344 [============================>.] - ETA: 0s - loss: 0.1066  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 10] macro=0.129923  (per-cell: 0.1299)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 59s 25ms/step - loss: 0.1066 - val_loss: 0.1299 - val_loss_macro: 0.1299\n",
      "Epoch 11/50\n",
      "2344/2344 [==============================] - 19s 8ms/step - loss: 0.0969\n",
      "Epoch 12/50\n",
      "2338/2344 [============================>.] - ETA: 0s - loss: 0.0908  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 12] macro=0.117806  (per-cell: 0.1178)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 59s 25ms/step - loss: 0.0908 - val_loss: 0.1178 - val_loss_macro: 0.1178\n",
      "Epoch 13/50\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 0.0858\n",
      "Epoch 14/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.0814  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 14] macro=0.110525  (per-cell: 0.1105)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.0814 - val_loss: 0.1105 - val_loss_macro: 0.1105\n",
      "Epoch 15/50\n",
      "2344/2344 [==============================] - 19s 8ms/step - loss: 0.0775\n",
      "Epoch 16/50\n",
      "2339/2344 [============================>.] - ETA: 0s - loss: 0.0741  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 16] macro=0.104397  (per-cell: 0.1044)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 59s 25ms/step - loss: 0.0741 - val_loss: 0.1044 - val_loss_macro: 0.1044\n",
      "Epoch 17/50\n",
      "2344/2344 [==============================] - 19s 8ms/step - loss: 0.0710\n",
      "Epoch 18/50\n",
      "2338/2344 [============================>.] - ETA: 0s - loss: 0.0682  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 18] macro=0.099636  (per-cell: 0.0996)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 59s 25ms/step - loss: 0.0682 - val_loss: 0.0996 - val_loss_macro: 0.0996\n",
      "Epoch 19/50\n",
      "2344/2344 [==============================] - 19s 8ms/step - loss: 0.0657\n",
      "Epoch 20/50\n",
      "2341/2344 [============================>.] - ETA: 0s - loss: 0.0634  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 20] macro=0.095886  (per-cell: 0.0959)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 59s 25ms/step - loss: 0.0634 - val_loss: 0.0959 - val_loss_macro: 0.0959\n",
      "Epoch 21/50\n",
      "2344/2344 [==============================] - 19s 8ms/step - loss: 0.0613\n",
      "Epoch 22/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.0594  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 22] macro=0.092220  (per-cell: 0.0922)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.0594 - val_loss: 0.0922 - val_loss_macro: 0.0922\n",
      "Epoch 23/50\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 0.0577\n",
      "Epoch 24/50\n",
      "2339/2344 [============================>.] - ETA: 0s - loss: 0.0561  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 24] macro=0.089332  (per-cell: 0.0893)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.0561 - val_loss: 0.0893 - val_loss_macro: 0.0893\n",
      "Epoch 25/50\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 0.0546\n",
      "Epoch 26/50\n",
      "2338/2344 [============================>.] - ETA: 0s - loss: 0.0532  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 26] macro=0.087147  (per-cell: 0.0871)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.0532 - val_loss: 0.0871 - val_loss_macro: 0.0871\n",
      "Epoch 27/50\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 0.0520\n",
      "Epoch 28/50\n",
      "2338/2344 [============================>.] - ETA: 0s - loss: 0.0508  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 28] macro=0.084235  (per-cell: 0.0842)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.0508 - val_loss: 0.0842 - val_loss_macro: 0.0842\n",
      "Epoch 29/50\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 0.0497\n",
      "Epoch 30/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.0487  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 30] macro=0.082498  (per-cell: 0.0825)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.0487 - val_loss: 0.0825 - val_loss_macro: 0.0825\n",
      "Epoch 31/50\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 0.0477\n",
      "Epoch 32/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.0469  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 32] macro=0.080855  (per-cell: 0.0809)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.0469 - val_loss: 0.0809 - val_loss_macro: 0.0809\n",
      "Epoch 33/50\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 0.0460\n",
      "Epoch 34/50\n",
      "2339/2344 [============================>.] - ETA: 0s - loss: 0.0452  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 34] macro=0.079081  (per-cell: 0.0791)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 57s 25ms/step - loss: 0.0452 - val_loss: 0.0791 - val_loss_macro: 0.0791\n",
      "Epoch 35/50\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 0.0445\n",
      "Epoch 36/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.0438  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 36] macro=0.077747  (per-cell: 0.0777)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 57s 25ms/step - loss: 0.0438 - val_loss: 0.0777 - val_loss_macro: 0.0777\n",
      "Epoch 37/50\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 0.0431\n",
      "Epoch 38/50\n",
      "2339/2344 [============================>.] - ETA: 0s - loss: 0.0425  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 38] macro=0.077502  (per-cell: 0.0775)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.0425 - val_loss: 0.0775 - val_loss_macro: 0.0775\n",
      "Epoch 39/50\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 0.0419\n",
      "Epoch 40/50\n",
      "2339/2344 [============================>.] - ETA: 0s - loss: 0.0413  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 40] macro=0.076403  (per-cell: 0.0764)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 57s 25ms/step - loss: 0.0413 - val_loss: 0.0764 - val_loss_macro: 0.0764\n",
      "Epoch 41/50\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 0.0408\n",
      "Epoch 42/50\n",
      "2339/2344 [============================>.] - ETA: 0s - loss: 0.0403  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 42] macro=0.076064  (per-cell: 0.0761)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 57s 24ms/step - loss: 0.0403 - val_loss: 0.0761 - val_loss_macro: 0.0761\n",
      "Epoch 43/50\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 0.0398\n",
      "Epoch 44/50\n",
      "2339/2344 [============================>.] - ETA: 0s - loss: 0.0393  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 44] macro=0.075543  (per-cell: 0.0755)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.0393 - val_loss: 0.0755 - val_loss_macro: 0.0755\n",
      "Epoch 45/50\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 0.0389\n",
      "Epoch 46/50\n",
      "2339/2344 [============================>.] - ETA: 0s - loss: 0.0384  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 46] macro=0.075762  (per-cell: 0.0758)\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.0385 - val_loss: 0.0758 - val_loss_macro: 0.0758\n",
      "Epoch 47/50\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 0.0381\n",
      "Epoch 48/50\n",
      "2338/2344 [============================>.] - ETA: 0s - loss: 0.0376  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 48] macro=0.074555  (per-cell: 0.0746)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 57s 24ms/step - loss: 0.0376 - val_loss: 0.0746 - val_loss_macro: 0.0746\n",
      "Epoch 49/50\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 0.0373\n",
      "Epoch 50/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.0370  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 50] macro=0.074043  (per-cell: 0.0740)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run2_best.h5\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.0370 - val_loss: 0.0740 - val_loss_macro: 0.0740\n",
      "\n",
      "‚úÖ Training complete for run 'rs2_run2'. Best checkpoint: checkpoints/rs2_run2_best.h5\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run2_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells:   0%|                                        | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Testing PBROM_data_cell_D5C78.mat: using 'D5_Cells_1' scaler, ID: 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_D5C78.mat             [PITM] MSE=4.721e-05 RSEP=9.13% MAPE=11.01%    \n",
      "[RandomSearch] Run 2 ‚Üí avg_rsep_pitm=9.1277\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 3 / 20\n",
      "  window_size   = 10\n",
      "  lambda_phys   = 0.1102\n",
      "  batch_size    = 256\n",
      "  learning_rate = 2.93e-05\n",
      "  num_layers    = 1\n",
      "  embed_dim     = 32\n",
      "==================================================\n",
      "Mixed precision policy: mixed_float16\n",
      "Using default strategy (1 GPU or CPU).\n",
      "Batch per device: 256 | Global batch: 256\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (window_size=10, stride=1) ---\n",
      "This will create one giant, UNBALANCED, shuffled training set WITH SAMPLE WEIGHTS.\n",
      "Calculating local time percentiles (p95_t, p95_dt)...\n",
      "  p95_t=1.2396e+07, p95_dt=9.9020e+01\n",
      "\n",
      "--- Pass 1.5a: Finding group sizes for weighting ---\n",
      "  Group 'D5_Cells_1' has 1,199,991 windows.\n",
      "\n",
      "--- Calculating Sample Weights ---\n",
      "  Group 'D5_Cells_1' (count=1,199,991): weight = 1.0000\n",
      "\n",
      "--- Pass 1.5b: Processing and all groups (NO oversampling) ---\n",
      "\n",
      "Processing Group: D5_Cells_1 (ID=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Files for D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:16<00:00, 16.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created 1,199,990 windows (weight: 1.0000).\n",
      "\n",
      "--- ‚úÖ Pre-processing complete ---\n",
      "Converting to numpy arrays...\n",
      "Total windows generated (unbalanced): 1,199,990\n",
      "X_dyn shape: (1199990, 10, 7)\n",
      "X_st shape:  (1199990, 4)\n",
      "X_gid shape: (1199990, 1)\n",
      "y_train shape: (1199990, 2)\n",
      "weights shape: (1199990,)\n",
      "Generating and applying global shuffle...\n",
      "--- üî¨ Verifying Shuffle ---\n",
      "Group mix in first 1000 samples (unbalanced is OK): {0: 1000}\n",
      "‚ùå SHUFFLE FAILED. Check warnings above.\n",
      "\n",
      "‚úÖ build_training_arrays() complete with sample weights.\n",
      "--- ‚ö°Ô∏è Creating fast in-memory training dataset (with weights) ---\n",
      "  Total windows: 1,199,990\n",
      "  Steps per epoch: 4,688\n",
      "‚úÖ Training dataset (with sample weights) is ready.\n",
      "  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "Starting training for 50 epochs (train steps/epoch ‚âà 4,688, batch=256)\n",
      "Epoch 1/50\n",
      "4688/4688 [==============================] - 33s 5ms/step - loss: 0.1264\n",
      "Epoch 2/50\n",
      "4684/4688 [============================>.] - ETA: 0s - loss: 0.0792  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 2] macro=0.068464  (per-cell: 0.0685)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run3_best.h5\n",
      "4688/4688 [==============================] - 66s 14ms/step - loss: 0.0792 - val_loss: 0.0685 - val_loss_macro: 0.0685\n",
      "Epoch 3/50\n",
      "4688/4688 [==============================] - 23s 5ms/step - loss: 0.0629\n",
      "Epoch 4/50\n",
      "4687/4688 [============================>.] - ETA: 0s - loss: 0.0553  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 4] macro=0.053262  (per-cell: 0.0533)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run3_best.h5\n",
      "4688/4688 [==============================] - 66s 14ms/step - loss: 0.0553 - val_loss: 0.0533 - val_loss_macro: 0.0533\n",
      "Epoch 5/50\n",
      "4688/4688 [==============================] - 23s 5ms/step - loss: 0.0504\n",
      "Epoch 6/50\n",
      "4685/4688 [============================>.] - ETA: 0s - loss: 0.0470  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 6] macro=0.048556  (per-cell: 0.0486)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run3_best.h5\n",
      "4688/4688 [==============================] - 65s 14ms/step - loss: 0.0470 - val_loss: 0.0486 - val_loss_macro: 0.0486\n",
      "Epoch 7/50\n",
      "4688/4688 [==============================] - 24s 5ms/step - loss: 0.0444\n",
      "Epoch 8/50\n",
      "4686/4688 [============================>.] - ETA: 0s - loss: 0.0424  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 8] macro=0.047498  (per-cell: 0.0475)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run3_best.h5\n",
      "4688/4688 [==============================] - 66s 14ms/step - loss: 0.0424 - val_loss: 0.0475 - val_loss_macro: 0.0475\n",
      "Epoch 9/50\n",
      "4688/4688 [==============================] - 25s 5ms/step - loss: 0.0407\n",
      "Epoch 10/50\n",
      "4687/4688 [============================>.] - ETA: 0s - loss: 0.0395  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 10] macro=0.046707  (per-cell: 0.0467)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run3_best.h5\n",
      "4688/4688 [==============================] - 66s 14ms/step - loss: 0.0395 - val_loss: 0.0467 - val_loss_macro: 0.0467\n",
      "Epoch 11/50\n",
      "4688/4688 [==============================] - 25s 5ms/step - loss: 0.0383\n",
      "Epoch 12/50\n",
      "4681/4688 [============================>.] - ETA: 0s - loss: 0.0373  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 12] macro=0.046528  (per-cell: 0.0465)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run3_best.h5\n",
      "4688/4688 [==============================] - 66s 14ms/step - loss: 0.0373 - val_loss: 0.0465 - val_loss_macro: 0.0465\n",
      "Epoch 13/50\n",
      "4688/4688 [==============================] - 24s 5ms/step - loss: 0.0365\n",
      "Epoch 14/50\n",
      "4687/4688 [============================>.] - ETA: 0s - loss: 0.0357  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 14] macro=0.046762  (per-cell: 0.0468)\n",
      "4688/4688 [==============================] - 65s 14ms/step - loss: 0.0357 - val_loss: 0.0468 - val_loss_macro: 0.0468\n",
      "Epoch 15/50\n",
      "4688/4688 [==============================] - 23s 5ms/step - loss: 0.0351\n",
      "Epoch 16/50\n",
      "4679/4688 [============================>.] - ETA: 0s - loss: 0.0345  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 16] macro=0.045876  (per-cell: 0.0459)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run3_best.h5\n",
      "4688/4688 [==============================] - 64s 14ms/step - loss: 0.0345 - val_loss: 0.0459 - val_loss_macro: 0.0459\n",
      "Epoch 17/50\n",
      "4688/4688 [==============================] - 23s 5ms/step - loss: 0.0339\n",
      "Epoch 18/50\n",
      "4679/4688 [============================>.] - ETA: 0s - loss: 0.0333  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 18] macro=0.044923  (per-cell: 0.0449)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run3_best.h5\n",
      "4688/4688 [==============================] - 64s 14ms/step - loss: 0.0333 - val_loss: 0.0449 - val_loss_macro: 0.0449\n",
      "Epoch 19/50\n",
      "4688/4688 [==============================] - 23s 5ms/step - loss: 0.0328\n",
      "Epoch 20/50\n",
      "4686/4688 [============================>.] - ETA: 0s - loss: 0.0321  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 20] macro=0.043768  (per-cell: 0.0438)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run3_best.h5\n",
      "4688/4688 [==============================] - 68s 14ms/step - loss: 0.0321 - val_loss: 0.0438 - val_loss_macro: 0.0438\n",
      "Epoch 21/50\n",
      "4688/4688 [==============================] - 24s 5ms/step - loss: 0.0314\n",
      "Epoch 22/50\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 0.0308  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 22] macro=0.043484  (per-cell: 0.0435)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run3_best.h5\n",
      "4688/4688 [==============================] - 65s 14ms/step - loss: 0.0308 - val_loss: 0.0435 - val_loss_macro: 0.0435\n",
      "Epoch 23/50\n",
      "4688/4688 [==============================] - 23s 5ms/step - loss: 0.0301\n",
      "Epoch 24/50\n",
      "4680/4688 [============================>.] - ETA: 0s - loss: 0.0294  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 24] macro=0.043620  (per-cell: 0.0436)\n",
      "4688/4688 [==============================] - 64s 14ms/step - loss: 0.0294 - val_loss: 0.0436 - val_loss_macro: 0.0436\n",
      "Epoch 25/50\n",
      "4688/4688 [==============================] - 23s 5ms/step - loss: 0.0287\n",
      "Epoch 26/50\n",
      "4686/4688 [============================>.] - ETA: 0s - loss: 0.0281  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 26] macro=0.044027  (per-cell: 0.0440)\n",
      "4688/4688 [==============================] - 64s 14ms/step - loss: 0.0281 - val_loss: 0.0440 - val_loss_macro: 0.0440\n",
      "Epoch 27/50\n",
      "4688/4688 [==============================] - 23s 5ms/step - loss: 0.0275\n",
      "Epoch 28/50\n",
      "4681/4688 [============================>.] - ETA: 0s - loss: 0.0270  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 28] macro=0.043055  (per-cell: 0.0431)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run3_best.h5\n",
      "4688/4688 [==============================] - 64s 14ms/step - loss: 0.0270 - val_loss: 0.0431 - val_loss_macro: 0.0431\n",
      "Epoch 29/50\n",
      "4688/4688 [==============================] - 23s 5ms/step - loss: 0.0265\n",
      "Epoch 30/50\n",
      "4687/4688 [============================>.] - ETA: 0s - loss: 0.0260  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 30] macro=0.042809  (per-cell: 0.0428)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run3_best.h5\n",
      "4688/4688 [==============================] - 64s 14ms/step - loss: 0.0260 - val_loss: 0.0428 - val_loss_macro: 0.0428\n",
      "Epoch 31/50\n",
      "4688/4688 [==============================] - 23s 5ms/step - loss: 0.0256\n",
      "Epoch 32/50\n",
      "4679/4688 [============================>.] - ETA: 0s - loss: 0.0252  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 32] macro=0.042129  (per-cell: 0.0421)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run3_best.h5\n",
      "4688/4688 [==============================] - 65s 14ms/step - loss: 0.0252 - val_loss: 0.0421 - val_loss_macro: 0.0421\n",
      "Epoch 33/50\n",
      "4688/4688 [==============================] - 23s 5ms/step - loss: 0.0249\n",
      "Epoch 34/50\n",
      "4687/4688 [============================>.] - ETA: 0s - loss: 0.0246  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 34] macro=0.042270  (per-cell: 0.0423)\n",
      "4688/4688 [==============================] - 64s 14ms/step - loss: 0.0245 - val_loss: 0.0423 - val_loss_macro: 0.0423\n",
      "Epoch 35/50\n",
      "4688/4688 [==============================] - 23s 5ms/step - loss: 0.0242\n",
      "Epoch 36/50\n",
      "4678/4688 [============================>.] - ETA: 0s - loss: 0.0240  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 36] macro=0.041713  (per-cell: 0.0417)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run3_best.h5\n",
      "4688/4688 [==============================] - 64s 14ms/step - loss: 0.0240 - val_loss: 0.0417 - val_loss_macro: 0.0417\n",
      "Epoch 37/50\n",
      "4688/4688 [==============================] - 23s 5ms/step - loss: 0.0238\n",
      "Epoch 38/50\n",
      "4680/4688 [============================>.] - ETA: 0s - loss: 0.0236  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 38] macro=0.042213  (per-cell: 0.0422)\n",
      "4688/4688 [==============================] - 65s 14ms/step - loss: 0.0236 - val_loss: 0.0422 - val_loss_macro: 0.0422\n",
      "Epoch 39/50\n",
      "4688/4688 [==============================] - 23s 5ms/step - loss: 0.0234\n",
      "Epoch 40/50\n",
      "4687/4688 [============================>.] - ETA: 0s - loss: 0.0233  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 40] macro=0.042399  (per-cell: 0.0424)\n",
      "4688/4688 [==============================] - 64s 14ms/step - loss: 0.0233 - val_loss: 0.0424 - val_loss_macro: 0.0424\n",
      "Epoch 41/50\n",
      "4688/4688 [==============================] - 23s 5ms/step - loss: 0.0231\n",
      "Epoch 42/50\n",
      "4682/4688 [============================>.] - ETA: 0s - loss: 0.0230  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 42] macro=0.042680  (per-cell: 0.0427)\n",
      "  ‚Üí LR reduced: 2.9329e-05 ‚Üí 1.46645e-05\n",
      "4688/4688 [==============================] - 64s 14ms/step - loss: 0.0230 - val_loss: 0.0427 - val_loss_macro: 0.0427\n",
      "Epoch 43/50\n",
      "4688/4688 [==============================] - 23s 5ms/step - loss: 0.0228\n",
      "Epoch 44/50\n",
      "4678/4688 [============================>.] - ETA: 0s - loss: 0.0227  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 44] macro=0.042587  (per-cell: 0.0426)\n",
      "4688/4688 [==============================] - 64s 14ms/step - loss: 0.0227 - val_loss: 0.0426 - val_loss_macro: 0.0426\n",
      "Epoch 45/50\n",
      "4688/4688 [==============================] - 23s 5ms/step - loss: 0.0227\n",
      "Epoch 46/50\n",
      "4678/4688 [============================>.] - ETA: 0s - loss: 0.0226  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 46] macro=0.042937  (per-cell: 0.0429)\n",
      "  ‚Üí Early stopping.\n",
      "4688/4688 [==============================] - 64s 14ms/step - loss: 0.0226 - val_loss: 0.0429 - val_loss_macro: 0.0429\n",
      "\n",
      "‚úÖ Training complete for run 'rs2_run3'. Best checkpoint: checkpoints/rs2_run3_best.h5\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run3_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells:   0%|                                        | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Testing PBROM_data_cell_D5C78.mat: using 'D5_Cells_1' scaler, ID: 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_D5C78.mat             [PITM] MSE=4.386e-05 RSEP=8.80% MAPE=9.77%    \n",
      "[RandomSearch] Run 3 ‚Üí avg_rsep_pitm=8.7975\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 4 / 20\n",
      "  window_size   = 100\n",
      "  lambda_phys   = 0.0901\n",
      "  batch_size    = 768\n",
      "  learning_rate = 3.29e-07\n",
      "  num_layers    = 4\n",
      "  embed_dim     = 96\n",
      "==================================================\n",
      "Mixed precision policy: mixed_float16\n",
      "Using default strategy (1 GPU or CPU).\n",
      "Batch per device: 768 | Global batch: 768\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (window_size=100, stride=1) ---\n",
      "This will create one giant, UNBALANCED, shuffled training set WITH SAMPLE WEIGHTS.\n",
      "Calculating local time percentiles (p95_t, p95_dt)...\n",
      "  p95_t=1.2396e+07, p95_dt=9.9020e+01\n",
      "\n",
      "--- Pass 1.5a: Finding group sizes for weighting ---\n",
      "  Group 'D5_Cells_1' has 1,199,901 windows.\n",
      "\n",
      "--- Calculating Sample Weights ---\n",
      "  Group 'D5_Cells_1' (count=1,199,901): weight = 1.0000\n",
      "\n",
      "--- Pass 1.5b: Processing and all groups (NO oversampling) ---\n",
      "\n",
      "Processing Group: D5_Cells_1 (ID=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Files for D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:18<00:00, 18.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created 1,199,900 windows (weight: 1.0000).\n",
      "\n",
      "--- ‚úÖ Pre-processing complete ---\n",
      "Converting to numpy arrays...\n",
      "Total windows generated (unbalanced): 1,199,900\n",
      "X_dyn shape: (1199900, 100, 7)\n",
      "X_st shape:  (1199900, 4)\n",
      "X_gid shape: (1199900, 1)\n",
      "y_train shape: (1199900, 2)\n",
      "weights shape: (1199900,)\n",
      "Generating and applying global shuffle...\n",
      "--- üî¨ Verifying Shuffle ---\n",
      "Group mix in first 1000 samples (unbalanced is OK): {0: 1000}\n",
      "‚ùå SHUFFLE FAILED. Check warnings above.\n",
      "\n",
      "‚úÖ build_training_arrays() complete with sample weights.\n",
      "--- ‚ö°Ô∏è Creating fast in-memory training dataset (with weights) ---\n",
      "  Total windows: 1,199,900\n",
      "  Steps per epoch: 1,563\n",
      "‚úÖ Training dataset (with sample weights) is ready.\n",
      "  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "Starting training for 50 epochs (train steps/epoch ‚âà 1,563, batch=768)\n",
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 85s 35ms/step - loss: 0.4794\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4548  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 2] macro=0.450854  (per-cell: 0.4509)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 126s 80ms/step - loss: 0.4548 - val_loss: 0.4509 - val_loss_macro: 0.4509\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4509\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4491  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 4] macro=0.449373  (per-cell: 0.4494)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 120s 77ms/step - loss: 0.4491 - val_loss: 0.4494 - val_loss_macro: 0.4494\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4476\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4462  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 6] macro=0.447235  (per-cell: 0.4472)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.4462 - val_loss: 0.4472 - val_loss_macro: 0.4472\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4449\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4437  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 8] macro=0.444845  (per-cell: 0.4448)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.4437 - val_loss: 0.4448 - val_loss_macro: 0.4448\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4424\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4410  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 10] macro=0.442299  (per-cell: 0.4423)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.4410 - val_loss: 0.4423 - val_loss_macro: 0.4423\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4397\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4383  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 12] macro=0.439585  (per-cell: 0.4396)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.4383 - val_loss: 0.4396 - val_loss_macro: 0.4396\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4368\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4352  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 14] macro=0.436639  (per-cell: 0.4366)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 75ms/step - loss: 0.4352 - val_loss: 0.4366 - val_loss_macro: 0.4366\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4336\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4318  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 16] macro=0.433460  (per-cell: 0.4335)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.4318 - val_loss: 0.4335 - val_loss_macro: 0.4335\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4300\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4281  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 18] macro=0.430070  (per-cell: 0.4301)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.4281 - val_loss: 0.4301 - val_loss_macro: 0.4301\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4262\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4242  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 20] macro=0.426296  (per-cell: 0.4263)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 75ms/step - loss: 0.4242 - val_loss: 0.4263 - val_loss_macro: 0.4263\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4224\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4206  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 22] macro=0.422685  (per-cell: 0.4227)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.4206 - val_loss: 0.4227 - val_loss_macro: 0.4227\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4190\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4176  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 24] macro=0.419656  (per-cell: 0.4197)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.4176 - val_loss: 0.4197 - val_loss_macro: 0.4197\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4161\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4148  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 26] macro=0.416947  (per-cell: 0.4169)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.4148 - val_loss: 0.4169 - val_loss_macro: 0.4169\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4136\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4124  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 28] macro=0.414609  (per-cell: 0.4146)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.4124 - val_loss: 0.4146 - val_loss_macro: 0.4146\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4111\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4099  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 30] macro=0.412482  (per-cell: 0.4125)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 75ms/step - loss: 0.4099 - val_loss: 0.4125 - val_loss_macro: 0.4125\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4087\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4075  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 32] macro=0.410561  (per-cell: 0.4106)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 75ms/step - loss: 0.4075 - val_loss: 0.4106 - val_loss_macro: 0.4106\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4064\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4052  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 34] macro=0.408850  (per-cell: 0.4089)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.4052 - val_loss: 0.4089 - val_loss_macro: 0.4089\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4041\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4030  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 36] macro=0.407165  (per-cell: 0.4072)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.4030 - val_loss: 0.4072 - val_loss_macro: 0.4072\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4019\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4008  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 38] macro=0.405570  (per-cell: 0.4056)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.4008 - val_loss: 0.4056 - val_loss_macro: 0.4056\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.3995\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3987  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 40] macro=0.404017  (per-cell: 0.4040)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 119s 76ms/step - loss: 0.3987 - val_loss: 0.4040 - val_loss_macro: 0.4040\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.3975\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3966  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 42] macro=0.402473  (per-cell: 0.4025)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.3966 - val_loss: 0.4025 - val_loss_macro: 0.4025\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.3955\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3945  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 44] macro=0.400834  (per-cell: 0.4008)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.3945 - val_loss: 0.4008 - val_loss_macro: 0.4008\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.3935\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3924  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 46] macro=0.399182  (per-cell: 0.3992)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.3924 - val_loss: 0.3992 - val_loss_macro: 0.3992\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.3916\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3906  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 48] macro=0.397520  (per-cell: 0.3975)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.3906 - val_loss: 0.3975 - val_loss_macro: 0.3975\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.3897\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3887  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 50] macro=0.395857  (per-cell: 0.3959)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run4_best.h5\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.3887 - val_loss: 0.3959 - val_loss_macro: 0.3959\n",
      "\n",
      "‚úÖ Training complete for run 'rs2_run4'. Best checkpoint: checkpoints/rs2_run4_best.h5\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run4_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells:   0%|                                        | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Testing PBROM_data_cell_D5C78.mat: using 'D5_Cells_1' scaler, ID: 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:25<00:00, 25.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_D5C78.mat             [PITM] MSE=5.964e-04 RSEP=32.44% MAPE=38.91%    \n",
      "[RandomSearch] Run 4 ‚Üí avg_rsep_pitm=32.4418\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 5 / 20\n",
      "  window_size   = 10\n",
      "  lambda_phys   = 0.6980\n",
      "  batch_size    = 768\n",
      "  learning_rate = 4.79e-08\n",
      "  num_layers    = 1\n",
      "  embed_dim     = 64\n",
      "==================================================\n",
      "Mixed precision policy: mixed_float16\n",
      "Using default strategy (1 GPU or CPU).\n",
      "Batch per device: 768 | Global batch: 768\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (window_size=10, stride=1) ---\n",
      "This will create one giant, UNBALANCED, shuffled training set WITH SAMPLE WEIGHTS.\n",
      "Calculating local time percentiles (p95_t, p95_dt)...\n",
      "  p95_t=1.2396e+07, p95_dt=9.9020e+01\n",
      "\n",
      "--- Pass 1.5a: Finding group sizes for weighting ---\n",
      "  Group 'D5_Cells_1' has 1,199,991 windows.\n",
      "\n",
      "--- Calculating Sample Weights ---\n",
      "  Group 'D5_Cells_1' (count=1,199,991): weight = 1.0000\n",
      "\n",
      "--- Pass 1.5b: Processing and all groups (NO oversampling) ---\n",
      "\n",
      "Processing Group: D5_Cells_1 (ID=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Files for D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:16<00:00, 16.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created 1,199,990 windows (weight: 1.0000).\n",
      "\n",
      "--- ‚úÖ Pre-processing complete ---\n",
      "Converting to numpy arrays...\n",
      "Total windows generated (unbalanced): 1,199,990\n",
      "X_dyn shape: (1199990, 10, 7)\n",
      "X_st shape:  (1199990, 4)\n",
      "X_gid shape: (1199990, 1)\n",
      "y_train shape: (1199990, 2)\n",
      "weights shape: (1199990,)\n",
      "Generating and applying global shuffle...\n",
      "--- üî¨ Verifying Shuffle ---\n",
      "Group mix in first 1000 samples (unbalanced is OK): {0: 1000}\n",
      "‚ùå SHUFFLE FAILED. Check warnings above.\n",
      "\n",
      "‚úÖ build_training_arrays() complete with sample weights.\n",
      "--- ‚ö°Ô∏è Creating fast in-memory training dataset (with weights) ---\n",
      "  Total windows: 1,199,990\n",
      "  Steps per epoch: 1,563\n",
      "‚úÖ Training dataset (with sample weights) is ready.\n",
      "  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "Starting training for 50 epochs (train steps/epoch ‚âà 1,563, batch=768)\n",
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 20s 5ms/step - loss: 0.3015\n",
      "Epoch 2/50\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.2936  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 2] macro=0.310024  (per-cell: 0.3100)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 0.2936 - val_loss: 0.3100 - val_loss_macro: 0.3100\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2867\n",
      "Epoch 4/50\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.2808  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 4] macro=0.294633  (per-cell: 0.2946)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 0.2807 - val_loss: 0.2946 - val_loss_macro: 0.2946\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2759\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2718  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 6] macro=0.284893  (per-cell: 0.2849)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 0.2718 - val_loss: 0.2849 - val_loss_macro: 0.2849\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2686\n",
      "Epoch 8/50\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.2656  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 8] macro=0.278279  (per-cell: 0.2783)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.2656 - val_loss: 0.2783 - val_loss_macro: 0.2783\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2632\n",
      "Epoch 10/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2611  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 10] macro=0.273498  (per-cell: 0.2735)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.2611 - val_loss: 0.2735 - val_loss_macro: 0.2735\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2593\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2576  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 12] macro=0.270129  (per-cell: 0.2701)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 49s 32ms/step - loss: 0.2576 - val_loss: 0.2701 - val_loss_macro: 0.2701\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.2564\n",
      "Epoch 14/50\n",
      "1556/1563 [============================>.] - ETA: 0s - loss: 0.2552  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 14] macro=0.267660  (per-cell: 0.2677)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.2552 - val_loss: 0.2677 - val_loss_macro: 0.2677\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2542\n",
      "Epoch 16/50\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.2533  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 16] macro=0.265830  (per-cell: 0.2658)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.2533 - val_loss: 0.2658 - val_loss_macro: 0.2658\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2526\n",
      "Epoch 18/50\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.2518  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 18] macro=0.264438  (per-cell: 0.2644)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 0.2518 - val_loss: 0.2644 - val_loss_macro: 0.2644\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2513\n",
      "Epoch 20/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2505  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 20] macro=0.263378  (per-cell: 0.2634)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.2506 - val_loss: 0.2634 - val_loss_macro: 0.2634\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.2503\n",
      "Epoch 22/50\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.2497  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 22] macro=0.262529  (per-cell: 0.2625)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.2497 - val_loss: 0.2625 - val_loss_macro: 0.2625\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2493\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2488  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 24] macro=0.261844  (per-cell: 0.2618)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 0.2488 - val_loss: 0.2618 - val_loss_macro: 0.2618\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.2486\n",
      "Epoch 26/50\n",
      "1556/1563 [============================>.] - ETA: 0s - loss: 0.2482  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 26] macro=0.261284  (per-cell: 0.2613)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 0.2482 - val_loss: 0.2613 - val_loss_macro: 0.2613\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2480\n",
      "Epoch 28/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2476  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 28] macro=0.260805  (per-cell: 0.2608)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 0.2476 - val_loss: 0.2608 - val_loss_macro: 0.2608\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.2473\n",
      "Epoch 30/50\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.2471  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 30] macro=0.260391  (per-cell: 0.2604)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 0.2471 - val_loss: 0.2604 - val_loss_macro: 0.2604\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.2469\n",
      "Epoch 32/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2468  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 32] macro=0.260023  (per-cell: 0.2600)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.2468 - val_loss: 0.2600 - val_loss_macro: 0.2600\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2464\n",
      "Epoch 34/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2463  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 34] macro=0.259681  (per-cell: 0.2597)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 0.2463 - val_loss: 0.2597 - val_loss_macro: 0.2597\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2461\n",
      "Epoch 36/50\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.2460  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 36] macro=0.259362  (per-cell: 0.2594)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.2460 - val_loss: 0.2594 - val_loss_macro: 0.2594\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2458\n",
      "Epoch 38/50\n",
      "1556/1563 [============================>.] - ETA: 0s - loss: 0.2456  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 38] macro=0.259062  (per-cell: 0.2591)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.2457 - val_loss: 0.2591 - val_loss_macro: 0.2591\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2454\n",
      "Epoch 40/50\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.2453  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 40] macro=0.258773  (per-cell: 0.2588)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 0.2453 - val_loss: 0.2588 - val_loss_macro: 0.2588\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.2452\n",
      "Epoch 42/50\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.2450  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 42] macro=0.258488  (per-cell: 0.2585)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.2450 - val_loss: 0.2585 - val_loss_macro: 0.2585\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2449\n",
      "Epoch 44/50\n",
      "1556/1563 [============================>.] - ETA: 0s - loss: 0.2447  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 44] macro=0.258207  (per-cell: 0.2582)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.2447 - val_loss: 0.2582 - val_loss_macro: 0.2582\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2445\n",
      "Epoch 46/50\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.2445  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 46] macro=0.257927  (per-cell: 0.2579)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.2445 - val_loss: 0.2579 - val_loss_macro: 0.2579\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.2443\n",
      "Epoch 48/50\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.2441  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 48] macro=0.257650  (per-cell: 0.2576)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 0.2442 - val_loss: 0.2577 - val_loss_macro: 0.2576\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2440\n",
      "Epoch 50/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2440  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 50] macro=0.257366  (per-cell: 0.2574)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run5_best.h5\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 0.2440 - val_loss: 0.2574 - val_loss_macro: 0.2574\n",
      "\n",
      "‚úÖ Training complete for run 'rs2_run5'. Best checkpoint: checkpoints/rs2_run5_best.h5\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run5_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells:   0%|                                        | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Testing PBROM_data_cell_D5C78.mat: using 'D5_Cells_1' scaler, ID: 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_D5C78.mat             [PITM] MSE=1.022e-03 RSEP=42.47% MAPE=49.16%    \n",
      "[RandomSearch] Run 5 ‚Üí avg_rsep_pitm=42.4712\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 6 / 20\n",
      "  window_size   = 100\n",
      "  lambda_phys   = 0.6279\n",
      "  batch_size    = 64\n",
      "  learning_rate = 1.42e-07\n",
      "  num_layers    = 4\n",
      "  embed_dim     = 128\n",
      "==================================================\n",
      "Mixed precision policy: mixed_float16\n",
      "Using default strategy (1 GPU or CPU).\n",
      "Batch per device: 64 | Global batch: 64\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (window_size=100, stride=1) ---\n",
      "This will create one giant, UNBALANCED, shuffled training set WITH SAMPLE WEIGHTS.\n",
      "Calculating local time percentiles (p95_t, p95_dt)...\n",
      "  p95_t=1.2396e+07, p95_dt=9.9020e+01\n",
      "\n",
      "--- Pass 1.5a: Finding group sizes for weighting ---\n",
      "  Group 'D5_Cells_1' has 1,199,901 windows.\n",
      "\n",
      "--- Calculating Sample Weights ---\n",
      "  Group 'D5_Cells_1' (count=1,199,901): weight = 1.0000\n",
      "\n",
      "--- Pass 1.5b: Processing and all groups (NO oversampling) ---\n",
      "\n",
      "Processing Group: D5_Cells_1 (ID=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Files for D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:20<00:00, 20.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created 1,199,900 windows (weight: 1.0000).\n",
      "\n",
      "--- ‚úÖ Pre-processing complete ---\n",
      "Converting to numpy arrays...\n",
      "Total windows generated (unbalanced): 1,199,900\n",
      "X_dyn shape: (1199900, 100, 7)\n",
      "X_st shape:  (1199900, 4)\n",
      "X_gid shape: (1199900, 1)\n",
      "y_train shape: (1199900, 2)\n",
      "weights shape: (1199900,)\n",
      "Generating and applying global shuffle...\n",
      "--- üî¨ Verifying Shuffle ---\n",
      "Group mix in first 1000 samples (unbalanced is OK): {0: 1000}\n",
      "‚ùå SHUFFLE FAILED. Check warnings above.\n",
      "\n",
      "‚úÖ build_training_arrays() complete with sample weights.\n",
      "--- ‚ö°Ô∏è Creating fast in-memory training dataset (with weights) ---\n",
      "  Total windows: 1,199,900\n",
      "  Steps per epoch: 18,749\n",
      "‚úÖ Training dataset (with sample weights) is ready.\n",
      "  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "Starting training for 50 epochs (train steps/epoch ‚âà 18,749, batch=64)\n",
      "Epoch 1/50\n",
      "18749/18749 [==============================] - 626s 32ms/step - loss: 0.5443\n",
      "Epoch 2/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.5286  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 2] macro=0.543213  (per-cell: 0.5432)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 692s 37ms/step - loss: 0.5286 - val_loss: 0.5432 - val_loss_macro: 0.5432\n",
      "Epoch 3/50\n",
      "18749/18749 [==============================] - 600s 32ms/step - loss: 0.5255\n",
      "Epoch 4/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.5225  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 4] macro=0.536661  (per-cell: 0.5367)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 675s 36ms/step - loss: 0.5225 - val_loss: 0.5366 - val_loss_macro: 0.5367\n",
      "Epoch 5/50\n",
      "18749/18749 [==============================] - 572s 30ms/step - loss: 0.5192\n",
      "Epoch 6/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.5153  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 6] macro=0.527499  (per-cell: 0.5275)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 654s 35ms/step - loss: 0.5153 - val_loss: 0.5275 - val_loss_macro: 0.5275\n",
      "Epoch 7/50\n",
      "18749/18749 [==============================] - 567s 30ms/step - loss: 0.5108\n",
      "Epoch 8/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.5059  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 8] macro=0.521217  (per-cell: 0.5212)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 654s 35ms/step - loss: 0.5059 - val_loss: 0.5212 - val_loss_macro: 0.5212\n",
      "Epoch 9/50\n",
      "18749/18749 [==============================] - 566s 30ms/step - loss: 0.5011\n",
      "Epoch 10/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4964  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 10] macro=0.517213  (per-cell: 0.5172)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 653s 35ms/step - loss: 0.4964 - val_loss: 0.5172 - val_loss_macro: 0.5172\n",
      "Epoch 11/50\n",
      "18749/18749 [==============================] - 565s 30ms/step - loss: 0.4923\n",
      "Epoch 12/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4891  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 12] macro=0.512503  (per-cell: 0.5125)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 652s 35ms/step - loss: 0.4891 - val_loss: 0.5125 - val_loss_macro: 0.5125\n",
      "Epoch 13/50\n",
      "18749/18749 [==============================] - 565s 30ms/step - loss: 0.4864\n",
      "Epoch 14/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4842  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 14] macro=0.508730  (per-cell: 0.5087)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 651s 35ms/step - loss: 0.4842 - val_loss: 0.5087 - val_loss_macro: 0.5087\n",
      "Epoch 15/50\n",
      "18749/18749 [==============================] - 569s 30ms/step - loss: 0.4821\n",
      "Epoch 16/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4804  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 16] macro=0.505002  (per-cell: 0.5050)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 655s 35ms/step - loss: 0.4804 - val_loss: 0.5050 - val_loss_macro: 0.5050\n",
      "Epoch 17/50\n",
      "18749/18749 [==============================] - 564s 30ms/step - loss: 0.4786\n",
      "Epoch 18/50\n",
      "18748/18749 [============================>.] - ETA: 0s - loss: 0.4770  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 18] macro=0.501531  (per-cell: 0.5015)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 652s 35ms/step - loss: 0.4770 - val_loss: 0.5015 - val_loss_macro: 0.5015\n",
      "Epoch 19/50\n",
      "18749/18749 [==============================] - 563s 30ms/step - loss: 0.4755\n",
      "Epoch 20/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4739  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 20] macro=0.498151  (per-cell: 0.4982)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 650s 35ms/step - loss: 0.4739 - val_loss: 0.4981 - val_loss_macro: 0.4982\n",
      "Epoch 21/50\n",
      "18749/18749 [==============================] - 563s 30ms/step - loss: 0.4724\n",
      "Epoch 22/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4708  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 22] macro=0.495073  (per-cell: 0.4951)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 649s 35ms/step - loss: 0.4708 - val_loss: 0.4950 - val_loss_macro: 0.4951\n",
      "Epoch 23/50\n",
      "18749/18749 [==============================] - 563s 30ms/step - loss: 0.4693\n",
      "Epoch 24/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4677  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 24] macro=0.491984  (per-cell: 0.4920)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 651s 35ms/step - loss: 0.4677 - val_loss: 0.4920 - val_loss_macro: 0.4920\n",
      "Epoch 25/50\n",
      "18749/18749 [==============================] - 562s 30ms/step - loss: 0.4662\n",
      "Epoch 26/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4646  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 26] macro=0.488809  (per-cell: 0.4888)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 649s 35ms/step - loss: 0.4646 - val_loss: 0.4888 - val_loss_macro: 0.4888\n",
      "Epoch 27/50\n",
      "18749/18749 [==============================] - 563s 30ms/step - loss: 0.4631\n",
      "Epoch 28/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4615  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 28] macro=0.485821  (per-cell: 0.4858)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 648s 35ms/step - loss: 0.4615 - val_loss: 0.4859 - val_loss_macro: 0.4858\n",
      "Epoch 29/50\n",
      "18749/18749 [==============================] - 562s 30ms/step - loss: 0.4598\n",
      "Epoch 30/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4579  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 30] macro=0.482151  (per-cell: 0.4822)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 649s 35ms/step - loss: 0.4579 - val_loss: 0.4821 - val_loss_macro: 0.4822\n",
      "Epoch 31/50\n",
      "18749/18749 [==============================] - 563s 30ms/step - loss: 0.4556\n",
      "Epoch 32/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4525  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 32] macro=0.478532  (per-cell: 0.4785)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 647s 34ms/step - loss: 0.4525 - val_loss: 0.4786 - val_loss_macro: 0.4785\n",
      "Epoch 33/50\n",
      "18749/18749 [==============================] - 561s 30ms/step - loss: 0.4482\n",
      "Epoch 34/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4435  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 34] macro=0.476757  (per-cell: 0.4768)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 650s 35ms/step - loss: 0.4435 - val_loss: 0.4767 - val_loss_macro: 0.4768\n",
      "Epoch 35/50\n",
      "18749/18749 [==============================] - 561s 30ms/step - loss: 0.4397\n",
      "Epoch 36/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4366  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 36] macro=0.474948  (per-cell: 0.4749)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 648s 35ms/step - loss: 0.4366 - val_loss: 0.4750 - val_loss_macro: 0.4749\n",
      "Epoch 37/50\n",
      "18749/18749 [==============================] - 563s 30ms/step - loss: 0.4342\n",
      "Epoch 38/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4322  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 38] macro=0.472544  (per-cell: 0.4725)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 646s 34ms/step - loss: 0.4322 - val_loss: 0.4725 - val_loss_macro: 0.4725\n",
      "Epoch 39/50\n",
      "18749/18749 [==============================] - 566s 30ms/step - loss: 0.4305\n",
      "Epoch 40/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4287  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 40] macro=0.470285  (per-cell: 0.4703)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 654s 35ms/step - loss: 0.4287 - val_loss: 0.4703 - val_loss_macro: 0.4703\n",
      "Epoch 41/50\n",
      "18749/18749 [==============================] - 561s 30ms/step - loss: 0.4272\n",
      "Epoch 42/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4257  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 42] macro=0.468172  (per-cell: 0.4682)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 650s 35ms/step - loss: 0.4257 - val_loss: 0.4682 - val_loss_macro: 0.4682\n",
      "Epoch 43/50\n",
      "18749/18749 [==============================] - 561s 30ms/step - loss: 0.4244\n",
      "Epoch 44/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4231  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 44] macro=0.466290  (per-cell: 0.4663)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 651s 35ms/step - loss: 0.4231 - val_loss: 0.4663 - val_loss_macro: 0.4663\n",
      "Epoch 45/50\n",
      "18749/18749 [==============================] - 562s 30ms/step - loss: 0.4218\n",
      "Epoch 46/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4205  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 46] macro=0.464392  (per-cell: 0.4644)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 647s 35ms/step - loss: 0.4205 - val_loss: 0.4644 - val_loss_macro: 0.4644\n",
      "Epoch 47/50\n",
      "18749/18749 [==============================] - 563s 30ms/step - loss: 0.4193\n",
      "Epoch 48/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4181  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 48] macro=0.463353  (per-cell: 0.4634)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 651s 35ms/step - loss: 0.4181 - val_loss: 0.4633 - val_loss_macro: 0.4634\n",
      "Epoch 49/50\n",
      "18749/18749 [==============================] - 564s 30ms/step - loss: 0.4170\n",
      "Epoch 50/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4159  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 50] macro=0.461432  (per-cell: 0.4614)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run6_best.h5\n",
      "18749/18749 [==============================] - 652s 35ms/step - loss: 0.4159 - val_loss: 0.4614 - val_loss_macro: 0.4614\n",
      "\n",
      "‚úÖ Training complete for run 'rs2_run6'. Best checkpoint: checkpoints/rs2_run6_best.h5\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run6_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells:   0%|                                        | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Testing PBROM_data_cell_D5C78.mat: using 'D5_Cells_1' scaler, ID: 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:28<00:00, 28.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_D5C78.mat             [PITM] MSE=7.816e-05 RSEP=11.74% MAPE=14.02%    \n",
      "[RandomSearch] Run 6 ‚Üí avg_rsep_pitm=11.7439\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 7 / 20\n",
      "  window_size   = 150\n",
      "  lambda_phys   = 0.8725\n",
      "  batch_size    = 512\n",
      "  learning_rate = 1.83e-06\n",
      "  num_layers    = 2\n",
      "  embed_dim     = 96\n",
      "==================================================\n",
      "Mixed precision policy: mixed_float16\n",
      "Using default strategy (1 GPU or CPU).\n",
      "Batch per device: 512 | Global batch: 512\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (window_size=150, stride=1) ---\n",
      "This will create one giant, UNBALANCED, shuffled training set WITH SAMPLE WEIGHTS.\n",
      "Calculating local time percentiles (p95_t, p95_dt)...\n",
      "  p95_t=1.2396e+07, p95_dt=9.9020e+01\n",
      "\n",
      "--- Pass 1.5a: Finding group sizes for weighting ---\n",
      "  Group 'D5_Cells_1' has 1,199,851 windows.\n",
      "\n",
      "--- Calculating Sample Weights ---\n",
      "  Group 'D5_Cells_1' (count=1,199,851): weight = 1.0000\n",
      "\n",
      "--- Pass 1.5b: Processing and all groups (NO oversampling) ---\n",
      "\n",
      "Processing Group: D5_Cells_1 (ID=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Files for D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:18<00:00, 18.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created 1,199,850 windows (weight: 1.0000).\n",
      "\n",
      "--- ‚úÖ Pre-processing complete ---\n",
      "Converting to numpy arrays...\n",
      "Total windows generated (unbalanced): 1,199,850\n",
      "X_dyn shape: (1199850, 150, 7)\n",
      "X_st shape:  (1199850, 4)\n",
      "X_gid shape: (1199850, 1)\n",
      "y_train shape: (1199850, 2)\n",
      "weights shape: (1199850,)\n",
      "Generating and applying global shuffle...\n",
      "--- üî¨ Verifying Shuffle ---\n",
      "Group mix in first 1000 samples (unbalanced is OK): {0: 1000}\n",
      "‚ùå SHUFFLE FAILED. Check warnings above.\n",
      "\n",
      "‚úÖ build_training_arrays() complete with sample weights.\n",
      "--- ‚ö°Ô∏è Creating fast in-memory training dataset (with weights) ---\n",
      "  Total windows: 1,199,850\n",
      "  Steps per epoch: 2,344\n",
      "‚úÖ Training dataset (with sample weights) is ready.\n",
      "  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "Starting training for 50 epochs (train steps/epoch ‚âà 2,344, batch=512)\n",
      "Epoch 1/50\n",
      "2344/2344 [==============================] - 78s 25ms/step - loss: 0.3942\n",
      "Epoch 2/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.3486  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 2] macro=0.371809  (per-cell: 0.3718)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 124s 53ms/step - loss: 0.3486 - val_loss: 0.3718 - val_loss_macro: 0.3718\n",
      "Epoch 3/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.3372\n",
      "Epoch 4/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.3260  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 4] macro=0.360864  (per-cell: 0.3609)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 121s 52ms/step - loss: 0.3260 - val_loss: 0.3609 - val_loss_macro: 0.3609\n",
      "Epoch 5/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.3177\n",
      "Epoch 6/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.3115  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 6] macro=0.349682  (per-cell: 0.3497)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 122s 52ms/step - loss: 0.3115 - val_loss: 0.3497 - val_loss_macro: 0.3497\n",
      "Epoch 7/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.3061\n",
      "Epoch 8/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.3014  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 8] macro=0.341059  (per-cell: 0.3411)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 121s 52ms/step - loss: 0.3015 - val_loss: 0.3411 - val_loss_macro: 0.3411\n",
      "Epoch 9/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.2973\n",
      "Epoch 10/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.2935  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 10] macro=0.331411  (per-cell: 0.3314)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 122s 52ms/step - loss: 0.2935 - val_loss: 0.3314 - val_loss_macro: 0.3314\n",
      "Epoch 11/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.2900\n",
      "Epoch 12/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.2864  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 12] macro=0.321790  (per-cell: 0.3218)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 122s 52ms/step - loss: 0.2864 - val_loss: 0.3218 - val_loss_macro: 0.3218\n",
      "Epoch 13/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.2822\n",
      "Epoch 14/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.2738  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 14] macro=0.311018  (per-cell: 0.3110)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 122s 52ms/step - loss: 0.2738 - val_loss: 0.3110 - val_loss_macro: 0.3110\n",
      "Epoch 15/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.2613\n",
      "Epoch 16/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.2541  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 16] macro=0.308264  (per-cell: 0.3083)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 122s 52ms/step - loss: 0.2541 - val_loss: 0.3083 - val_loss_macro: 0.3083\n",
      "Epoch 17/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.2502\n",
      "Epoch 18/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2471  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 18] macro=0.304613  (per-cell: 0.3046)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 121s 52ms/step - loss: 0.2471 - val_loss: 0.3046 - val_loss_macro: 0.3046\n",
      "Epoch 19/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.2442\n",
      "Epoch 20/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.2414  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 20] macro=0.302247  (per-cell: 0.3022)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 121s 52ms/step - loss: 0.2414 - val_loss: 0.3022 - val_loss_macro: 0.3022\n",
      "Epoch 21/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.2388\n",
      "Epoch 22/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2362  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 22] macro=0.300382  (per-cell: 0.3004)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 121s 52ms/step - loss: 0.2362 - val_loss: 0.3004 - val_loss_macro: 0.3004\n",
      "Epoch 23/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.2338\n",
      "Epoch 24/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2315  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 24] macro=0.298428  (per-cell: 0.2984)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 121s 52ms/step - loss: 0.2315 - val_loss: 0.2984 - val_loss_macro: 0.2984\n",
      "Epoch 25/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.2294\n",
      "Epoch 26/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.2274  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 26] macro=0.296356  (per-cell: 0.2964)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 121s 52ms/step - loss: 0.2274 - val_loss: 0.2964 - val_loss_macro: 0.2964\n",
      "Epoch 27/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.2255\n",
      "Epoch 28/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2237  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 28] macro=0.292330  (per-cell: 0.2923)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 121s 52ms/step - loss: 0.2237 - val_loss: 0.2923 - val_loss_macro: 0.2923\n",
      "Epoch 29/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.2220\n",
      "Epoch 30/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.2204  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 30] macro=0.289817  (per-cell: 0.2898)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 121s 52ms/step - loss: 0.2204 - val_loss: 0.2898 - val_loss_macro: 0.2898\n",
      "Epoch 31/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.2188\n",
      "Epoch 32/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.2173  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 32] macro=0.285642  (per-cell: 0.2856)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 121s 52ms/step - loss: 0.2173 - val_loss: 0.2856 - val_loss_macro: 0.2856\n",
      "Epoch 33/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.2159\n",
      "Epoch 34/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.2144  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 34] macro=0.283041  (per-cell: 0.2830)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 122s 52ms/step - loss: 0.2144 - val_loss: 0.2830 - val_loss_macro: 0.2830\n",
      "Epoch 35/50\n",
      "2344/2344 [==============================] - 59s 25ms/step - loss: 0.2130\n",
      "Epoch 36/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.2117  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 36] macro=0.280879  (per-cell: 0.2809)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 122s 52ms/step - loss: 0.2117 - val_loss: 0.2809 - val_loss_macro: 0.2809\n",
      "Epoch 37/50\n",
      "2344/2344 [==============================] - 59s 25ms/step - loss: 0.2103\n",
      "Epoch 38/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.2091  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 38] macro=0.277775  (per-cell: 0.2778)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 123s 52ms/step - loss: 0.2091 - val_loss: 0.2778 - val_loss_macro: 0.2778\n",
      "Epoch 39/50\n",
      "2344/2344 [==============================] - 59s 25ms/step - loss: 0.2078\n",
      "Epoch 40/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2067  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 40] macro=0.275720  (per-cell: 0.2757)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 122s 52ms/step - loss: 0.2067 - val_loss: 0.2757 - val_loss_macro: 0.2757\n",
      "Epoch 41/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.2055\n",
      "Epoch 42/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2043  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 42] macro=0.273018  (per-cell: 0.2730)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 122s 52ms/step - loss: 0.2043 - val_loss: 0.2730 - val_loss_macro: 0.2730\n",
      "Epoch 43/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.2033\n",
      "Epoch 44/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2022  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 44] macro=0.270710  (per-cell: 0.2707)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 122s 52ms/step - loss: 0.2022 - val_loss: 0.2707 - val_loss_macro: 0.2707\n",
      "Epoch 45/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.2011\n",
      "Epoch 46/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2001  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 46] macro=0.268687  (per-cell: 0.2687)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 122s 52ms/step - loss: 0.2001 - val_loss: 0.2687 - val_loss_macro: 0.2687\n",
      "Epoch 47/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.1990\n",
      "Epoch 48/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.1981  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 48] macro=0.266183  (per-cell: 0.2662)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 121s 52ms/step - loss: 0.1981 - val_loss: 0.2662 - val_loss_macro: 0.2662\n",
      "Epoch 49/50\n",
      "2344/2344 [==============================] - 58s 25ms/step - loss: 0.1971\n",
      "Epoch 50/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.1961  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 50] macro=0.264405  (per-cell: 0.2644)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run7_best.h5\n",
      "2344/2344 [==============================] - 122s 52ms/step - loss: 0.1961 - val_loss: 0.2644 - val_loss_macro: 0.2644\n",
      "\n",
      "‚úÖ Training complete for run 'rs2_run7'. Best checkpoint: checkpoints/rs2_run7_best.h5\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run7_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells:   0%|                                        | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Testing PBROM_data_cell_D5C78.mat: using 'D5_Cells_1' scaler, ID: 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:27<00:00, 27.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_D5C78.mat             [PITM] MSE=8.585e-05 RSEP=12.31% MAPE=15.26%    \n",
      "[RandomSearch] Run 7 ‚Üí avg_rsep_pitm=12.3084\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 8 / 20\n",
      "  window_size   = 10\n",
      "  lambda_phys   = 0.3558\n",
      "  batch_size    = 512\n",
      "  learning_rate = 3.03e-06\n",
      "  num_layers    = 4\n",
      "  embed_dim     = 32\n",
      "==================================================\n",
      "Mixed precision policy: mixed_float16\n",
      "Using default strategy (1 GPU or CPU).\n",
      "Batch per device: 512 | Global batch: 512\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (window_size=10, stride=1) ---\n",
      "This will create one giant, UNBALANCED, shuffled training set WITH SAMPLE WEIGHTS.\n",
      "Calculating local time percentiles (p95_t, p95_dt)...\n",
      "  p95_t=1.2396e+07, p95_dt=9.9020e+01\n",
      "\n",
      "--- Pass 1.5a: Finding group sizes for weighting ---\n",
      "  Group 'D5_Cells_1' has 1,199,991 windows.\n",
      "\n",
      "--- Calculating Sample Weights ---\n",
      "  Group 'D5_Cells_1' (count=1,199,991): weight = 1.0000\n",
      "\n",
      "--- Pass 1.5b: Processing and all groups (NO oversampling) ---\n",
      "\n",
      "Processing Group: D5_Cells_1 (ID=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Files for D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:16<00:00, 16.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created 1,199,990 windows (weight: 1.0000).\n",
      "\n",
      "--- ‚úÖ Pre-processing complete ---\n",
      "Converting to numpy arrays...\n",
      "Total windows generated (unbalanced): 1,199,990\n",
      "X_dyn shape: (1199990, 10, 7)\n",
      "X_st shape:  (1199990, 4)\n",
      "X_gid shape: (1199990, 1)\n",
      "y_train shape: (1199990, 2)\n",
      "weights shape: (1199990,)\n",
      "Generating and applying global shuffle...\n",
      "--- üî¨ Verifying Shuffle ---\n",
      "Group mix in first 1000 samples (unbalanced is OK): {0: 1000}\n",
      "‚ùå SHUFFLE FAILED. Check warnings above.\n",
      "\n",
      "‚úÖ build_training_arrays() complete with sample weights.\n",
      "--- ‚ö°Ô∏è Creating fast in-memory training dataset (with weights) ---\n",
      "  Total windows: 1,199,990\n",
      "  Steps per epoch: 2,344\n",
      "‚úÖ Training dataset (with sample weights) is ready.\n",
      "  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "Starting training for 50 epochs (train steps/epoch ‚âà 2,344, batch=512)\n",
      "Epoch 1/50\n",
      "2344/2344 [==============================] - 51s 11ms/step - loss: 0.3436\n",
      "Epoch 2/50\n",
      "2341/2344 [============================>.] - ETA: 0s - loss: 0.3122  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 2] macro=0.315473  (per-cell: 0.3155)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 71s 31ms/step - loss: 0.3122 - val_loss: 0.3155 - val_loss_macro: 0.3155\n",
      "Epoch 3/50\n",
      "2344/2344 [==============================] - 27s 12ms/step - loss: 0.3060\n",
      "Epoch 4/50\n",
      "2341/2344 [============================>.] - ETA: 0s - loss: 0.2998  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 4] macro=0.301216  (per-cell: 0.3012)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 68s 29ms/step - loss: 0.2998 - val_loss: 0.3012 - val_loss_macro: 0.3012\n",
      "Epoch 5/50\n",
      "2344/2344 [==============================] - 28s 12ms/step - loss: 0.2918\n",
      "Epoch 6/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.2787  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 6] macro=0.271637  (per-cell: 0.2716)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 68s 29ms/step - loss: 0.2787 - val_loss: 0.2716 - val_loss_macro: 0.2716\n",
      "Epoch 7/50\n",
      "2344/2344 [==============================] - 27s 12ms/step - loss: 0.2670\n",
      "Epoch 8/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2607  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 8] macro=0.268919  (per-cell: 0.2689)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 68s 29ms/step - loss: 0.2607 - val_loss: 0.2689 - val_loss_macro: 0.2689\n",
      "Epoch 9/50\n",
      "2344/2344 [==============================] - 27s 12ms/step - loss: 0.2558\n",
      "Epoch 10/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.2516  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 10] macro=0.260754  (per-cell: 0.2608)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 68s 29ms/step - loss: 0.2516 - val_loss: 0.2608 - val_loss_macro: 0.2608\n",
      "Epoch 11/50\n",
      "2344/2344 [==============================] - 27s 12ms/step - loss: 0.2476\n",
      "Epoch 12/50\n",
      "2340/2344 [============================>.] - ETA: 0s - loss: 0.2441  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 12] macro=0.252235  (per-cell: 0.2522)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 68s 29ms/step - loss: 0.2441 - val_loss: 0.2522 - val_loss_macro: 0.2522\n",
      "Epoch 13/50\n",
      "2344/2344 [==============================] - 27s 12ms/step - loss: 0.2407\n",
      "Epoch 14/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.2375  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 14] macro=0.245228  (per-cell: 0.2452)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 71s 30ms/step - loss: 0.2375 - val_loss: 0.2452 - val_loss_macro: 0.2452\n",
      "Epoch 15/50\n",
      "2344/2344 [==============================] - 30s 13ms/step - loss: 0.2344\n",
      "Epoch 16/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2315  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 16] macro=0.238416  (per-cell: 0.2384)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 73s 31ms/step - loss: 0.2315 - val_loss: 0.2384 - val_loss_macro: 0.2384\n",
      "Epoch 17/50\n",
      "2344/2344 [==============================] - 31s 13ms/step - loss: 0.2286\n",
      "Epoch 18/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.2258  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 18] macro=0.231965  (per-cell: 0.2320)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 72s 31ms/step - loss: 0.2258 - val_loss: 0.2320 - val_loss_macro: 0.2320\n",
      "Epoch 19/50\n",
      "2344/2344 [==============================] - 31s 13ms/step - loss: 0.2232\n",
      "Epoch 20/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.2204  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 20] macro=0.225712  (per-cell: 0.2257)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 72s 31ms/step - loss: 0.2204 - val_loss: 0.2257 - val_loss_macro: 0.2257\n",
      "Epoch 21/50\n",
      "2344/2344 [==============================] - 31s 13ms/step - loss: 0.2177\n",
      "Epoch 22/50\n",
      "2341/2344 [============================>.] - ETA: 0s - loss: 0.2148  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 22] macro=0.219497  (per-cell: 0.2195)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 73s 31ms/step - loss: 0.2148 - val_loss: 0.2195 - val_loss_macro: 0.2195\n",
      "Epoch 23/50\n",
      "2344/2344 [==============================] - 31s 13ms/step - loss: 0.2119\n",
      "Epoch 24/50\n",
      "2341/2344 [============================>.] - ETA: 0s - loss: 0.2086  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 24] macro=0.213250  (per-cell: 0.2133)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 72s 31ms/step - loss: 0.2086 - val_loss: 0.2133 - val_loss_macro: 0.2133\n",
      "Epoch 25/50\n",
      "2344/2344 [==============================] - 31s 13ms/step - loss: 0.2053\n",
      "Epoch 26/50\n",
      "2341/2344 [============================>.] - ETA: 0s - loss: 0.2023  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 26] macro=0.208316  (per-cell: 0.2083)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 73s 31ms/step - loss: 0.2023 - val_loss: 0.2083 - val_loss_macro: 0.2083\n",
      "Epoch 27/50\n",
      "2344/2344 [==============================] - 31s 13ms/step - loss: 0.1995\n",
      "Epoch 28/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.1970  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 28] macro=0.204329  (per-cell: 0.2043)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 74s 31ms/step - loss: 0.1970 - val_loss: 0.2043 - val_loss_macro: 0.2043\n",
      "Epoch 29/50\n",
      "2344/2344 [==============================] - 31s 13ms/step - loss: 0.1943\n",
      "Epoch 30/50\n",
      "2341/2344 [============================>.] - ETA: 0s - loss: 0.1915  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 30] macro=0.199678  (per-cell: 0.1997)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 72s 31ms/step - loss: 0.1914 - val_loss: 0.1997 - val_loss_macro: 0.1997\n",
      "Epoch 31/50\n",
      "2344/2344 [==============================] - 31s 13ms/step - loss: 0.1884\n",
      "Epoch 32/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.1856  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 32] macro=0.196351  (per-cell: 0.1964)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 72s 31ms/step - loss: 0.1856 - val_loss: 0.1964 - val_loss_macro: 0.1964\n",
      "Epoch 33/50\n",
      "2344/2344 [==============================] - 31s 13ms/step - loss: 0.1831\n",
      "Epoch 34/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.1809  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 34] macro=0.192600  (per-cell: 0.1926)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 72s 31ms/step - loss: 0.1809 - val_loss: 0.1926 - val_loss_macro: 0.1926\n",
      "Epoch 35/50\n",
      "2344/2344 [==============================] - 31s 13ms/step - loss: 0.1789\n",
      "Epoch 36/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.1771  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 36] macro=0.189437  (per-cell: 0.1894)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 72s 31ms/step - loss: 0.1771 - val_loss: 0.1894 - val_loss_macro: 0.1894\n",
      "Epoch 37/50\n",
      "2344/2344 [==============================] - 30s 13ms/step - loss: 0.1753\n",
      "Epoch 38/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.1738  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 38] macro=0.186144  (per-cell: 0.1861)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 71s 30ms/step - loss: 0.1738 - val_loss: 0.1861 - val_loss_macro: 0.1861\n",
      "Epoch 39/50\n",
      "2344/2344 [==============================] - 31s 13ms/step - loss: 0.1723\n",
      "Epoch 40/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.1708  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 40] macro=0.182437  (per-cell: 0.1824)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 73s 31ms/step - loss: 0.1708 - val_loss: 0.1824 - val_loss_macro: 0.1824\n",
      "Epoch 41/50\n",
      "2344/2344 [==============================] - 31s 13ms/step - loss: 0.1694\n",
      "Epoch 42/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.1681  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 42] macro=0.179606  (per-cell: 0.1796)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 72s 31ms/step - loss: 0.1681 - val_loss: 0.1796 - val_loss_macro: 0.1796\n",
      "Epoch 43/50\n",
      "2344/2344 [==============================] - 31s 13ms/step - loss: 0.1667\n",
      "Epoch 44/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.1656  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 44] macro=0.176970  (per-cell: 0.1770)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 72s 31ms/step - loss: 0.1656 - val_loss: 0.1770 - val_loss_macro: 0.1770\n",
      "Epoch 45/50\n",
      "2344/2344 [==============================] - 31s 13ms/step - loss: 0.1643\n",
      "Epoch 46/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.1631  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 46] macro=0.174478  (per-cell: 0.1745)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 73s 31ms/step - loss: 0.1631 - val_loss: 0.1745 - val_loss_macro: 0.1745\n",
      "Epoch 47/50\n",
      "2344/2344 [==============================] - 31s 13ms/step - loss: 0.1620\n",
      "Epoch 48/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.1608  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 48] macro=0.171911  (per-cell: 0.1719)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 74s 31ms/step - loss: 0.1608 - val_loss: 0.1719 - val_loss_macro: 0.1719\n",
      "Epoch 49/50\n",
      "2344/2344 [==============================] - 31s 13ms/step - loss: 0.1598\n",
      "Epoch 50/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.1587  ‚Üí STREAM: 1 files, 1,199,991 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 50] macro=0.169702  (per-cell: 0.1697)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run8_best.h5\n",
      "2344/2344 [==============================] - 73s 31ms/step - loss: 0.1587 - val_loss: 0.1697 - val_loss_macro: 0.1697\n",
      "\n",
      "‚úÖ Training complete for run 'rs2_run8'. Best checkpoint: checkpoints/rs2_run8_best.h5\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run8_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells:   0%|                                        | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Testing PBROM_data_cell_D5C78.mat: using 'D5_Cells_1' scaler, ID: 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_D5C78.mat             [PITM] MSE=6.258e-05 RSEP=10.51% MAPE=12.70%    \n",
      "[RandomSearch] Run 8 ‚Üí avg_rsep_pitm=10.5086\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 9 / 20\n",
      "  window_size   = 20\n",
      "  lambda_phys   = 0.7618\n",
      "  batch_size    = 512\n",
      "  learning_rate = 2.71e-05\n",
      "  num_layers    = 3\n",
      "  embed_dim     = 64\n",
      "==================================================\n",
      "Mixed precision policy: mixed_float16\n",
      "Using default strategy (1 GPU or CPU).\n",
      "Batch per device: 512 | Global batch: 512\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (window_size=20, stride=1) ---\n",
      "This will create one giant, UNBALANCED, shuffled training set WITH SAMPLE WEIGHTS.\n",
      "Calculating local time percentiles (p95_t, p95_dt)...\n",
      "  p95_t=1.2396e+07, p95_dt=9.9020e+01\n",
      "\n",
      "--- Pass 1.5a: Finding group sizes for weighting ---\n",
      "  Group 'D5_Cells_1' has 1,199,981 windows.\n",
      "\n",
      "--- Calculating Sample Weights ---\n",
      "  Group 'D5_Cells_1' (count=1,199,981): weight = 1.0000\n",
      "\n",
      "--- Pass 1.5b: Processing and all groups (NO oversampling) ---\n",
      "\n",
      "Processing Group: D5_Cells_1 (ID=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Files for D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:17<00:00, 17.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created 1,199,980 windows (weight: 1.0000).\n",
      "\n",
      "--- ‚úÖ Pre-processing complete ---\n",
      "Converting to numpy arrays...\n",
      "Total windows generated (unbalanced): 1,199,980\n",
      "X_dyn shape: (1199980, 20, 7)\n",
      "X_st shape:  (1199980, 4)\n",
      "X_gid shape: (1199980, 1)\n",
      "y_train shape: (1199980, 2)\n",
      "weights shape: (1199980,)\n",
      "Generating and applying global shuffle...\n",
      "--- üî¨ Verifying Shuffle ---\n",
      "Group mix in first 1000 samples (unbalanced is OK): {0: 1000}\n",
      "‚ùå SHUFFLE FAILED. Check warnings above.\n",
      "\n",
      "‚úÖ build_training_arrays() complete with sample weights.\n",
      "--- ‚ö°Ô∏è Creating fast in-memory training dataset (with weights) ---\n",
      "  Total windows: 1,199,980\n",
      "  Steps per epoch: 2,344\n",
      "‚úÖ Training dataset (with sample weights) is ready.\n",
      "  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "Starting training for 50 epochs (train steps/epoch ‚âà 2,344, batch=512)\n",
      "Epoch 1/50\n",
      "2344/2344 [==============================] - 48s 11ms/step - loss: 0.3113\n",
      "Epoch 2/50\n",
      "2340/2344 [============================>.] - ETA: 0s - loss: 0.2302  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 2] macro=0.255744  (per-cell: 0.2557)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run9_best.h5\n",
      "2344/2344 [==============================] - 72s 31ms/step - loss: 0.2302 - val_loss: 0.2557 - val_loss_macro: 0.2557\n",
      "Epoch 3/50\n",
      "2344/2344 [==============================] - 26s 11ms/step - loss: 0.1913\n",
      "Epoch 4/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.1666  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 4] macro=0.201450  (per-cell: 0.2015)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run9_best.h5\n",
      "2344/2344 [==============================] - 67s 29ms/step - loss: 0.1666 - val_loss: 0.2015 - val_loss_macro: 0.2015\n",
      "Epoch 5/50\n",
      "2344/2344 [==============================] - 25s 11ms/step - loss: 0.1489\n",
      "Epoch 6/50\n",
      "2341/2344 [============================>.] - ETA: 0s - loss: 0.1345  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 6] macro=0.174102  (per-cell: 0.1741)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run9_best.h5\n",
      "2344/2344 [==============================] - 66s 28ms/step - loss: 0.1344 - val_loss: 0.1741 - val_loss_macro: 0.1741\n",
      "Epoch 7/50\n",
      "2344/2344 [==============================] - 24s 10ms/step - loss: 0.1237\n",
      "Epoch 8/50\n",
      "2341/2344 [============================>.] - ETA: 0s - loss: 0.1151  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 8] macro=0.158462  (per-cell: 0.1585)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run9_best.h5\n",
      "2344/2344 [==============================] - 65s 28ms/step - loss: 0.1151 - val_loss: 0.1585 - val_loss_macro: 0.1585\n",
      "Epoch 9/50\n",
      "2344/2344 [==============================] - 24s 10ms/step - loss: 0.1078\n",
      "Epoch 10/50\n",
      "2340/2344 [============================>.] - ETA: 0s - loss: 0.1017  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 10] macro=0.149779  (per-cell: 0.1498)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run9_best.h5\n",
      "2344/2344 [==============================] - 65s 28ms/step - loss: 0.1017 - val_loss: 0.1498 - val_loss_macro: 0.1498\n",
      "Epoch 11/50\n",
      "2344/2344 [==============================] - 24s 10ms/step - loss: 0.0964\n",
      "Epoch 12/50\n",
      "2340/2344 [============================>.] - ETA: 0s - loss: 0.0919  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 12] macro=0.145308  (per-cell: 0.1453)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run9_best.h5\n",
      "2344/2344 [==============================] - 69s 30ms/step - loss: 0.0918 - val_loss: 0.1453 - val_loss_macro: 0.1453\n",
      "Epoch 13/50\n",
      "2344/2344 [==============================] - 27s 12ms/step - loss: 0.0878\n",
      "Epoch 14/50\n",
      "2340/2344 [============================>.] - ETA: 0s - loss: 0.0842  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 14] macro=0.142193  (per-cell: 0.1422)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run9_best.h5\n",
      "2344/2344 [==============================] - 69s 30ms/step - loss: 0.0842 - val_loss: 0.1422 - val_loss_macro: 0.1422\n",
      "Epoch 15/50\n",
      "2344/2344 [==============================] - 27s 12ms/step - loss: 0.0811\n",
      "Epoch 16/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.0783  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 16] macro=0.134892  (per-cell: 0.1349)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run9_best.h5\n",
      "2344/2344 [==============================] - 69s 29ms/step - loss: 0.0783 - val_loss: 0.1349 - val_loss_macro: 0.1349\n",
      "Epoch 17/50\n",
      "2344/2344 [==============================] - 27s 11ms/step - loss: 0.0758\n",
      "Epoch 18/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.0735  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 18] macro=0.130879  (per-cell: 0.1309)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run9_best.h5\n",
      "2344/2344 [==============================] - 69s 29ms/step - loss: 0.0735 - val_loss: 0.1309 - val_loss_macro: 0.1309\n",
      "Epoch 19/50\n",
      "2344/2344 [==============================] - 27s 11ms/step - loss: 0.0714\n",
      "Epoch 20/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.0696  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 20] macro=0.126383  (per-cell: 0.1264)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run9_best.h5\n",
      "2344/2344 [==============================] - 69s 29ms/step - loss: 0.0696 - val_loss: 0.1264 - val_loss_macro: 0.1264\n",
      "Epoch 21/50\n",
      "2344/2344 [==============================] - 27s 12ms/step - loss: 0.0679\n",
      "Epoch 22/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.0663  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 22] macro=0.124217  (per-cell: 0.1242)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run9_best.h5\n",
      "2344/2344 [==============================] - 68s 29ms/step - loss: 0.0663 - val_loss: 0.1242 - val_loss_macro: 0.1242\n",
      "Epoch 23/50\n",
      "2344/2344 [==============================] - 27s 11ms/step - loss: 0.0649\n",
      "Epoch 24/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.0636  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 24] macro=0.120848  (per-cell: 0.1208)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run9_best.h5\n",
      "2344/2344 [==============================] - 69s 29ms/step - loss: 0.0636 - val_loss: 0.1208 - val_loss_macro: 0.1208\n",
      "Epoch 25/50\n",
      "2344/2344 [==============================] - 27s 12ms/step - loss: 0.0623\n",
      "Epoch 26/50\n",
      "2340/2344 [============================>.] - ETA: 0s - loss: 0.0613  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 26] macro=0.119834  (per-cell: 0.1198)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run9_best.h5\n",
      "2344/2344 [==============================] - 70s 30ms/step - loss: 0.0613 - val_loss: 0.1198 - val_loss_macro: 0.1198\n",
      "Epoch 27/50\n",
      "2344/2344 [==============================] - 27s 12ms/step - loss: 0.0602\n",
      "Epoch 28/50\n",
      "2340/2344 [============================>.] - ETA: 0s - loss: 0.0592  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 28] macro=0.120004  (per-cell: 0.1200)\n",
      "2344/2344 [==============================] - 69s 29ms/step - loss: 0.0592 - val_loss: 0.1200 - val_loss_macro: 0.1200\n",
      "Epoch 29/50\n",
      "2344/2344 [==============================] - 27s 11ms/step - loss: 0.0583\n",
      "Epoch 30/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.0574  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 30] macro=0.119485  (per-cell: 0.1195)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run9_best.h5\n",
      "2344/2344 [==============================] - 68s 29ms/step - loss: 0.0574 - val_loss: 0.1195 - val_loss_macro: 0.1195\n",
      "Epoch 31/50\n",
      "2344/2344 [==============================] - 27s 11ms/step - loss: 0.0566\n",
      "Epoch 32/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.0559  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 32] macro=0.117929  (per-cell: 0.1179)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run9_best.h5\n",
      "2344/2344 [==============================] - 69s 29ms/step - loss: 0.0559 - val_loss: 0.1179 - val_loss_macro: 0.1179\n",
      "Epoch 33/50\n",
      "2344/2344 [==============================] - 27s 12ms/step - loss: 0.0551\n",
      "Epoch 34/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.0545  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 34] macro=0.116222  (per-cell: 0.1162)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run9_best.h5\n",
      "2344/2344 [==============================] - 70s 30ms/step - loss: 0.0545 - val_loss: 0.1162 - val_loss_macro: 0.1162\n",
      "Epoch 35/50\n",
      "2344/2344 [==============================] - 27s 12ms/step - loss: 0.0538\n",
      "Epoch 36/50\n",
      "2341/2344 [============================>.] - ETA: 0s - loss: 0.0532  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 36] macro=0.116044  (per-cell: 0.1160)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run9_best.h5\n",
      "2344/2344 [==============================] - 69s 29ms/step - loss: 0.0532 - val_loss: 0.1160 - val_loss_macro: 0.1160\n",
      "Epoch 37/50\n",
      "2344/2344 [==============================] - 27s 11ms/step - loss: 0.0526\n",
      "Epoch 38/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.0520  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 38] macro=0.118187  (per-cell: 0.1182)\n",
      "2344/2344 [==============================] - 71s 30ms/step - loss: 0.0520 - val_loss: 0.1182 - val_loss_macro: 0.1182\n",
      "Epoch 39/50\n",
      "2344/2344 [==============================] - 27s 12ms/step - loss: 0.0514\n",
      "Epoch 40/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.0508  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 40] macro=0.116238  (per-cell: 0.1162)\n",
      "2344/2344 [==============================] - 71s 30ms/step - loss: 0.0508 - val_loss: 0.1162 - val_loss_macro: 0.1162\n",
      "Epoch 41/50\n",
      "2344/2344 [==============================] - 27s 11ms/step - loss: 0.0502\n",
      "Epoch 42/50\n",
      "2341/2344 [============================>.] - ETA: 0s - loss: 0.0498  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 42] macro=0.117316  (per-cell: 0.1173)\n",
      "  ‚Üí LR reduced: 2.71341e-05 ‚Üí 1.35671e-05\n",
      "2344/2344 [==============================] - 70s 30ms/step - loss: 0.0498 - val_loss: 0.1173 - val_loss_macro: 0.1173\n",
      "Epoch 43/50\n",
      "2344/2344 [==============================] - 27s 12ms/step - loss: 0.0494\n",
      "Epoch 44/50\n",
      "2341/2344 [============================>.] - ETA: 0s - loss: 0.0492  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 44] macro=0.119253  (per-cell: 0.1193)\n",
      "2344/2344 [==============================] - 69s 29ms/step - loss: 0.0492 - val_loss: 0.1193 - val_loss_macro: 0.1193\n",
      "Epoch 45/50\n",
      "2344/2344 [==============================] - 27s 12ms/step - loss: 0.0489\n",
      "Epoch 46/50\n",
      "2342/2344 [============================>.] - ETA: 0s - loss: 0.0488  ‚Üí STREAM: 1 files, 1,199,981 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 46] macro=0.118011  (per-cell: 0.1180)\n",
      "  ‚Üí Early stopping.\n",
      "2344/2344 [==============================] - 69s 29ms/step - loss: 0.0488 - val_loss: 0.1180 - val_loss_macro: 0.1180\n",
      "\n",
      "‚úÖ Training complete for run 'rs2_run9'. Best checkpoint: checkpoints/rs2_run9_best.h5\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run9_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells:   0%|                                        | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Testing PBROM_data_cell_D5C78.mat: using 'D5_Cells_1' scaler, ID: 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_D5C78.mat             [PITM] MSE=9.419e-05 RSEP=12.89% MAPE=15.83%    \n",
      "[RandomSearch] Run 9 ‚Üí avg_rsep_pitm=12.8923\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 10 / 20\n",
      "  window_size   = 150\n",
      "  lambda_phys   = 0.8046\n",
      "  batch_size    = 512\n",
      "  learning_rate = 2.84e-06\n",
      "  num_layers    = 4\n",
      "  embed_dim     = 128\n",
      "==================================================\n",
      "Mixed precision policy: mixed_float16\n",
      "Using default strategy (1 GPU or CPU).\n",
      "Batch per device: 512 | Global batch: 512\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (window_size=150, stride=1) ---\n",
      "This will create one giant, UNBALANCED, shuffled training set WITH SAMPLE WEIGHTS.\n",
      "Calculating local time percentiles (p95_t, p95_dt)...\n",
      "  p95_t=1.2396e+07, p95_dt=9.9020e+01\n",
      "\n",
      "--- Pass 1.5a: Finding group sizes for weighting ---\n",
      "  Group 'D5_Cells_1' has 1,199,851 windows.\n",
      "\n",
      "--- Calculating Sample Weights ---\n",
      "  Group 'D5_Cells_1' (count=1,199,851): weight = 1.0000\n",
      "\n",
      "--- Pass 1.5b: Processing and all groups (NO oversampling) ---\n",
      "\n",
      "Processing Group: D5_Cells_1 (ID=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Files for D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:19<00:00, 19.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created 1,199,850 windows (weight: 1.0000).\n",
      "\n",
      "--- ‚úÖ Pre-processing complete ---\n",
      "Converting to numpy arrays...\n",
      "Total windows generated (unbalanced): 1,199,850\n",
      "X_dyn shape: (1199850, 150, 7)\n",
      "X_st shape:  (1199850, 4)\n",
      "X_gid shape: (1199850, 1)\n",
      "y_train shape: (1199850, 2)\n",
      "weights shape: (1199850,)\n",
      "Generating and applying global shuffle...\n",
      "--- üî¨ Verifying Shuffle ---\n",
      "Group mix in first 1000 samples (unbalanced is OK): {0: 1000}\n",
      "‚ùå SHUFFLE FAILED. Check warnings above.\n",
      "\n",
      "‚úÖ build_training_arrays() complete with sample weights.\n",
      "--- ‚ö°Ô∏è Creating fast in-memory training dataset (with weights) ---\n",
      "  Total windows: 1,199,850\n",
      "  Steps per epoch: 2,344\n",
      "‚úÖ Training dataset (with sample weights) is ready.\n",
      "  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "Starting training for 50 epochs (train steps/epoch ‚âà 2,344, batch=512)\n",
      "Epoch 1/50\n",
      "2344/2344 [==============================] - 142s 47ms/step - loss: 0.5370\n",
      "Epoch 2/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.4996  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 2] macro=0.528570  (per-cell: 0.5286)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 203s 87ms/step - loss: 0.4996 - val_loss: 0.5286 - val_loss_macro: 0.5286\n",
      "Epoch 3/50\n",
      "2344/2344 [==============================] - 110s 47ms/step - loss: 0.4800\n",
      "Epoch 4/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.4644  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 4] macro=0.489482  (per-cell: 0.4895)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 198s 84ms/step - loss: 0.4644 - val_loss: 0.4895 - val_loss_macro: 0.4895\n",
      "Epoch 5/50\n",
      "2344/2344 [==============================] - 110s 47ms/step - loss: 0.4353\n",
      "Epoch 6/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.4178  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 6] macro=0.467180  (per-cell: 0.4672)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 198s 85ms/step - loss: 0.4178 - val_loss: 0.4672 - val_loss_macro: 0.4672\n",
      "Epoch 7/50\n",
      "2344/2344 [==============================] - 109s 47ms/step - loss: 0.4069\n",
      "Epoch 8/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.3974  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 8] macro=0.446921  (per-cell: 0.4469)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 196s 84ms/step - loss: 0.3974 - val_loss: 0.4469 - val_loss_macro: 0.4469\n",
      "Epoch 9/50\n",
      "2344/2344 [==============================] - 107s 46ms/step - loss: 0.3886\n",
      "Epoch 10/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.3804  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 10] macro=0.428635  (per-cell: 0.4286)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 195s 83ms/step - loss: 0.3804 - val_loss: 0.4286 - val_loss_macro: 0.4286\n",
      "Epoch 11/50\n",
      "2344/2344 [==============================] - 109s 46ms/step - loss: 0.3727\n",
      "Epoch 12/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.3652  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 12] macro=0.413803  (per-cell: 0.4138)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 195s 83ms/step - loss: 0.3652 - val_loss: 0.4138 - val_loss_macro: 0.4138\n",
      "Epoch 13/50\n",
      "2344/2344 [==============================] - 110s 47ms/step - loss: 0.3581\n",
      "Epoch 14/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.3516  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 14] macro=0.401704  (per-cell: 0.4017)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 198s 85ms/step - loss: 0.3516 - val_loss: 0.4017 - val_loss_macro: 0.4017\n",
      "Epoch 15/50\n",
      "2344/2344 [==============================] - 109s 47ms/step - loss: 0.3454\n",
      "Epoch 16/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.3395  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 16] macro=0.390444  (per-cell: 0.3904)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 195s 83ms/step - loss: 0.3395 - val_loss: 0.3904 - val_loss_macro: 0.3904\n",
      "Epoch 17/50\n",
      "2344/2344 [==============================] - 109s 46ms/step - loss: 0.3338\n",
      "Epoch 18/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.3284  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 18] macro=0.380249  (per-cell: 0.3802)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 195s 83ms/step - loss: 0.3284 - val_loss: 0.3802 - val_loss_macro: 0.3802\n",
      "Epoch 19/50\n",
      "2344/2344 [==============================] - 108s 46ms/step - loss: 0.3231\n",
      "Epoch 20/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.3181  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 20] macro=0.371283  (per-cell: 0.3713)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 197s 84ms/step - loss: 0.3181 - val_loss: 0.3713 - val_loss_macro: 0.3713\n",
      "Epoch 21/50\n",
      "2344/2344 [==============================] - 109s 46ms/step - loss: 0.3131\n",
      "Epoch 22/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.3084  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 22] macro=0.362952  (per-cell: 0.3630)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 196s 84ms/step - loss: 0.3084 - val_loss: 0.3630 - val_loss_macro: 0.3630\n",
      "Epoch 23/50\n",
      "2344/2344 [==============================] - 110s 47ms/step - loss: 0.3037\n",
      "Epoch 24/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2992  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 24] macro=0.356249  (per-cell: 0.3562)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 198s 84ms/step - loss: 0.2992 - val_loss: 0.3562 - val_loss_macro: 0.3562\n",
      "Epoch 25/50\n",
      "2344/2344 [==============================] - 110s 47ms/step - loss: 0.2948\n",
      "Epoch 26/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.2906  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 26] macro=0.349061  (per-cell: 0.3491)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 197s 84ms/step - loss: 0.2906 - val_loss: 0.3491 - val_loss_macro: 0.3491\n",
      "Epoch 27/50\n",
      "2344/2344 [==============================] - 109s 47ms/step - loss: 0.2864\n",
      "Epoch 28/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2824  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 28] macro=0.344721  (per-cell: 0.3447)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 197s 84ms/step - loss: 0.2824 - val_loss: 0.3447 - val_loss_macro: 0.3447\n",
      "Epoch 29/50\n",
      "2344/2344 [==============================] - 110s 47ms/step - loss: 0.2782\n",
      "Epoch 30/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2732  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 30] macro=0.340786  (per-cell: 0.3408)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 197s 84ms/step - loss: 0.2732 - val_loss: 0.3408 - val_loss_macro: 0.3408\n",
      "Epoch 31/50\n",
      "2344/2344 [==============================] - 110s 47ms/step - loss: 0.2694\n",
      "Epoch 32/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.2657  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 32] macro=0.332997  (per-cell: 0.3330)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 198s 85ms/step - loss: 0.2657 - val_loss: 0.3330 - val_loss_macro: 0.3330\n",
      "Epoch 33/50\n",
      "2344/2344 [==============================] - 111s 47ms/step - loss: 0.2623\n",
      "Epoch 34/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2588  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 34] macro=0.326959  (per-cell: 0.3270)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 199s 85ms/step - loss: 0.2589 - val_loss: 0.3270 - val_loss_macro: 0.3270\n",
      "Epoch 35/50\n",
      "2344/2344 [==============================] - 111s 47ms/step - loss: 0.2556\n",
      "Epoch 36/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2525  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 36] macro=0.320817  (per-cell: 0.3208)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 198s 85ms/step - loss: 0.2525 - val_loss: 0.3208 - val_loss_macro: 0.3208\n",
      "Epoch 37/50\n",
      "2344/2344 [==============================] - 110s 47ms/step - loss: 0.2493\n",
      "Epoch 38/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2463  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 38] macro=0.315188  (per-cell: 0.3152)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 199s 85ms/step - loss: 0.2463 - val_loss: 0.3152 - val_loss_macro: 0.3152\n",
      "Epoch 39/50\n",
      "2344/2344 [==============================] - 111s 47ms/step - loss: 0.2433\n",
      "Epoch 40/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.2405  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 40] macro=0.310103  (per-cell: 0.3101)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 199s 85ms/step - loss: 0.2405 - val_loss: 0.3101 - val_loss_macro: 0.3101\n",
      "Epoch 41/50\n",
      "2344/2344 [==============================] - 111s 47ms/step - loss: 0.2378\n",
      "Epoch 42/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2350  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 42] macro=0.304353  (per-cell: 0.3044)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 199s 85ms/step - loss: 0.2350 - val_loss: 0.3044 - val_loss_macro: 0.3044\n",
      "Epoch 43/50\n",
      "2344/2344 [==============================] - 112s 48ms/step - loss: 0.2324\n",
      "Epoch 44/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2297  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 44] macro=0.299411  (per-cell: 0.2994)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 200s 86ms/step - loss: 0.2297 - val_loss: 0.2994 - val_loss_macro: 0.2994\n",
      "Epoch 45/50\n",
      "2344/2344 [==============================] - 112s 48ms/step - loss: 0.2272\n",
      "Epoch 46/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2248  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 46] macro=0.294828  (per-cell: 0.2948)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.2248 - val_loss: 0.2948 - val_loss_macro: 0.2948\n",
      "Epoch 47/50\n",
      "2344/2344 [==============================] - 112s 48ms/step - loss: 0.2223\n",
      "Epoch 48/50\n",
      "2344/2344 [==============================] - ETA: 0s - loss: 0.2200  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 48] macro=0.290942  (per-cell: 0.2909)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 200s 85ms/step - loss: 0.2200 - val_loss: 0.2909 - val_loss_macro: 0.2909\n",
      "Epoch 49/50\n",
      "2344/2344 [==============================] - 111s 47ms/step - loss: 0.2177\n",
      "Epoch 50/50\n",
      "2343/2344 [============================>.] - ETA: 0s - loss: 0.2154  ‚Üí STREAM: 1 files, 1,199,851 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 50] macro=0.286084  (per-cell: 0.2861)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run10_best.h5\n",
      "2344/2344 [==============================] - 198s 85ms/step - loss: 0.2154 - val_loss: 0.2861 - val_loss_macro: 0.2861\n",
      "\n",
      "‚úÖ Training complete for run 'rs2_run10'. Best checkpoint: checkpoints/rs2_run10_best.h5\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run10_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells:   0%|                                        | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Testing PBROM_data_cell_D5C78.mat: using 'D5_Cells_1' scaler, ID: 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:42<00:00, 42.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_D5C78.mat             [PITM] MSE=5.025e-06 RSEP=2.98% MAPE=3.19%    \n",
      "[RandomSearch] Run 10 ‚Üí avg_rsep_pitm=2.9779\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 11 / 20\n",
      "  window_size   = 100\n",
      "  lambda_phys   = 0.9406\n",
      "  batch_size    = 64\n",
      "  learning_rate = 4.58e-07\n",
      "  num_layers    = 5\n",
      "  embed_dim     = 128\n",
      "==================================================\n",
      "Mixed precision policy: mixed_float16\n",
      "Using default strategy (1 GPU or CPU).\n",
      "Batch per device: 64 | Global batch: 64\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (window_size=100, stride=1) ---\n",
      "This will create one giant, UNBALANCED, shuffled training set WITH SAMPLE WEIGHTS.\n",
      "Calculating local time percentiles (p95_t, p95_dt)...\n",
      "  p95_t=1.2396e+07, p95_dt=9.9020e+01\n",
      "\n",
      "--- Pass 1.5a: Finding group sizes for weighting ---\n",
      "  Group 'D5_Cells_1' has 1,199,901 windows.\n",
      "\n",
      "--- Calculating Sample Weights ---\n",
      "  Group 'D5_Cells_1' (count=1,199,901): weight = 1.0000\n",
      "\n",
      "--- Pass 1.5b: Processing and all groups (NO oversampling) ---\n",
      "\n",
      "Processing Group: D5_Cells_1 (ID=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Files for D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:17<00:00, 17.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created 1,199,900 windows (weight: 1.0000).\n",
      "\n",
      "--- ‚úÖ Pre-processing complete ---\n",
      "Converting to numpy arrays...\n",
      "Total windows generated (unbalanced): 1,199,900\n",
      "X_dyn shape: (1199900, 100, 7)\n",
      "X_st shape:  (1199900, 4)\n",
      "X_gid shape: (1199900, 1)\n",
      "y_train shape: (1199900, 2)\n",
      "weights shape: (1199900,)\n",
      "Generating and applying global shuffle...\n",
      "--- üî¨ Verifying Shuffle ---\n",
      "Group mix in first 1000 samples (unbalanced is OK): {0: 1000}\n",
      "‚ùå SHUFFLE FAILED. Check warnings above.\n",
      "\n",
      "‚úÖ build_training_arrays() complete with sample weights.\n",
      "--- ‚ö°Ô∏è Creating fast in-memory training dataset (with weights) ---\n",
      "  Total windows: 1,199,900\n",
      "  Steps per epoch: 18,749\n",
      "‚úÖ Training dataset (with sample weights) is ready.\n",
      "  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "Starting training for 50 epochs (train steps/epoch ‚âà 18,749, batch=64)\n",
      "Epoch 1/50\n",
      "18749/18749 [==============================] - 736s 37ms/step - loss: 0.6316\n",
      "Epoch 2/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.5989  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 2] macro=0.621709  (per-cell: 0.6217)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run11_best.h5\n",
      "18749/18749 [==============================] - 808s 43ms/step - loss: 0.5989 - val_loss: 0.6217 - val_loss_macro: 0.6217\n",
      "Epoch 3/50\n",
      "18749/18749 [==============================] - 694s 37ms/step - loss: 0.5781\n",
      "Epoch 4/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.5653  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 4] macro=0.597652  (per-cell: 0.5977)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run11_best.h5\n",
      "18749/18749 [==============================] - 793s 42ms/step - loss: 0.5653 - val_loss: 0.5977 - val_loss_macro: 0.5977\n",
      "Epoch 5/50\n",
      "18749/18749 [==============================] - 694s 37ms/step - loss: 0.5537\n",
      "Epoch 6/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.5349  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 6] macro=0.581557  (per-cell: 0.5816)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run11_best.h5\n",
      "18749/18749 [==============================] - 789s 42ms/step - loss: 0.5349 - val_loss: 0.5815 - val_loss_macro: 0.5816\n",
      "Epoch 7/50\n",
      "18749/18749 [==============================] - 694s 37ms/step - loss: 0.5138\n",
      "Epoch 8/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.5032  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 8] macro=0.567910  (per-cell: 0.5679)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run11_best.h5\n",
      "18749/18749 [==============================] - 789s 42ms/step - loss: 0.5032 - val_loss: 0.5679 - val_loss_macro: 0.5679\n",
      "Epoch 9/50\n",
      "18749/18749 [==============================] - 694s 37ms/step - loss: 0.4940\n",
      "Epoch 10/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4856  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 10] macro=0.552750  (per-cell: 0.5528)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run11_best.h5\n",
      "18749/18749 [==============================] - 789s 42ms/step - loss: 0.4856 - val_loss: 0.5528 - val_loss_macro: 0.5528\n",
      "Epoch 11/50\n",
      "18749/18749 [==============================] - 694s 37ms/step - loss: 0.4778\n",
      "Epoch 12/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4705  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 12] macro=0.540775  (per-cell: 0.5408)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run11_best.h5\n",
      "18749/18749 [==============================] - 788s 42ms/step - loss: 0.4705 - val_loss: 0.5408 - val_loss_macro: 0.5408\n",
      "Epoch 13/50\n",
      "18749/18749 [==============================] - 694s 37ms/step - loss: 0.4636\n",
      "Epoch 14/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4569  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 14] macro=0.527975  (per-cell: 0.5280)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run11_best.h5\n",
      "18749/18749 [==============================] - 789s 42ms/step - loss: 0.4569 - val_loss: 0.5280 - val_loss_macro: 0.5280\n",
      "Epoch 15/50\n",
      "18749/18749 [==============================] - 693s 37ms/step - loss: 0.4505\n",
      "Epoch 16/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4443  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 16] macro=0.516120  (per-cell: 0.5161)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run11_best.h5\n",
      "18749/18749 [==============================] - 788s 42ms/step - loss: 0.4443 - val_loss: 0.5161 - val_loss_macro: 0.5161\n",
      "Epoch 17/50\n",
      "18749/18749 [==============================] - 693s 37ms/step - loss: 0.4382\n",
      "Epoch 18/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4324  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 18] macro=0.506719  (per-cell: 0.5067)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run11_best.h5\n",
      "18749/18749 [==============================] - 788s 42ms/step - loss: 0.4324 - val_loss: 0.5067 - val_loss_macro: 0.5067\n",
      "Epoch 19/50\n",
      "18749/18749 [==============================] - 694s 37ms/step - loss: 0.4268\n",
      "Epoch 20/50\n",
      "18749/18749 [==============================] - ETA: 0s - loss: 0.4212  ‚Üí STREAM: 1 files, 1,199,901 windows (Group: 'D5_Cells_1', ID: 0)\n",
      "\n",
      "[Val @ epoch 20] macro=0.495093  (per-cell: 0.4951)\n",
      "  ‚úì Saved BEST checkpoint ‚Üí checkpoints/rs2_run11_best.h5\n",
      "18749/18749 [==============================] - 788s 42ms/step - loss: 0.4212 - val_loss: 0.4951 - val_loss_macro: 0.4951\n",
      "Epoch 21/50\n",
      "12801/18749 [===================>..........] - ETA: 3:40 - loss: 0.4167"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# Cell 10b ‚Äî Random Search Execution (using train_one_model)\n",
    "# ===============================================\n",
    "import numpy as np, tensorflow as tf, os, csv, random\n",
    "\n",
    "# Helper to write CSV\n",
    "def _write_csv_row(path, header, row_dict):\n",
    "    write_header = not os.path.exists(path)\n",
    "    with open(path, \"a\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=header)\n",
    "        if write_header:\n",
    "            w.writeheader()\n",
    "        w.writerow(row_dict)\n",
    "\n",
    "# Reset any leftover graphs\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Results CSV\n",
    "ABLATION_CSV_PATH = os.path.join(\"ablation\", \"random_search_stage2_results.csv\")\n",
    "if os.path.exists(ABLATION_CSV_PATH):\n",
    "    os.remove(ABLATION_CSV_PATH)\n",
    "\n",
    "CSV_HEADER = [\n",
    "    \"run_num\",\n",
    "    \"window_size\",\n",
    "    \"lambda_phys\",\n",
    "    \"batch_size\",\n",
    "    \"learning_rate\",\n",
    "    \"num_layers\",\n",
    "    \"embed_dim\",\n",
    "    \"avg_rsep_pitm\"\n",
    "]\n",
    "\n",
    "for run_num in range(N_RANDOM_RUNS):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # üîë Make Python & NumPy RNG state different per run\n",
    "    random.seed(SEED + run_num)\n",
    "    np.random.seed(SEED + run_num)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Sample hyperparameters with a constraint:\n",
    "    #   Do NOT allow any combination where 2 or 3 of\n",
    "    #   {window_size=400, batch_size=1024, num_layers=5}\n",
    "    #   are selected simultaneously.\n",
    "    #   (At most ONE of these can be active.)\n",
    "    # --------------------------------------------------\n",
    "    while True:\n",
    "        # Discrete hyperparameters\n",
    "        run_ws = random.choice(RANDOM_SEARCH_SPACE_STAGE2[\"window_size\"])\n",
    "        run_bs = random.choice(RANDOM_SEARCH_SPACE_STAGE2[\"batch_size\"])\n",
    "        run_layers = random.choice(RANDOM_SEARCH_SPACE_STAGE2[\"num_layers\"])\n",
    "        run_embed  = random.choice(RANDOM_SEARCH_SPACE_STAGE2[\"embed_dim\"])\n",
    "\n",
    "        # Continuous hyperparameters\n",
    "        run_lp_min, run_lp_max = RANDOM_SEARCH_SPACE_STAGE2[\"lambda_phys\"]\n",
    "        run_lp = random.uniform(run_lp_min, run_lp_max)\n",
    "\n",
    "        lr_min, lr_max = RANDOM_SEARCH_SPACE_STAGE2[\"learning_rate\"]\n",
    "        run_lr = 10 ** random.uniform(np.log10(lr_min), np.log10(lr_max))\n",
    "\n",
    "        # Count how many of the \"heavy\" settings are active\n",
    "        heavy_flags = int(run_ws == 400) + int(run_bs == 1024) + int(run_layers == 5)\n",
    "\n",
    "        # Accept only if at most ONE of them is active\n",
    "        if heavy_flags <= 1:\n",
    "            break\n",
    "        # otherwise, resample\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"RANDOM SEARCH RUN {run_num+1} / {N_RANDOM_RUNS}\")\n",
    "    print(f\"  window_size   = {run_ws}\")\n",
    "    print(f\"  lambda_phys   = {run_lp:.4f}\")\n",
    "    print(f\"  batch_size    = {run_bs}\")\n",
    "    print(f\"  learning_rate = {run_lr:.2e}\")\n",
    "    print(f\"  num_layers    = {run_layers}\")\n",
    "    print(f\"  embed_dim     = {run_embed}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Unique run name for this random-search trial\n",
    "    run_name = f\"rs2_run{run_num+1}\"\n",
    "\n",
    "    # --- Train model using EXACT same pipeline as main training ---\n",
    "    model, history = train_one_model(\n",
    "        run_name=run_name,\n",
    "        window_size=run_ws,\n",
    "        embed_dim=run_embed,\n",
    "        num_layers=run_layers,\n",
    "        batch_per_device=run_bs,\n",
    "        learning_rate=run_lr,\n",
    "        lambda_phys=run_lp,\n",
    "        do_plot=False  # no live plots during random search\n",
    "    )\n",
    "\n",
    "    # BEST_CKPT was set inside train_one_model for this run_name\n",
    "    # We now load that checkpoint before evaluating\n",
    "    if os.path.exists(BEST_CKPT):\n",
    "        print(f\"Loading BEST checkpoint for evaluation: {BEST_CKPT}\")\n",
    "        model.load_weights(BEST_CKPT)\n",
    "    else:\n",
    "        print(f\"WARNING: BEST_CKPT not found at {BEST_CKPT}. Using final weights.\")\n",
    "\n",
    "    # --- Evaluate on TEST set using the shared testing pipeline ---\n",
    "    test_results = evaluate_model_on_test(\n",
    "        model,\n",
    "        window_size=run_ws,\n",
    "        stride=STRIDE,\n",
    "        plot_suffix=run_name,\n",
    "        do_plot=False\n",
    "    )\n",
    "\n",
    "    rsep_values = [res[3] for res in test_results if np.isfinite(res[3])]\n",
    "    avg_rsep_pitm = np.mean(rsep_values) if rsep_values else np.nan\n",
    "    print(f\"[RandomSearch] Run {run_num+1} ‚Üí avg_rsep_pitm={avg_rsep_pitm:.4f}\")\n",
    "\n",
    "    row_dict = {\n",
    "        \"run_num\": run_num+1,\n",
    "        \"window_size\": run_ws,\n",
    "        \"lambda_phys\": run_lp,\n",
    "        \"batch_size\": run_bs,\n",
    "        \"learning_rate\": run_lr,\n",
    "        \"num_layers\": run_layers,\n",
    "        \"embed_dim\": run_embed,\n",
    "        \"avg_rsep_pitm\": avg_rsep_pitm\n",
    "    }\n",
    "    _write_csv_row(ABLATION_CSV_PATH, CSV_HEADER, row_dict)\n",
    "\n",
    "print(\"\\n‚úÖ Stage 2 Random Search complete.\")\n",
    "print(f\"Results saved to {ABLATION_CSV_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c342f6e2-be75-4a2a-a72a-d7871a4a4262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Top 10 Best Models from Random Search (Lower RSEP is Better)\n",
      "   (Reading from: ablation/random_search_stage2_results.csv)\n",
      "   run_num  window_size  lambda_phys  batch_size  learning_rate  num_layers  embed_dim  avg_rsep_pitm\n",
      "9       10          150     0.804619         512   2.844316e-06           4        128       2.977860\n",
      "0        1           10     0.245532          64   1.982764e-05           3         64       6.226054\n",
      "2        3           10     0.110198         256   2.932896e-05           1         32       8.797483\n",
      "1        2           10     0.406865         512   1.339659e-05           2        128       9.127683\n",
      "7        8           10     0.355845         512   3.033304e-06           4         32      10.508576\n",
      "5        6          100     0.627870          64   1.420809e-07           4        128      11.743940\n",
      "6        7          150     0.872478         512   1.829556e-06           2         96      12.308417\n",
      "8        9           20     0.761797         512   2.713411e-05           3         64      12.892252\n",
      "3        4          100     0.090067         768   3.285117e-07           4         96      32.441759\n",
      "4        5           10     0.697979         768   4.790458e-08           1         64      42.471172\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# Cell 10c ‚Äî Random Search Analysis\n",
    "# ======================================\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- ‚≠êÔ∏è FIX: Point to the correct \"Stage 2\" CSV file ---\n",
    "RESULTS_CSV = os.path.join(\"ablation\", \"random_search_stage2_results.csv\")\n",
    "if not os.path.exists(RESULTS_CSV):\n",
    "    print(f\"Error: Results file not found. Run Cell 10b first.\")\n",
    "    # You can't proceed if the file doesn't exist\n",
    "else:\n",
    "    pd.set_option('display.width', 1000)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "\n",
    "    df_results = pd.read_csv(RESULTS_CSV)\n",
    "    \n",
    "    # --- Sort by the metric (RSEP) to find the best runs ---\n",
    "    # ascending=True is correct because lower RSEP is better\n",
    "    df_sorted = df_results.sort_values(by=\"avg_rsep_pitm\", ascending=True)\n",
    "\n",
    "    print(f\"üèÜ Top 10 Best Models from Random Search (Lower RSEP is Better)\")\n",
    "    print(f\"   (Reading from: {RESULTS_CSV})\")\n",
    "    print(df_sorted.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "973bf8a5-f9ae-4ee5-972e-ee28e1c97c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ  Best model found from Random Search (Stage 2)\n",
      "run_num           10.000000\n",
      "window_size      150.000000\n",
      "lambda_phys        0.804619\n",
      "batch_size       512.000000\n",
      "learning_rate      0.000003\n",
      "num_layers         4.000000\n",
      "embed_dim        128.000000\n",
      "avg_rsep_pitm      2.977860\n",
      "Name: 9, dtype: float64\n",
      "\n",
      "Rebuilding best model from random search:\n",
      "  Run number:   10\n",
      "  Window Size:  150\n",
      "  Num Layers:   4\n",
      "  Embed Dim:    128\n",
      "  lambda_phys:  0.8046\n",
      "\n",
      "‚úÖ Successfully loaded weights from: checkpoints/rs2_run10_best.h5\n",
      "\n",
      "Running final evaluation on all TEST cells...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells:   0%|                                        | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Testing PBROM_data_cell_D5C78.mat: using 'D5_Cells_1' scaler, ID: 0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 680x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [01:02<00:00, 62.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ‚Üí plots/PBROM_data_cell_D5C78_pred_pct_BEST_RANDOM_SEARCH_MODEL.png\n",
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_D5C78.mat             [PITM] MSE=4.965e-06 RSEP=2.96% MAPE=3.17%    \n",
      "\n",
      "==================================================\n",
      "Per-Cell Evaluation Complete.\n",
      "Average RSEP: 2.9600%\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Cell 11 ‚Äî Load Best Model from Random Search & Evaluate\n",
    "# ==========================================================\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RESULTS_CSV = os.path.join(\"ablation\", \"random_search_stage2_results.csv\")\n",
    "if not os.path.exists(RESULTS_CSV):\n",
    "    raise FileNotFoundError(f\"Random search results not found at: {RESULTS_CSV}\")\n",
    "\n",
    "df_results = pd.read_csv(RESULTS_CSV)\n",
    "\n",
    "# Sort by avg_rsep_pitm ascending (lower is better)\n",
    "df_sorted = df_results.sort_values(by=\"avg_rsep_pitm\", ascending=True)\n",
    "best_row = df_sorted.iloc[0]\n",
    "\n",
    "print(\"üèÜ  Best model found from Random Search (Stage 2)\")\n",
    "print(best_row)\n",
    "\n",
    "BEST_RUN_NUM   = int(best_row[\"run_num\"])\n",
    "BEST_WS        = int(best_row[\"window_size\"])\n",
    "BEST_LAYERS    = int(best_row[\"num_layers\"])\n",
    "BEST_EMBED     = int(best_row[\"embed_dim\"])\n",
    "BEST_LAMBDA_PHYS = float(best_row[\"lambda_phys\"])\n",
    "\n",
    "# Rebuild the model architecture with these hyperparameters\n",
    "print(f\"\\nRebuilding best model from random search:\")\n",
    "print(f\"  Run number:   {BEST_RUN_NUM}\")\n",
    "print(f\"  Window Size:  {BEST_WS}\")\n",
    "print(f\"  Num Layers:   {BEST_LAYERS}\")\n",
    "print(f\"  Embed Dim:    {BEST_EMBED}\")\n",
    "print(f\"  lambda_phys:  {BEST_LAMBDA_PHYS:.4f}\")\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_pitm_model(\n",
    "    window_size=BEST_WS,\n",
    "    num_groups=NUM_GROUPS,\n",
    "    embed_dim=BEST_EMBED,\n",
    "    num_heads=NUM_HEADS,\n",
    "    ff_dim=FF_DIM,\n",
    "    num_layers=BEST_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "# Load the best checkpoint from that run\n",
    "run_name = f\"rs2_run{BEST_RUN_NUM}\"\n",
    "CHECKPOINT_NAME = f\"{run_name}_best.h5\"\n",
    "MODEL_TO_TEST = os.path.join(\"checkpoints\", CHECKPOINT_NAME)\n",
    "\n",
    "if not os.path.exists(MODEL_TO_TEST):\n",
    "    raise FileNotFoundError(f\"Checkpoint not found: {MODEL_TO_TEST}\")\n",
    "else:\n",
    "    model.load_weights(MODEL_TO_TEST)\n",
    "    print(f\"\\n‚úÖ Successfully loaded weights from: {MODEL_TO_TEST}\")\n",
    "\n",
    "# Run full evaluation on TEST cells with plots\n",
    "print(\"\\nRunning final evaluation on all TEST cells...\")\n",
    "results = evaluate_model_on_test(\n",
    "    model,\n",
    "    window_size=BEST_WS,\n",
    "    stride=STRIDE,\n",
    "    plot_suffix=\"BEST_RANDOM_SEARCH_MODEL\",\n",
    "    do_plot=True\n",
    ")\n",
    "\n",
    "rsep_values = [res[3] for res in results if np.isfinite(res[3])]\n",
    "final_avg_rsep = np.mean(rsep_values) if rsep_values else np.nan\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Per-Cell Evaluation Complete.\")\n",
    "print(f\"Average RSEP: {final_avg_rsep:.4f}%\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96c2bdf2-fea0-4470-9a67-457e3e759d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Export] Collecting curves for best random-search model...\n",
      "  (Testing PBROM_data_cell_D5C78.mat: using 'D5_Cells_1' scaler, ID: 0)\n",
      "[Export] Saved best-model curves for group 'D5_Cells_1'\n",
      "         ‚Üí export_curves/pitm_best_randomsearch_curves_D5_Cells_1.joblib\n",
      "         Cells exported: 1\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Cell 12 ‚Äî Export Best-Model Test Curves for This Battery Group\n",
    "# ==========================================================\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# üîß 1) Set a short label for THIS notebook's battery group\n",
    "#     ‚ûú Change ONLY this string in your other scripts\n",
    "BATTERY_GROUP_LABEL = \"D5_Cells_1\"   # <-- EDIT for each group script\n",
    "\n",
    "# üîß 2) Directory where we will save the export file\n",
    "EXPORT_DIR = \"export_curves\"\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Helper: collect the exact curves used in Cell 11's plots\n",
    "# ----------------------------------------------------------\n",
    "def collect_test_curves_for_export(model, window_size, stride):\n",
    "    \"\"\"\n",
    "    For each TEST cell:\n",
    "      - Run predict_cell(...)\n",
    "      - Align model outputs to experimental timestamps\n",
    "      - Build a dictionary with everything needed to re-plot:\n",
    "            * t_exp_hours, Q_exp_pct   (scatter)\n",
    "            * t_dense_hours, Q_pb_pct, Q_hat_pct  (lines)\n",
    "    Returns:\n",
    "      list of dicts, one per test cell\n",
    "    \"\"\"\n",
    "    curves = []\n",
    "\n",
    "    for fn in TEST_FILES:\n",
    "        # This uses the same predict_cell that Cell 6a / 11 rely on\n",
    "        out = predict_cell(model, fn, window_size, stride)\n",
    "        if out is None or len(out) < 7:\n",
    "            print(f\"[Export] WARNING: predict_cell returned invalid output for {fn}\")\n",
    "            continue\n",
    "\n",
    "        (t_dense, q_exp_norm_d, q_pb_norm_d,\n",
    "         q_hat_norm_d, cap_nom, Time_s_full, t_exp) = out\n",
    "\n",
    "        if t_dense.size == 0:\n",
    "            print(f\"[Export] WARNING: no windows for {fn}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # --- Reproduce the same alignment as in evaluate_model_on_test ---\n",
    "        ts_dense = t_dense\n",
    "        # Restrict experimental timestamps to the model coverage\n",
    "        t_exp_use = t_exp[(t_exp >= ts_dense[0]) & (t_exp <= ts_dense[-1])]\n",
    "        if t_exp_use.size == 0:\n",
    "            print(f\"[Export] WARNING: no experimental times within model horizon for {fn}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        idx = nearest_indices(ts_dense, t_exp_use)\n",
    "        if idx.size == 0:\n",
    "            print(f\"[Export] WARNING: nearest_indices returned empty for {fn}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Stamp experimental/Q curves at those timestamps\n",
    "        Q_exp_norm_stamp   = q_exp_norm_d[idx]\n",
    "        Q_pb_norm_stamp    = q_pb_norm_d[idx]\n",
    "        Q_pred_norm_stamp  = q_hat_norm_d[idx]\n",
    "\n",
    "        # Convert to plotting units (same as Cell 6a / 11):\n",
    "        #   time in hours, degradation in %\n",
    "        t_exp_hours   = t_exp_use / 3600.0\n",
    "        t_dense_hours = t_dense / 3600.0\n",
    "\n",
    "        Q_exp_pct = 100.0 * Q_exp_norm_stamp\n",
    "        Q_pb_pct  = 100.0 * q_pb_norm_d\n",
    "        Q_hat_pct = 100.0 * q_hat_norm_d\n",
    "\n",
    "        curves.append({\n",
    "            \"file_name\":   os.path.basename(fn),\n",
    "            \"t_exp_hours\": t_exp_hours.astype(np.float64),\n",
    "            \"Q_exp_pct\":   Q_exp_pct.astype(np.float64),\n",
    "            \"t_dense_hours\": t_dense_hours.astype(np.float64),\n",
    "            \"Q_pb_pct\":    Q_pb_pct.astype(np.float64),\n",
    "            \"Q_hat_pct\":   Q_hat_pct.astype(np.float64),\n",
    "            \"Cap_Nom\":     float(cap_nom),\n",
    "        })\n",
    "\n",
    "    return curves\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3) Collect curves + package everything into one object\n",
    "# ----------------------------------------------------------\n",
    "print(\"\\n[Export] Collecting curves for best random-search model...\")\n",
    "\n",
    "# We assume Cell 11 has already defined:\n",
    "#   - model           (best model loaded)\n",
    "#   - BEST_WS         (best window size)\n",
    "#   - STRIDE          (global stride)\n",
    "#   - results         (per-cell metrics from evaluate_model_on_test)\n",
    "curves = collect_test_curves_for_export(\n",
    "    model,\n",
    "    window_size=BEST_WS,\n",
    "    stride=STRIDE\n",
    ")\n",
    "\n",
    "if not curves:\n",
    "    print(\"[Export] No curves collected ‚Äî nothing to save.\")\n",
    "else:\n",
    "    export_payload = {\n",
    "        \"battery_group\": BATTERY_GROUP_LABEL,\n",
    "        \"window_size\":   BEST_WS,\n",
    "        \"stride\":        STRIDE,\n",
    "        \"results_table\": results,   # metrics from Cell 11 (MSE / RSEP / MAPE)\n",
    "        \"curves\":        curves,    # list of dicts (per test cell)\n",
    "    }\n",
    "\n",
    "    # File name includes the group label so different scripts won't collide\n",
    "    export_path = os.path.join(\n",
    "        EXPORT_DIR,\n",
    "        f\"pitm_best_randomsearch_curves_{BATTERY_GROUP_LABEL}.joblib\"\n",
    "    )\n",
    "    joblib.dump(export_payload, export_path)\n",
    "\n",
    "    print(f\"[Export] Saved best-model curves for group '{BATTERY_GROUP_LABEL}'\")\n",
    "    print(f\"         ‚Üí {export_path}\")\n",
    "    print(f\"         Cells exported: {len(curves)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7ecd1b-eec7-4d85-9407-1b52293d2c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfce744-64f3-4ad8-8cd6-bce5d0df1da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7188b0f9-6331-4850-8dc8-ca477f431268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env_2)",
   "language": "python",
   "name": "ml_env_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
