{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9be1b0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 1 GPU(s) active, memory growth enabled.\n",
      "‚úÖ File map generated: 6 files mapped to base groups.\n",
      "  Example lookup: PBROM_data_cell_24.mat -> PBROM_Cells_1\n",
      "  Example lookup: PBROM_data_cell_26.mat -> PBROM_Cells_1\n",
      "  Example lookup: PBROM_data_cell_28.mat -> PBROM_Cells_1\n",
      "\n",
      "Verifying file availability (optional):\n",
      "[TRAIN] PBROM_data_cell_24.mat: N=150863\n",
      "[TRAIN] PBROM_data_cell_D5C77.mat: N=1200000\n",
      "[TRAIN] Found/loaded 2/2 files in 'PBROM data'\n",
      "[VAL] PBROM_data_cell_26.mat: N=151439\n",
      "[VAL] PBROM_data_cell_D5C69.mat: N=1200000\n",
      "[VAL] Found/loaded 2/2 files in 'PBROM data'\n",
      "[TEST] PBROM_data_cell_28.mat: N=151631\n",
      "[TEST] PBROM_data_cell_D5C78.mat: N=1200000\n",
      "[TEST] Found/loaded 2/2 files in 'PBROM data'\n",
      "\n",
      "‚úÖ Group ID map generated (2 total groups):\n",
      "  0: D5_Cells_1\n",
      "  1: PBROM_Cells_1\n",
      "\n",
      "‚úÖ Cell 1 ready: imports, seeds, GPU setup, dirs, splits, loader.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ‚ö° GPU + XLA acceleration (added at top)\n",
    "# ==========================================\n",
    "import os\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=2\"   # Enable XLA fusion\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"             # suppress TF INFO/WARN\n",
    "os.environ[\"TF_CPP_MAX_VLOG_LEVEL\"] = \"0\"            # suppress verbose C++ logs\n",
    "\n",
    "import logging, absl.logging\n",
    "import tensorflow as tf\n",
    "\n",
    "# üîß Threading config MUST be set before TF runtime initializes\n",
    "tf.config.threading.set_inter_op_parallelism_threads(8)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(8)\n",
    "\n",
    "# Logging levels\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "# XLA JIT\n",
    "tf.config.optimizer.set_jit(True)                    # Just-In-Time compile\n",
    "\n",
    "# Enable full GPU memory and multi-GPU graph\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"‚úÖ {len(gpus)} GPU(s) active, memory growth enabled.\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è CPU mode.\")\n",
    "\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Cell 1 ‚Äî Setup & Splits\n",
    "# =========================\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  # 2=warnings+errors, 3=errors only\n",
    "os.environ[\"TF_NUM_INTEROP_THREADS\"] = \"1\"\n",
    "os.environ[\"TF_NUM_INTRAOP_THREADS\"] = \"1\"\n",
    "\n",
    "import json, random\n",
    "import numpy as np\n",
    "import h5py\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import logging\n",
    "import absl.logging\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "\n",
    "\n",
    "# --- Quiet TF a bit ---\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "# --- Reproducibility ---\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# # --- GPU: enable memory growth if present (safe no-op on CPU) ---\n",
    "# gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         for g in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(g, True)\n",
    "#         print(f\"‚úÖ GPUs: {len(gpus)} | Memory growth enabled\")\n",
    "#     except Exception as e:\n",
    "#         print(\"‚ö†Ô∏è GPU setup issue:\", e)\n",
    "# else:\n",
    "#     print(\"‚ÑπÔ∏è No GPU detected (CPU mode)\")\n",
    "\n",
    "# --- Paths ---\n",
    "DATA_DIR = os.getenv(\"PBROM_DATA_DIR\", \"PBROM data\")  # change if your folder name differs\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "os.makedirs(\"scalers\", exist_ok=True)\n",
    "os.makedirs(\"ablation\", exist_ok=True)\n",
    "os.makedirs(\"figs\", exist_ok=True)\n",
    "\n",
    "# # --- ‚≠êÔ∏è MODIFIED: File lists are now grouped ‚≠êÔ∏è ---\n",
    "# This is now the \"single source of truth\" for all files.\n",
    "# Based on your request for granular, per-cell groups.\n",
    "\n",
    "\n",
    "# TRAIN_GROUPS = {\n",
    "#     \"PBROM_Cells_1\": [\n",
    "#         \"PBROM_data_cell_24.mat\",\n",
    "#     ],\n",
    "#     \"PBROM_Cells_2\": [\n",
    "#         \"PBROM_data_cell_32.mat\",\n",
    "#     ],\n",
    "#     \"NASA_Cells_1\": [\n",
    "#         \"PBROM_data_NASA_B7.mat\",\n",
    "#     ],\n",
    "#     \"NASA_Cells_2\": [\n",
    "#         \"PBROM_data_NASA_B30.mat\",\n",
    "#     ],\n",
    "#     \"D5_Cells_1\": [\n",
    "#         \"PBROM_data_cell_D5C77.mat\",\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# VAL_GROUPS = {\n",
    "#     \"PBROM_Cells_1_Val\": [\n",
    "#         \"PBROM_data_cell_26.mat\",\n",
    "#     ],\n",
    "#     \"PBROM_Cells_2_Val\": [\n",
    "#         \"PBROM_data_cell_33.mat\",\n",
    "#     ],\n",
    "#     \"NASA_Cells_1_Val\": [\n",
    "#         \"PBROM_data_NASA_B6.mat\",\n",
    "#     ],\n",
    "#     \"NASA_Cells_2_Val\": [\n",
    "#         \"PBROM_data_NASA_B29.mat\",\n",
    "#     ],\n",
    "#     \"D5_Cells_1_Val\": [\n",
    "#         \"PBROM_data_cell_D5C69.mat\",\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# TEST_GROUPS = {\n",
    "#     \"PBROM_Cells_1_Test\": [\n",
    "#         \"PBROM_data_cell_28.mat\",\n",
    "#     ],\n",
    "#     \"PBROM_Cells_2_Test\": [\n",
    "#         \"PBROM_data_cell_35.mat\",\n",
    "#     ],\n",
    "#     \"NASA_Cells_1_Test\": [\n",
    "#         \"PBROM_data_NASA_B5.mat\",\n",
    "#     ],\n",
    "#     \"NASA_Cells_2_Test\": [\n",
    "#         \"PBROM_data_NASA_B32.mat\",\n",
    "#     ],\n",
    "#     \"D5_Cells_1_Test\": [\n",
    "#         \"PBROM_data_cell_D5C78.mat\",\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TRAIN_GROUPS = {\n",
    "#     \"PBROM_Cells_2\": [\n",
    "#         \"PBROM_data_cell_32.mat\",\n",
    "#     ],\n",
    "#     \"NASA_Cells_2\": [\n",
    "#         \"PBROM_data_NASA_B30.mat\",\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# VAL_GROUPS = {\n",
    "#     \"PBROM_Cells_2_Val\": [\n",
    "#         \"PBROM_data_cell_33.mat\",\n",
    "#     ],\n",
    "#     \"NASA_Cells_2_Val\": [\n",
    "#         \"PBROM_data_NASA_B29.mat\",\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# TEST_GROUPS = {\n",
    "#     \"PBROM_Cells_2_Test\": [\n",
    "#         \"PBROM_data_cell_35.mat\",\n",
    "#     ],\n",
    "#     \"NASA_Cells_2_Test\": [\n",
    "#         \"PBROM_data_NASA_B32.mat\",\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "TRAIN_GROUPS = {\n",
    "    \"PBROM_Cells_1\": [\n",
    "        \"PBROM_data_cell_24.mat\",\n",
    "    ],\n",
    "    \"D5_Cells_1\": [\n",
    "        \"PBROM_data_cell_D5C77.mat\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "VAL_GROUPS = {\n",
    "    \"PBROM_Cells_1_Val\": [\n",
    "        \"PBROM_data_cell_26.mat\",\n",
    "    ],\n",
    "    \"D5_Cells_1_Val\": [\n",
    "        \"PBROM_data_cell_D5C69.mat\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "TEST_GROUPS = {\n",
    "    \"PBROM_Cells_1_Test\": [\n",
    "        \"PBROM_data_cell_28.mat\",\n",
    "    ],\n",
    "    \"D5_Cells_1_Test\": [\n",
    "        \"PBROM_data_cell_D5C78.mat\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "# --- ‚≠êÔ∏è NEW: Auto-generate flat lists and lookup map ‚≠êÔ∏è ---\n",
    "# (This code builds all the helper lists we need)\n",
    "\n",
    "TRAIN_FILES = [f for files in TRAIN_GROUPS.values() for f in files]\n",
    "VAL_FILES = [f for files in VAL_GROUPS.values() for f in files]\n",
    "TEST_FILES = [f for files in TEST_GROUPS.values() for f in files]\n",
    "\n",
    "# This is our critical \"lookup map\"\n",
    "# It maps every single file to a group name, which we use to load the correct scaler\n",
    "FILE_TO_GROUP_MAP = {}\n",
    "all_groups = {**TRAIN_GROUPS, **VAL_GROUPS, **TEST_GROUPS}\n",
    "for group, files in all_groups.items():\n",
    "    for f in files:\n",
    "        # We find the \"base\" name for the scaler (e.g., \"PBROM_Cells_1\")\n",
    "        # This allows \"PBROM_Cells_1_Val\" to use the \"PBROM_Cells_1\" scaler\n",
    "        base_group = group.split('_Val')[0].split('_Test')[0]\n",
    "        FILE_TO_GROUP_MAP[f] = base_group\n",
    "\n",
    "print(f\"‚úÖ File map generated: {len(FILE_TO_GROUP_MAP)} files mapped to base groups.\")\n",
    "print(f\"  Example lookup: {TRAIN_FILES[0]} -> {FILE_TO_GROUP_MAP.get(TRAIN_FILES[0])}\")\n",
    "print(f\"  Example lookup: {VAL_FILES[0]} -> {FILE_TO_GROUP_MAP.get(VAL_FILES[0])}\")\n",
    "print(f\"  Example lookup: {TEST_FILES[0]} -> {FILE_TO_GROUP_MAP.get(TEST_FILES[0])}\")\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "\n",
    "# --- Helper: robust HDF5 .mat loader (squeezes to 1D/2D np arrays) ---\n",
    "def _read_field(f, key, required=True):\n",
    "    if key not in f:\n",
    "        if required:\n",
    "            raise KeyError(f\"Missing key '{key}' in MAT file.\")\n",
    "        return None\n",
    "    arr = np.array(f[key])\n",
    "    # MATLAB often stores column vectors as (1, N) or (N, 1); squeeze safely\n",
    "    return np.squeeze(arr)\n",
    "\n",
    "def load_mat(file_name):\n",
    "    \"\"\"\n",
    "    Loads a PBROM/NASA cell .mat file and returns a dict of numpy arrays:\n",
    "      I_p, SOC_p, Time_s_p, Q_exp_p, Q_total_p, V_cum_p, Temp_cum_p,\n",
    "      C_rate_profile, Bat_cap_profile, R_ch_profile, V_max_profile, V_min_profile,\n",
    "      Cap_Nom, t_exp\n",
    "    \"\"\"\n",
    "    path = os.path.join(DATA_DIR, file_name)\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Couldn't find: {path}\")\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        data = {\n",
    "            \"I_p\":                 _read_field(f, \"I_p\"),\n",
    "            \"SOC_p\":               _read_field(f, \"SOC_p\"),\n",
    "            \"Time_s_p\":            _read_field(f, \"Time_s_p\"),\n",
    "            \"Q_exp_p\":             _read_field(f, \"Q_exp_p\"),\n",
    "            \"Q_total_p\":           _read_field(f, \"Q_total_p\"),\n",
    "            \"V_cum_p\":             _read_field(f, \"V_cum_p\"),\n",
    "            \"Temp_cum_p\":          _read_field(f, \"Temp_cum_p\"),\n",
    "            \"C_rate_profile\":      _read_field(f, \"C_rate_profile\"),\n",
    "            \"Bat_cap_profile\":     _read_field(f, \"Bat_cap_profile\"),\n",
    "            \"R_ch_profile\":        _read_field(f, \"R_ch_profile\"),\n",
    "            \"V_max_profile\":       _read_field(f, \"V_max_profile\"),\n",
    "            \"V_min_profile\":       _read_field(f, \"V_min_profile\"),\n",
    "            \"Cap_Nom\":             _read_field(f, \"Cap_Nom\"),\n",
    "            \"t_exp\":               _read_field(f, \"t_exp\"),\n",
    "        }\n",
    "    return data\n",
    "\n",
    "# --- Quick sanity: print counts and peek sizes if files exist ---\n",
    "def _peek(files, tag):\n",
    "    ok = 0\n",
    "    for fn in files:\n",
    "        try:\n",
    "            d = load_mat(fn)\n",
    "            n = len(np.atleast_1d(d[\"Time_s_p\"]))\n",
    "            print(f\"[{tag}] {fn}: N={n}\")\n",
    "            ok += 1\n",
    "        except Exception as e:\n",
    "            print(f\"[{tag}] {fn}: ({e})\")\n",
    "    print(f\"[{tag}] Found/loaded {ok}/{len(files)} files in '{DATA_DIR}'\")\n",
    "\n",
    "print(\"\\nVerifying file availability (optional):\")\n",
    "# _peek now uses the new auto-generated flat lists\n",
    "_peek(TRAIN_FILES, \"TRAIN\")\n",
    "_peek(VAL_FILES,   \"VAL\")\n",
    "_peek(TEST_FILES,  \"TEST\")\n",
    "\n",
    "# =========================\n",
    "# ADD TO END OF CELL 1\n",
    "# =========================\n",
    "\n",
    "# Get all unique \"base\" group names from the file map\n",
    "# This ensures all groups (train, val, test) are included\n",
    "ALL_BASE_GROUPS = sorted(list(set(FILE_TO_GROUP_MAP.values())))\n",
    "\n",
    "# Create the ID mapping\n",
    "GROUP_TO_ID_MAP = {group_name: i for i, group_name in enumerate(ALL_BASE_GROUPS)}\n",
    "NUM_GROUPS = len(ALL_BASE_GROUPS)\n",
    "\n",
    "print(f\"\\n‚úÖ Group ID map generated ({NUM_GROUPS} total groups):\")\n",
    "for group_name, idx in GROUP_TO_ID_MAP.items():\n",
    "    print(f\"  {idx}: {group_name}\")\n",
    "\n",
    "# This map will now be available to all other cells\n",
    "\n",
    "print(\"\\n‚úÖ Cell 1 ready: imports, seeds, GPU setup, dirs, splits, loader.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ab54ef5d-c9f6-4ad7-9e79-0563b9a1d4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Pass-0] Processing PER-GROUP Stats (Time, Features, Targets) ...\n",
      "--- Group: PBROM_Cells_1 ---\n",
      "  ‚úì Time stats: p95_t=1.15e+07, p95_dt=200.00\n",
      "  ‚úì Feature scaler saved\n",
      "  ‚úì Delta scaler saved\n",
      "--- Group: D5_Cells_1 ---\n",
      "  ‚úì Time stats: p95_t=1.24e+07, p95_dt=99.02\n",
      "  ‚úì Feature scaler saved\n",
      "  ‚úì Delta scaler saved\n",
      "\n",
      "[Pass-0] Fitting *global* static scaler ...\n",
      "‚úÖ Cell 2 complete: All per-group stats ready.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Cell 2 ‚Äî Pass-0 (v5 - FULL PER-GROUP Time & Feature Scaling)\n",
    "# ==========================================================\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "# ---- Constants ----\n",
    "SCALE_DELTA = 1e5\n",
    "T_MIN = 10.0\n",
    "T_MAX = 50.0\n",
    "\n",
    "# ---- PercentileScaler ----\n",
    "class PercentileScaler:\n",
    "    def __init__(self, p_scale=95, p_clip=99.9, eps=1e-6, min_pos=20):\n",
    "        self.p_scale = p_scale; self.p_clip = p_clip; self.eps = eps; self.min_pos = min_pos\n",
    "        self.scale_ = 1.0; self.clip_limit_ = 1e9 \n",
    "    def fit(self, x):\n",
    "        x = np.asarray(x).reshape(-1); x_pos = x[x > 0] \n",
    "        if x_pos.size < self.min_pos:\n",
    "            if x.size > 0:\n",
    "                p_scale_val = np.percentile(x, max(self.p_scale, 99))\n",
    "                p_clip_val = np.percentile(x, max(self.p_clip, 99.9))\n",
    "            else:\n",
    "                p_scale_val = 1.0; p_clip_val = 1.0\n",
    "        else:\n",
    "            p_scale_val = np.percentile(x_pos, self.p_scale)\n",
    "            p_clip_val = np.percentile(x_pos, self.p_clip)\n",
    "        self.scale_ = max(float(p_scale_val), self.eps)\n",
    "        self.clip_limit_ = max(float(p_clip_val) / self.scale_, 1.0) \n",
    "    def transform(self, x):\n",
    "        x_scaled = np.asarray(x).reshape(-1, 1) / self.scale_\n",
    "        return np.clip(x_scaled, 0.0, self.clip_limit_)\n",
    "    def inverse_transform(self, x): return np.asarray(x).reshape(-1, 1) * self.scale_\n",
    "\n",
    "# ---- Helpers ----\n",
    "def _grab_scalar(x, default=0.0):\n",
    "    arr = np.asarray(x).reshape(-1)\n",
    "    return float(arr[0]) if arr.size else default\n",
    "\n",
    "def _read_field(f, key, required=True):\n",
    "    if key not in f:\n",
    "        if required: raise KeyError(f\"Missing key '{key}' in MAT file.\")\n",
    "        return None\n",
    "    return np.squeeze(np.array(f[key]))\n",
    "\n",
    "def load_mat(file_name):\n",
    "    path = os.path.join(DATA_DIR, file_name)\n",
    "    if not os.path.exists(path): raise FileNotFoundError(f\"Couldn't find: {path}\")\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        data = {\n",
    "            \"SOC_p\": _read_field(f, \"SOC_p\"), \"Time_s_p\": _read_field(f, \"Time_s_p\"),\n",
    "            \"Q_exp_p\": _read_field(f, \"Q_exp_p\"), \"Q_total_p\": _read_field(f, \"Q_total_p\"),\n",
    "            \"V_cum_p\": _read_field(f, \"V_cum_p\"), \"Temp_cum_p\": _read_field(f, \"Temp_cum_p\"),\n",
    "            \"C_rate_profile\": _read_field(f, \"C_rate_profile\"),\n",
    "            \"Bat_cap_profile\": _read_field(f, \"Bat_cap_profile\"), \"R_ch_profile\": _read_field(f, \"R_ch_profile\"),\n",
    "            \"V_max_profile\": _read_field(f, \"V_max_profile\"), \"V_min_profile\": _read_field(f, \"V_min_profile\"),\n",
    "            \"Cap_Nom\": _read_field(f, \"Cap_Nom\"), \"t_exp\": _read_field(f, \"t_exp\"),\n",
    "        }\n",
    "    return data\n",
    "\n",
    "# --- Compute Time Percentiles PER GROUP ---\n",
    "def compute_group_time_percentiles(file_list):\n",
    "    elapsed_pool = []\n",
    "    dt_pool = []\n",
    "    for fn in file_list:\n",
    "        try:\n",
    "            d = load_mat(fn)\n",
    "            t = d[\"Time_s_p\"].astype(np.float64).flatten()\n",
    "            if t.size == 0: continue\n",
    "            elapsed = t - t[0]\n",
    "            dt = np.diff(t, prepend=t[0])\n",
    "            elapsed_pool.append(elapsed)\n",
    "            if dt.size > 1: dt_pool.append(dt[1:])\n",
    "        except Exception as e: print(f\"Skipping {fn} in time calc: {e}\")\n",
    "    \n",
    "    elapsed_all = np.concatenate(elapsed_pool) if elapsed_pool else np.array([1.0])\n",
    "    dt_all = np.concatenate(dt_pool) if dt_pool else np.array([1.0])\n",
    "    \n",
    "    p95_t = float(np.percentile(elapsed_all, 95))\n",
    "    p95_dt = float(np.percentile(dt_all, 95))\n",
    "    return p95_t, p95_dt\n",
    "\n",
    "# --- Sample Rows (Takes specific p95_t) ---\n",
    "def sample_dynamic_rows_for_scaler(file_list, p95_t, p95_dt):\n",
    "    target_rows_total = 500_000\n",
    "    per_file_target = max(10_000, target_rows_total // max(1, len(file_list)))\n",
    "    rows = []\n",
    "    for fn in file_list:\n",
    "        try:\n",
    "            d = load_mat(fn)\n",
    "            SOC = np.atleast_1d(d[\"SOC_p\"]).astype(np.float64).flatten()\n",
    "            V   = np.atleast_1d(d[\"V_cum_p\"]).astype(np.float64).flatten()\n",
    "            T   = np.atleast_1d(d[\"Temp_cum_p\"]).astype(np.float64).flatten()\n",
    "            t   = np.atleast_1d(d[\"Time_s_p\"]).astype(np.float64).flatten()\n",
    "            Cr = np.atleast_1d(d[\"C_rate_profile\"]).astype(np.float64).flatten()\n",
    "\n",
    "            V_max = _grab_scalar(d[\"V_max_profile\"], 4.2); V_min = _grab_scalar(d[\"V_min_profile\"], 2.5)\n",
    "\n",
    "            if t.size == 0: continue\n",
    "            elapsed = t - t[0]; dt = np.diff(t, prepend=t[0])\n",
    "            \n",
    "            # ‚≠êÔ∏è Use Group-Specific P95 Time here\n",
    "            t_abs_norm = np.clip(elapsed / max(p95_t, 1e-12), 0.0, 4.0)\n",
    "            dt_norm    = np.clip(dt      / max(p95_dt, 1e-12), 0.0, 4.0)\n",
    "            V_norm = np.clip((V - V_min) / max(V_max - V_min, 1e-6), -1.0, 2.0)\n",
    "            T_norm = np.clip((T - T_MIN) / (T_MAX - T_MIN), -1.0, 2.0)\n",
    "\n",
    "            N = min(SOC.size, V_norm.size, T_norm.size, t_abs_norm.size, dt_norm.size, Cr.size)\n",
    "            if N <= 0: continue\n",
    "            if N <= per_file_target: idx = np.arange(N)\n",
    "            else: idx = np.linspace(0, N - 1, per_file_target).astype(int)\n",
    "\n",
    "            dyn = np.stack([ SOC[idx], V_norm[idx], T_norm[idx], t_abs_norm[idx], dt_norm[idx], Cr[idx] ], axis=1)\n",
    "            rows.append(dyn)\n",
    "        except: pass\n",
    "        \n",
    "    if not rows: return np.zeros((10, 6), dtype=np.float64)\n",
    "    return np.vstack(rows)\n",
    "\n",
    "def collect_positive_deltas_scaled(file_list):\n",
    "    buf = []\n",
    "    for fn in file_list:\n",
    "        try:\n",
    "            d = load_mat(fn)\n",
    "            Qe_norm = np.atleast_1d(d[\"Q_exp_p\"]).astype(np.float64).flatten()\n",
    "            Qp_norm = np.atleast_1d(d[\"Q_total_p\"]).astype(np.float64).flatten()\n",
    "            if Qe_norm.size < 2 or Qp_norm.size < 2: continue\n",
    "            dq_e = np.maximum(Qe_norm[1:] - Qe_norm[:-1], 0.0) * SCALE_DELTA\n",
    "            dq_p = np.maximum(Qp_norm[1:] - Qp_norm[:-1], 0.0) * SCALE_DELTA\n",
    "            if dq_e.size: buf.append(dq_e)\n",
    "            if dq_p.size: buf.append(dq_p)\n",
    "        except: pass\n",
    "    if not buf: return np.array([1.0])\n",
    "    return np.concatenate(buf)\n",
    "\n",
    "# ---- Execution ----\n",
    "print(\"\\n[Pass-0] Processing PER-GROUP Stats (Time, Features, Targets) ...\")\n",
    "feature_scalers = {}\n",
    "\n",
    "for group_name, file_list in TRAIN_GROUPS.items():\n",
    "    if not file_list: continue\n",
    "    print(f\"--- Group: {group_name} ---\")\n",
    "\n",
    "    # 1. Compute and Save Time Stats PER GROUP\n",
    "    p95_t, p95_dt = compute_group_time_percentiles(file_list)\n",
    "    time_stats_group = {\"p95_t\": p95_t, \"p95_dt\": p95_dt}\n",
    "    \n",
    "    ts_path = os.path.join(\"scalers\", f\"time_stats_{group_name}.json\")\n",
    "    with open(ts_path, \"w\") as f: json.dump(time_stats_group, f, indent=2)\n",
    "    print(f\"  ‚úì Time stats: p95_t={p95_t:.2e}, p95_dt={p95_dt:.2f}\")\n",
    "\n",
    "    # 2. Fit Feature Scaler (using Group Time)\n",
    "    dyn_rows_group = sample_dynamic_rows_for_scaler(file_list, p95_t, p95_dt)\n",
    "    f_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    f_scaler.fit(dyn_rows_group)\n",
    "    \n",
    "    fs_path = os.path.join(\"scalers\", f\"feature_scaler_{group_name}.pkl\")\n",
    "    joblib.dump(f_scaler, fs_path)\n",
    "    print(f\"  ‚úì Feature scaler saved\")\n",
    "\n",
    "    # 3. Fit Delta Scaler\n",
    "    dq_group = collect_positive_deltas_scaled(file_list)\n",
    "    delta_scaler_group = PercentileScaler(p_scale=95, p_clip=99.9)\n",
    "    delta_scaler_group.fit(dq_group)\n",
    "    \n",
    "    ds_path = os.path.join(\"scalers\", f\"delta_scaler_{group_name}.pkl\")\n",
    "    joblib.dump(delta_scaler_group, ds_path)\n",
    "    print(f\"  ‚úì Delta scaler saved\")\n",
    "\n",
    "# Static scaler remains global\n",
    "def collect_static_rows(train_files):\n",
    "    rows = []\n",
    "    for fn in train_files:\n",
    "        try:\n",
    "            d = load_mat(fn)\n",
    "            rows.append([ _grab_scalar(d[\"Bat_cap_profile\"]), _grab_scalar(d[\"R_ch_profile\"]), _grab_scalar(d[\"V_max_profile\"]), _grab_scalar(d[\"V_min_profile\"]) ])\n",
    "        except: pass\n",
    "    return np.array(rows, dtype=np.float64) if rows else np.zeros((1,4), dtype=np.float64)\n",
    "\n",
    "print(\"\\n[Pass-0] Fitting *global* static scaler ...\")\n",
    "static_rows = collect_static_rows(TRAIN_FILES)\n",
    "static_scaler = StandardScaler()\n",
    "static_scaler.fit(static_rows)\n",
    "joblib.dump(static_scaler, os.path.join(\"scalers\", \"static_scaler.pkl\"))\n",
    "print(\"‚úÖ Cell 2 complete: All per-group stats ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67b36c3b-0ed9-49ec-9405-d4ce3f1cfae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Hyperparameters registered.\n",
      "‚úÖ ARCHITECTURE: 4 Layers, 128 Embed Dim\n",
      "‚úÖ REGULARIZATION: DROPOUT=0.2, L2_REG=0.0005, NOISE_STDDEV=0.001\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# Cell 3 ‚Äî Main Hyperparameters (central)\n",
    "# ======================================\n",
    "\n",
    "# --- Windowing / dataset ---\n",
    "WINDOW_SIZE = 80    # using 25-step window\n",
    "STRIDE      = 1\n",
    "BATCH_SIZE  = 768   # (legacy; training actually uses BATCH_PER_DEVICE)\n",
    "\n",
    "# --- ‚≠êÔ∏è MODIFIED: Simplified Architecture ---\n",
    "EMBED_DIM       = 128    # Reduced from 64\n",
    "NUM_HEADS       = 4\n",
    "FF_DIM          = 64    # Reduced from 128\n",
    "NUM_LAYERS      = 4     # Reduced from 2\n",
    "SOFTPLUS_BETA   = 1.0\n",
    "GROUP_EMBED_DIM = 8\n",
    "\n",
    "# --- Regularization (Keep these) ---\n",
    "DROPOUT         = 0.20\n",
    "L2_REG          = 5e-4\n",
    "GAUSSIAN_NOISE_STDDEV = 0.001\n",
    "\n",
    "# --- Training / optimization ---\n",
    "BATCH_PER_DEVICE = 768  # effective batch size per GPU\n",
    "EPOCHS           = 50   # you rarely need 50 with early stopping\n",
    "LR               = 2.140965e-6 # same stable LR that worked well for you\n",
    "CLIPNORM         = 1.0\n",
    "AMSGRAD          = True\n",
    "\n",
    "# --- Loss weights ---\n",
    "LAMBDA_DATA = 1.0\n",
    "LAMBDA_PHYS = 1.030679\n",
    "LAMBDA_ZERO = 0.0\n",
    "HUBER_DELTA = 1.0 \n",
    "\n",
    "# --- Scheduler / early stopping ---\n",
    "VAL_FREQ            = 2   # validate more often to catch best epoch\n",
    "EARLY_STOP_PATIENCE = 5   # 5√ó2=10 epochs of no improvement allowed\n",
    "LR_PATIENCE         = 3\n",
    "LR_FACTOR           = 0.5\n",
    "LR_MIN              = 1e-6\n",
    "\n",
    "# --- Constants ---\n",
    "SCALE_DELTA = 1e5\n",
    "\n",
    "print(\"‚úÖ Hyperparameters registered.\")\n",
    "print(f\"‚úÖ ARCHITECTURE: {NUM_LAYERS} Layers, {EMBED_DIM} Embed Dim\")\n",
    "print(f\"‚úÖ REGULARIZATION: DROPOUT={DROPOUT}, L2_REG={L2_REG}, NOISE_STDDEV={GAUSSIAN_NOISE_STDDEV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "157b39c0-441c-43c7-bc64-5a579eca2f69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with v8 'Concat Conditioning' architecture:\n",
      "Model: \"PITM_v8_Concat_Conditioning\"\n",
      "________________________________________________________________________________________________________________________\n",
      " Layer (type)                          Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      " dyn_in (InputLayer)                   [(None, 80, 7)]            0             []                                      \n",
      "                                                                                                                        \n",
      " static_in (InputLayer)                [(None, 4)]                0             []                                      \n",
      "                                                                                                                        \n",
      " group_id_in (InputLayer)              [(None, 1)]                0             []                                      \n",
      "                                                                                                                        \n",
      " gaussian_noise_1 (GaussianNoise)      (None, 80, 7)              0             ['dyn_in[0][0]']                        \n",
      "                                                                                                                        \n",
      " expand_static (Lambda)                (None, 1, 4)               0             ['static_in[0][0]']                     \n",
      "                                                                                                                        \n",
      " group_embedding (Embedding)           (None, 1, 8)               16            ['group_id_in[0][0]']                   \n",
      "                                                                                                                        \n",
      " tile_static (Lambda)                  (None, 80, 4)              0             ['expand_static[0][0]',                 \n",
      "                                                                                 'gaussian_noise_1[0][0]']              \n",
      "                                                                                                                        \n",
      " tile_group (Lambda)                   (None, 80, 8)              0             ['group_embedding[0][0]']               \n",
      "                                                                                                                        \n",
      " concat_all_features (Concatenate)     (None, 80, 19)             0             ['gaussian_noise_1[0][0]',              \n",
      "                                                                                 'tile_static[0][0]',                   \n",
      "                                                                                 'tile_group[0][0]']                    \n",
      "                                                                                                                        \n",
      " input_projection (TimeDistributed)    (None, 80, 128)            2560          ['concat_all_features[0][0]']           \n",
      "                                                                                                                        \n",
      " shared_pos_enc (SharedPositionalEncod  (None, 80, 128)           10240         ['input_projection[0][0]']              \n",
      " ing)                                                                                                                   \n",
      "                                                                                                                        \n",
      " layer_normalization_10 (LayerNormaliz  (None, 80, 128)           256           ['shared_pos_enc[0][0]']                \n",
      " ation)                                                                                                                 \n",
      "                                                                                                                        \n",
      " multi_head_attention_5 (MultiHeadAtte  (None, 80, 128)           66048         ['layer_normalization_10[0][0]',        \n",
      " ntion)                                                                          'layer_normalization_10[0][0]']        \n",
      "                                                                                                                        \n",
      " dropout_10 (Dropout)                  (None, 80, 128)            0             ['multi_head_attention_5[0][0]']        \n",
      "                                                                                                                        \n",
      " add_10 (Add)                          (None, 80, 128)            0             ['shared_pos_enc[0][0]',                \n",
      "                                                                                 'dropout_10[0][0]']                    \n",
      "                                                                                                                        \n",
      " layer_normalization_11 (LayerNormaliz  (None, 80, 128)           256           ['add_10[0][0]']                        \n",
      " ation)                                                                                                                 \n",
      "                                                                                                                        \n",
      " dense_14 (Dense)                      (None, 80, 64)             8256          ['layer_normalization_11[0][0]']        \n",
      "                                                                                                                        \n",
      " dropout_11 (Dropout)                  (None, 80, 64)             0             ['dense_14[0][0]']                      \n",
      "                                                                                                                        \n",
      " dense_15 (Dense)                      (None, 80, 128)            8320          ['dropout_11[0][0]']                    \n",
      "                                                                                                                        \n",
      " add_11 (Add)                          (None, 80, 128)            0             ['add_10[0][0]',                        \n",
      "                                                                                 'dense_15[0][0]']                      \n",
      "                                                                                                                        \n",
      " layer_normalization_12 (LayerNormaliz  (None, 80, 128)           256           ['add_11[0][0]']                        \n",
      " ation)                                                                                                                 \n",
      "                                                                                                                        \n",
      " multi_head_attention_6 (MultiHeadAtte  (None, 80, 128)           66048         ['layer_normalization_12[0][0]',        \n",
      " ntion)                                                                          'layer_normalization_12[0][0]']        \n",
      "                                                                                                                        \n",
      " dropout_12 (Dropout)                  (None, 80, 128)            0             ['multi_head_attention_6[0][0]']        \n",
      "                                                                                                                        \n",
      " add_12 (Add)                          (None, 80, 128)            0             ['add_11[0][0]',                        \n",
      "                                                                                 'dropout_12[0][0]']                    \n",
      "                                                                                                                        \n",
      " layer_normalization_13 (LayerNormaliz  (None, 80, 128)           256           ['add_12[0][0]']                        \n",
      " ation)                                                                                                                 \n",
      "                                                                                                                        \n",
      " dense_16 (Dense)                      (None, 80, 64)             8256          ['layer_normalization_13[0][0]']        \n",
      "                                                                                                                        \n",
      " dropout_13 (Dropout)                  (None, 80, 64)             0             ['dense_16[0][0]']                      \n",
      "                                                                                                                        \n",
      " dense_17 (Dense)                      (None, 80, 128)            8320          ['dropout_13[0][0]']                    \n",
      "                                                                                                                        \n",
      " add_13 (Add)                          (None, 80, 128)            0             ['add_12[0][0]',                        \n",
      "                                                                                 'dense_17[0][0]']                      \n",
      "                                                                                                                        \n",
      " layer_normalization_14 (LayerNormaliz  (None, 80, 128)           256           ['add_13[0][0]']                        \n",
      " ation)                                                                                                                 \n",
      "                                                                                                                        \n",
      " multi_head_attention_7 (MultiHeadAtte  (None, 80, 128)           66048         ['layer_normalization_14[0][0]',        \n",
      " ntion)                                                                          'layer_normalization_14[0][0]']        \n",
      "                                                                                                                        \n",
      " dropout_14 (Dropout)                  (None, 80, 128)            0             ['multi_head_attention_7[0][0]']        \n",
      "                                                                                                                        \n",
      " add_14 (Add)                          (None, 80, 128)            0             ['add_13[0][0]',                        \n",
      "                                                                                 'dropout_14[0][0]']                    \n",
      "                                                                                                                        \n",
      " layer_normalization_15 (LayerNormaliz  (None, 80, 128)           256           ['add_14[0][0]']                        \n",
      " ation)                                                                                                                 \n",
      "                                                                                                                        \n",
      " dense_18 (Dense)                      (None, 80, 64)             8256          ['layer_normalization_15[0][0]']        \n",
      "                                                                                                                        \n",
      " dropout_15 (Dropout)                  (None, 80, 64)             0             ['dense_18[0][0]']                      \n",
      "                                                                                                                        \n",
      " dense_19 (Dense)                      (None, 80, 128)            8320          ['dropout_15[0][0]']                    \n",
      "                                                                                                                        \n",
      " add_15 (Add)                          (None, 80, 128)            0             ['add_14[0][0]',                        \n",
      "                                                                                 'dense_19[0][0]']                      \n",
      "                                                                                                                        \n",
      " layer_normalization_16 (LayerNormaliz  (None, 80, 128)           256           ['add_15[0][0]']                        \n",
      " ation)                                                                                                                 \n",
      "                                                                                                                        \n",
      " multi_head_attention_8 (MultiHeadAtte  (None, 80, 128)           66048         ['layer_normalization_16[0][0]',        \n",
      " ntion)                                                                          'layer_normalization_16[0][0]']        \n",
      "                                                                                                                        \n",
      " dropout_16 (Dropout)                  (None, 80, 128)            0             ['multi_head_attention_8[0][0]']        \n",
      "                                                                                                                        \n",
      " add_16 (Add)                          (None, 80, 128)            0             ['add_15[0][0]',                        \n",
      "                                                                                 'dropout_16[0][0]']                    \n",
      "                                                                                                                        \n",
      " layer_normalization_17 (LayerNormaliz  (None, 80, 128)           256           ['add_16[0][0]']                        \n",
      " ation)                                                                                                                 \n",
      "                                                                                                                        \n",
      " dense_20 (Dense)                      (None, 80, 64)             8256          ['layer_normalization_17[0][0]']        \n",
      "                                                                                                                        \n",
      " dropout_17 (Dropout)                  (None, 80, 64)             0             ['dense_20[0][0]']                      \n",
      "                                                                                                                        \n",
      " dense_21 (Dense)                      (None, 80, 128)            8320          ['dropout_17[0][0]']                    \n",
      "                                                                                                                        \n",
      " add_17 (Add)                          (None, 80, 128)            0             ['add_16[0][0]',                        \n",
      "                                                                                 'dense_21[0][0]']                      \n",
      "                                                                                                                        \n",
      " take_last_token (Lambda)              (None, 128)                0             ['add_17[0][0]']                        \n",
      "                                                                                                                        \n",
      " flatten_group (Flatten)               (None, 8)                  0             ['group_embedding[0][0]']               \n",
      "                                                                                                                        \n",
      " concat_head (Concatenate)             (None, 136)                0             ['take_last_token[0][0]',               \n",
      "                                                                                 'flatten_group[0][0]']                 \n",
      "                                                                                                                        \n",
      " dense_22 (Dense)                      (None, 64)                 8768          ['concat_head[0][0]']                   \n",
      "                                                                                                                        \n",
      " dense_23 (Dense)                      (None, 32)                 2080          ['dense_22[0][0]']                      \n",
      "                                                                                                                        \n",
      " raw_pre_softplus (Dense)              (None, 1)                  33            ['dense_23[0][0]']                      \n",
      "                                                                                                                        \n",
      " delta_hat (Lambda)                    (None, 1)                  0             ['raw_pre_softplus[0][0]']              \n",
      "                                                                                                                        \n",
      "========================================================================================================================\n",
      "Total params: 356,241\n",
      "Trainable params: 356,241\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________________________________________________\n",
      "\n",
      "‚úÖ Cell 4 ready: v8 'Concat' model built (uncompiled).\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Cell 4 ‚Äî Model Builder (v8 - \"Concat Conditioning\")\n",
    "# ==========================================================\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, LayerNormalization, MultiHeadAttention,\n",
    "    Add, Concatenate, TimeDistributed, Embedding, Lambda,\n",
    "    Flatten, GaussianNoise\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "\n",
    "# (transformer_encoder_prenorm is unchanged)\n",
    "def transformer_encoder_prenorm(x, head_size, num_heads, ff_dim, dropout, l2_reg):\n",
    "    x_ln1 = LayerNormalization(epsilon=1e-6)(x)\n",
    "    attn  = MultiHeadAttention(num_heads=num_heads, key_dim=head_size, dropout=dropout)(x_ln1, x_ln1)\n",
    "    attn  = Dropout(dropout)(attn)\n",
    "    x     = Add()([x, attn])\n",
    "    \n",
    "    x_ln2 = LayerNormalization(epsilon=1e-6)(x)\n",
    "    ff    = Dense(ff_dim, activation=\"relu\", kernel_regularizer=regularizers.l2(l2_reg))(x_ln2)\n",
    "    ff    = Dropout(dropout)(ff)\n",
    "    ff    = Dense(x.shape[-1], kernel_regularizer=regularizers.l2(l2_reg))(ff)\n",
    "    x     = Add()([x, ff])\n",
    "    return x\n",
    "\n",
    "# (SharedPositionalEncoding is unchanged)\n",
    "class SharedPositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, window_size, embedding_dim, **kwargs):\n",
    "        super().__init__(**kwargs); self.window_size = int(window_size); self.embedding_dim = int(embedding_dim)\n",
    "        self.embedding_layer = Embedding(input_dim=self.window_size, output_dim=self.embedding_dim, name=\"shared_pos_embedding\")\n",
    "    def call(self, x):\n",
    "        T = tf.shape(x)[1]; positions = tf.range(start=0, limit=T, delta=1); pos_enc = self.embedding_layer(positions)\n",
    "        pos_enc = tf.expand_dims(pos_enc, axis=0); pos_enc = tf.tile(pos_enc, [tf.shape(x)[0], 1, 1]); return x + pos_enc\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config(); cfg.update({\"window_size\": self.window_size, \"embedding_dim\": self.embedding_dim}); return cfg\n",
    "\n",
    "# ---- Model builder (v8 - Concat Conditioning) ----\n",
    "def build_pitm_model(\n",
    "    window_size,\n",
    "    num_groups,                  # From Cell 1\n",
    "    group_embed_dim=GROUP_EMBED_DIM, # From Cell 3\n",
    "    embed_dim=EMBED_DIM,\n",
    "    num_heads=NUM_HEADS,\n",
    "    ff_dim=FF_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    l2_reg=L2_REG,\n",
    "    noise_stddev=GAUSSIAN_NOISE_STDDEV # From Cell 3\n",
    "):\n",
    "    \"\"\"\n",
    "    v8: Uses Concatenation for Group ID instead of Addition.\n",
    "    This prevents LayerNorm from washing out the group signal.\n",
    "    \"\"\"\n",
    "    head_size = max(1, embed_dim // num_heads)\n",
    "\n",
    "    # ----- 1. Define Inputs -----\n",
    "    dyn_in = Input(shape=(window_size, 7), name=\"dyn_in\") # 7 features (incl. extra)\n",
    "    stat_in = Input(shape=(4,), name=\"static_in\")\n",
    "    group_id_in = Input(shape=(1,), name=\"group_id_in\", dtype='int32') \n",
    "\n",
    "    # ----- 2. Data Augmentation (Noise) -----\n",
    "    dyn_noised = GaussianNoise(noise_stddev)(dyn_in)\n",
    "\n",
    "    # ----- 3. Static Physics Processing -----\n",
    "    stat_expanded = Lambda(lambda x: tf.expand_dims(x, axis=1), name=\"expand_static\")(stat_in) \n",
    "    stat_tiled = Lambda(lambda x: tf.tile(x[0], [1, window_size, 1]), name=\"tile_static\")([stat_expanded, dyn_noised]) \n",
    "\n",
    "    # ----- 4. Group Embedding & Tiling -----\n",
    "    group_vec = Embedding(\n",
    "        input_dim=num_groups, \n",
    "        output_dim=group_embed_dim, \n",
    "        embeddings_regularizer=regularizers.l2(l2_reg),\n",
    "        name=\"group_embedding\"\n",
    "    )(group_id_in) # Shape: (Batch, 1, 8)\n",
    "\n",
    "    group_vec_tiled = Lambda(lambda x: tf.tile(x, [1, window_size, 1]), name=\"tile_group\")(group_vec)\n",
    "\n",
    "    # ----- 5. ‚≠êÔ∏è CONCATENATION (The Fix) ‚≠êÔ∏è -----\n",
    "    # Instead of adding, we stack them channel-wise.\n",
    "    # Dynamic(7) + Static(4) + Group(8) = 19 channels\n",
    "    dyn_combined = Concatenate(name=\"concat_all_features\")([dyn_noised, stat_tiled, group_vec_tiled])\n",
    "    \n",
    "    # Project everything to the Transformer dimension\n",
    "    x = TimeDistributed(\n",
    "        Dense(embed_dim, activation=\"relu\", kernel_regularizer=regularizers.l2(l2_reg)), \n",
    "        name=\"input_projection\"\n",
    "    )(dyn_combined)\n",
    "    \n",
    "    # ----- 6. Shared Body (Transformer) -----\n",
    "    shared_pos = SharedPositionalEncoding(window_size, embed_dim, name=\"shared_pos_enc\")\n",
    "    x = shared_pos(x) \n",
    "    for _ in range(num_layers):\n",
    "        x = transformer_encoder_prenorm(x, head_size=head_size, num_heads=num_heads, ff_dim=ff_dim, dropout=dropout, l2_reg=l2_reg)\n",
    "    \n",
    "    # Take last token\n",
    "    take_last = Lambda(lambda t: t[:, -1, :], name=\"take_last_token\")\n",
    "    x_last = take_last(x)\n",
    "    \n",
    "    # ----- 7. ‚≠êÔ∏è Output Head Conditioning ‚≠êÔ∏è -----\n",
    "    # Concatenate the Group ID *again* so the final regressor definitely knows which group it is\n",
    "    group_vec_flat = Flatten(name=\"flatten_group\")(group_vec)\n",
    "    fused = Concatenate(name=\"concat_head\")([x_last, group_vec_flat])\n",
    "    \n",
    "    fused_head = Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(l2_reg))(fused)\n",
    "    fused_head = Dense(32, activation=\"relu\", kernel_regularizer=regularizers.l2(l2_reg))(fused_head)\n",
    "    \n",
    "    raw = Dense(\n",
    "        1,\n",
    "        name=\"raw_pre_softplus\",\n",
    "        bias_initializer=initializers.Constant(0.0),\n",
    "        kernel_regularizer=regularizers.l2(l2_reg),\n",
    "    )(fused_head)\n",
    "\n",
    "    # --- 8. Final Activation ---\n",
    "    def softplus32(z, beta=1.0):\n",
    "        z32 = tf.cast(z, tf.float32)\n",
    "        out32 = tf.nn.softplus(beta * z32) / beta\n",
    "        return tf.cast(out32, z.dtype)\n",
    "    \n",
    "    delta_hat = Lambda(lambda z: softplus32(z, beta=SOFTPLUS_BETA),\n",
    "                       name=\"delta_hat\")(raw)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[dyn_in, stat_in, group_id_in], \n",
    "        outputs=delta_hat,\n",
    "        name=\"PITM_v8_Concat_Conditioning\"\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# (Loss function is unchanged)\n",
    "def pitm_delta_loss(lambda_data=1.0, lambda_phys=1.0, lambda_zero=0.0, huber_delta=1.5):\n",
    "    def huber(e, delta): a = tf.abs(e); return tf.where(a <= delta, 0.5 * tf.square(e), delta * (a - 0.5 * delta))\n",
    "    def _loss(y_true, y_pred):\n",
    "        dq_exp = y_true[:, 0:1]; dq_pb = y_true[:, 1:2]; dq_hat = y_pred\n",
    "        pos_mask = tf.cast(tf.logical_or(dq_exp > 0.0, dq_pb > 0.0), tf.float32); zero_mask = 1.0 - pos_mask\n",
    "        l_data = tf.reduce_mean(huber(dq_exp - dq_hat, huber_delta)); l_phys = tf.reduce_mean(huber(dq_pb - dq_hat, huber_delta))\n",
    "        l_zero = tf.reduce_mean(zero_mask * dq_hat)\n",
    "        return lambda_data*l_data + lambda_phys*l_phys + lambda_zero*l_zero\n",
    "    return _loss\n",
    "\n",
    "print(\"Building model with v8 'Concat Conditioning' architecture:\")\n",
    "model = build_pitm_model(\n",
    "    window_size=WINDOW_SIZE,\n",
    "    num_groups=NUM_GROUPS,  # From Cell 1\n",
    "    embed_dim=EMBED_DIM,\n",
    "    num_heads=NUM_HEADS,\n",
    "    ff_dim=FF_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "model.summary(line_length=120)\n",
    "print(\"\\n‚úÖ Cell 4 ready: v8 'Concat' model built (uncompiled).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b578f63-82a3-4e29-834b-eea4600bfb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# Cell 4.5 ‚Äî Pre-process (v8.2 - Fixed Weighting)\n",
    "# ===============================================\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "# --- Local Helpers ---\n",
    "def _read_field_local(f, key):\n",
    "    if key not in f: return None\n",
    "    return np.squeeze(np.array(f[key]))\n",
    "\n",
    "def _grab1_local(x): \n",
    "    if x is None: return 0.0\n",
    "    return float(np.asarray(x).reshape(-1)[0])\n",
    "\n",
    "def _make_time_channels_local(Time_s, p95_t_in, p95_dt_in):\n",
    "    t = np.asarray(Time_s, np.float64).flatten()\n",
    "    elapsed = t - t[0]\n",
    "    dt = np.diff(t, prepend=t[0])\n",
    "    t_abs_norm = np.clip(elapsed / max(p95_t_in, 1e-12), 0.0, 4.0)\n",
    "    dt_norm    = np.clip(dt      / max(p95_dt_in, 1e-12), 0.0, 4.0)\n",
    "    return t_abs_norm, dt_norm\n",
    "\n",
    "def _calc_deltas_local(Q_norm, scale_delta_in):\n",
    "    Q_norm = np.asarray(Q_norm, np.float64).flatten()\n",
    "    if Q_norm.size < 2: return np.zeros(0, np.float64)\n",
    "    dq = np.maximum(Q_norm[1:] - Q_norm[:-1], 0.0) * scale_delta_in\n",
    "    return dq.astype(np.float64)\n",
    "\n",
    "def load_mat_local_robust(file_name):\n",
    "    path = os.path.join(DATA_DIR, file_name)\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        return {\n",
    "            \"SOC_p\": _read_field_local(f,\"SOC_p\"), \n",
    "            \"Time_s_p\": _read_field_local(f,\"Time_s_p\"),\n",
    "            \"Q_exp_p\": _read_field_local(f,\"Q_exp_p\"), \n",
    "            \"Q_total_p\": _read_field_local(f,\"Q_total_p\"),\n",
    "            \"V_cum_p\": _read_field_local(f,\"V_cum_p\"), \n",
    "            \"Temp_cum_p\": _read_field_local(f,\"Temp_cum_p\"),\n",
    "            \"C_rate_profile\": _read_field_local(f,\"C_rate_profile\"),\n",
    "            \"Bat_cap_profile\": _read_field_local(f,\"Bat_cap_profile\"), \n",
    "            \"R_ch_profile\": _read_field_local(f,\"R_ch_profile\"),\n",
    "            \"V_max_profile\": _read_field_local(f,\"V_max_profile\"), \n",
    "            \"V_min_profile\": _read_field_local(f,\"V_min_profile\"),\n",
    "            \"Cap_Nom\": _read_field_local(f,\"Cap_Nom\")\n",
    "        }\n",
    "\n",
    "# --- Main Builder ---\n",
    "def build_training_arrays(window_size, stride):\n",
    "    global X_train_dyn, X_train_st, X_train_gid, y_train, train_sample_weights\n",
    "    \n",
    "    print(f\"\\n--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\")\n",
    "    \n",
    "    # 1. Load Global Static Scaler\n",
    "    try:\n",
    "        static_global = joblib.load(os.path.join(\"scalers\", \"static_scaler.pkl\"))\n",
    "    except:\n",
    "        print(\"Error: static_scaler.pkl not found. Run Cell 2 first.\")\n",
    "        return\n",
    "\n",
    "    # 2. ‚≠êÔ∏è FIXED: Robust Window Counting ‚≠êÔ∏è\n",
    "    print(\"--- Counting windows for balancing ---\")\n",
    "    group_counts = {}\n",
    "    for group_name, file_list in TRAIN_GROUPS.items():\n",
    "        count = 0\n",
    "        for fn in file_list:\n",
    "            try:\n",
    "                # Use the robust loader so we get the exact same shape as the main loop\n",
    "                d = load_mat_local_robust(fn)\n",
    "                N = d[\"SOC_p\"].flatten().shape[0]\n",
    "                count += max(0, (N - window_size) // stride + 1)\n",
    "            except Exception as e: \n",
    "                print(f\"  Warning (counting): {fn} - {e}\")\n",
    "        group_counts[group_name] = count\n",
    "        print(f\"  Group '{group_name}': {count} windows\")\n",
    "\n",
    "    total_windows = sum(group_counts.values())\n",
    "    if total_windows == 0:\n",
    "        print(\"üî• FATAL: Zero total windows found. Check DATA_DIR or file paths.\")\n",
    "        return\n",
    "\n",
    "    num_groups = len(group_counts)\n",
    "    ideal_count = total_windows / max(num_groups, 1)\n",
    "    \n",
    "    # Calculate Weights\n",
    "    group_weights_map = {}\n",
    "    for g, c in group_counts.items():\n",
    "        # Weight = Ideal / Actual. Small groups get > 1.0, Large groups get < 1.0\n",
    "        w = ideal_count / max(c, 1) \n",
    "        group_weights_map[g] = w\n",
    "        print(f\"  -> Weight for '{g}': {w:.4f}\")\n",
    "\n",
    "    # 3. Process Data\n",
    "    all_X_dyn, all_X_st, all_X_gid, all_y, all_sample_weights = [], [], [], [], []\n",
    "\n",
    "    print(\"\\n--- Processing Groups ---\")\n",
    "    for group_name, file_list in TRAIN_GROUPS.items():\n",
    "        if not file_list: continue\n",
    "        group_id = GROUP_TO_ID_MAP[group_name]\n",
    "        weight_val = group_weights_map.get(group_name, 1.0)\n",
    "\n",
    "        # Load Per-Group Configs\n",
    "        try:\n",
    "            feature_scaler_group = joblib.load(os.path.join(\"scalers\", f\"feature_scaler_{group_name}.pkl\"))\n",
    "            delta_scaler_group = joblib.load(os.path.join(\"scalers\", f\"delta_scaler_{group_name}.pkl\"))\n",
    "            with open(os.path.join(\"scalers\", f\"time_stats_{group_name}.json\"), \"r\") as f:\n",
    "                tstats = json.load(f)\n",
    "                p95_t_group = float(tstats[\"p95_t\"])\n",
    "                p95_dt_group = float(tstats[\"p95_dt\"])\n",
    "        except Exception as e:\n",
    "            print(f\"üî• ERROR loading stats for {group_name}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        group_X_dyn, group_X_st, group_X_gid, group_y = [], [], [], []\n",
    "\n",
    "        for fn in tqdm(file_list, desc=f\"  {group_name}\"):\n",
    "            try:\n",
    "                d = load_mat_local_robust(fn)\n",
    "                \n",
    "                SOC = np.asarray(d[\"SOC_p\"]).flatten()\n",
    "                V   = np.asarray(d[\"V_cum_p\"]).flatten()\n",
    "                T   = np.asarray(d[\"Temp_cum_p\"]).flatten()\n",
    "                Cr  = np.asarray(d[\"C_rate_profile\"]).flatten()\n",
    "                t_s = np.asarray(d[\"Time_s_p\"]).flatten()\n",
    "                \n",
    "                # Group-specific Time\n",
    "                t_abs, dt_norm = _make_time_channels_local(t_s, p95_t_group, p95_dt_group)\n",
    "                \n",
    "                Bat = _grab1_local(d[\"Bat_cap_profile\"])\n",
    "                Rch = _grab1_local(d[\"R_ch_profile\"])\n",
    "                Vmx = _grab1_local(d[\"V_max_profile\"])\n",
    "                Vmn = _grab1_local(d[\"V_min_profile\"])\n",
    "                \n",
    "                # Use Globals for T_norm\n",
    "                V_norm = np.clip((V - Vmn)/max(Vmx-Vmn, 1e-6), -1, 2)\n",
    "                T_norm = np.clip((T - T_MIN)/(T_MAX - T_MIN), -1, 2)\n",
    "                \n",
    "                N = min(SOC.size, t_abs.size, Cr.size)\n",
    "                if N < window_size: continue\n",
    "                \n",
    "                # Stack 6 features\n",
    "                rows6 = np.stack([SOC[:N], V_norm[:N], T_norm[:N], t_abs[:N], dt_norm[:N], Cr[:N]], axis=1)\n",
    "                rows_scaled = feature_scaler_group.transform(rows6).astype(np.float32)\n",
    "                \n",
    "                win_pos = np.linspace(0, 1, window_size, dtype=np.float32).reshape(-1, 1)\n",
    "                static_vec = static_global.transform([[Bat, Rch, Vmx, Vmn]]).astype(np.float32)[0]\n",
    "                \n",
    "                dq_e = _calc_deltas_local(d[\"Q_exp_p\"], SCALE_DELTA)\n",
    "                dq_p = _calc_deltas_local(d[\"Q_total_p\"], SCALE_DELTA)\n",
    "\n",
    "                for end in range(window_size, N, stride):\n",
    "                    w6 = rows_scaled[end-window_size:end]\n",
    "                    w7 = np.concatenate([w6, win_pos], axis=1)\n",
    "                    \n",
    "                    group_X_dyn.append(w7)\n",
    "                    group_X_st.append(static_vec)\n",
    "                    group_X_gid.append([group_id])\n",
    "                    \n",
    "                    idx = end - 1\n",
    "                    y0 = delta_scaler_group.transform([dq_e[idx]])[0,0] if idx < dq_e.size else 0.0\n",
    "                    y1 = delta_scaler_group.transform([dq_p[idx]])[0,0] if idx < dq_p.size else 0.0\n",
    "                    group_y.append([y0, y1])\n",
    "            except Exception as e: \n",
    "                print(f\"‚ùå Err {fn}: {e}\")\n",
    "        \n",
    "        # Store group data\n",
    "        if len(group_X_dyn) > 0:\n",
    "            all_X_dyn.append(np.array(group_X_dyn, dtype=np.float32))\n",
    "            all_X_st.append(np.array(group_X_st, dtype=np.float32))\n",
    "            all_X_gid.append(np.array(group_X_gid, dtype=np.int32))\n",
    "            all_y.append(np.array(group_y, dtype=np.float32))\n",
    "            \n",
    "            # ‚≠êÔ∏è APPLY CALCULATED WEIGHT ‚≠êÔ∏è\n",
    "            # Create an array of weights (all same value for this group)\n",
    "            w_arr = np.full(len(group_y), weight_val, dtype=np.float32)\n",
    "            all_sample_weights.append(w_arr)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Warning: No windows generated for group {group_name}\")\n",
    "\n",
    "    # Concatenate everything\n",
    "    print(\"Concatenating...\")\n",
    "    if len(all_X_dyn) == 0: \n",
    "        print(\"üî• FATAL: No data generated. Check errors.\")\n",
    "        return\n",
    "        \n",
    "    X_train_dyn = np.concatenate(all_X_dyn)\n",
    "    X_train_st = np.concatenate(all_X_st)\n",
    "    X_train_gid = np.concatenate(all_X_gid)\n",
    "    y_train = np.concatenate(all_y)\n",
    "    train_sample_weights = np.concatenate(all_sample_weights)\n",
    "    \n",
    "    # Shuffle (Critical: shuffle weights in sync!)\n",
    "    indices = np.arange(len(y_train))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    X_train_dyn = X_train_dyn[indices]\n",
    "    X_train_st = X_train_st[indices]\n",
    "    X_train_gid = X_train_gid[indices]\n",
    "    y_train = y_train[indices]\n",
    "    train_sample_weights = train_sample_weights[indices]\n",
    "    \n",
    "    globals()[\"X_train_dyn\"] = X_train_dyn\n",
    "    globals()[\"X_train_st\"]  = X_train_st\n",
    "    globals()[\"X_train_gid\"] = X_train_gid\n",
    "    globals()[\"y_train\"]     = y_train\n",
    "    globals()[\"train_sample_weights\"] = train_sample_weights\n",
    "\n",
    "    print(f\"‚úÖ Done. {len(y_train)} windows generated. Weights applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6805055e-b343-48a2-a401-462b3bac70fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cell 5a complete: Fixed LR variable scope.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Cell 5a ‚Äî Training Setup + Validation Generator (v8 - Fixed LR Scope)\n",
    "# ==========================================================\n",
    "import os, csv, math, json, random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import mixed_precision\n",
    "import joblib\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# --- Load Global Static Scaler ---\n",
    "static_scaler = joblib.load(os.path.join(\"scalers\", \"static_scaler.pkl\"))\n",
    "\n",
    "# --- Loss Function ---\n",
    "def pitm_delta_loss_mp(lambda_data=LAMBDA_DATA, lambda_phys=LAMBDA_PHYS,\n",
    "                       lambda_zero=LAMBDA_ZERO, huber_delta=HUBER_DELTA):\n",
    "    @tf.function\n",
    "    def huber(e, delta):\n",
    "        e = tf.cast(e, tf.float32)\n",
    "        delta = tf.cast(delta, tf.float32)\n",
    "        a = tf.abs(e)\n",
    "        return tf.where(a <= delta, 0.5 * tf.square(e), delta * (a - 0.5 * delta))\n",
    "    @tf.function\n",
    "    def _loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32); y_pred = tf.cast(y_pred, tf.float32)\n",
    "        dq_exp = y_true[:, 0:1]; dq_pb = y_true[:, 1:2]; dq_hat = y_pred\n",
    "        pos_mask = tf.cast(tf.logical_or(dq_exp > 0.0, dq_pb > 0.0), tf.float32)\n",
    "        l_data = tf.reduce_mean(huber(dq_exp - dq_hat, huber_delta))\n",
    "        l_phys = tf.reduce_mean(huber(dq_pb - dq_hat, huber_delta))\n",
    "        l_zero = tf.reduce_mean((1.0 - pos_mask) * dq_hat)\n",
    "        return tf.cast(lambda_data*l_data + lambda_phys*l_phys + lambda_zero*l_zero, tf.float32)\n",
    "    return _loss\n",
    "\n",
    "# --- Validation Helpers ---\n",
    "def _make_time_channels_np(Time_s, p95_t_in, p95_dt_in):\n",
    "    t = np.asarray(Time_s, np.float64).flatten()\n",
    "    elapsed = t - t[0]; dt = np.diff(t, prepend=t[0])\n",
    "    t_abs_norm = np.clip(elapsed / max(p95_t_in, 1e-12), 0.0, 4.0)\n",
    "    dt_norm    = np.clip(dt      / max(p95_dt_in, 1e-12), 0.0, 4.0)\n",
    "    return t_abs_norm, dt_norm\n",
    "\n",
    "def _positive_deltas_scaled_np(Q_norm):\n",
    "    Q_norm = np.asarray(Q_norm, np.float64).flatten()\n",
    "    if Q_norm.size < 2: return np.zeros(0, np.float64)\n",
    "    dq = np.maximum(Q_norm[1:] - Q_norm[:-1], 0.0) * SCALE_DELTA\n",
    "    return dq.astype(np.float64)\n",
    "\n",
    "def _window_count(N, T, s): return int(max(0, (N - T) // s + 1))\n",
    "\n",
    "def load_numpy_series_val(file_name, p95_t, p95_dt):\n",
    "    path = os.path.join(DATA_DIR, file_name)\n",
    "    d = {}\n",
    "    with h5py.File(path, 'r') as f:\n",
    "        for k in [\"SOC_p\",\"V_cum_p\",\"Temp_cum_p\",\"C_rate_profile\",\"Time_s_p\",\"Q_exp_p\",\"Q_total_p\",\n",
    "                  \"Bat_cap_profile\",\"R_ch_profile\",\"V_max_profile\",\"V_min_profile\",\"Cap_Nom\"]:\n",
    "            if k in f: d[k] = np.squeeze(np.array(f[k]))\n",
    "            \n",
    "    SOC=d[\"SOC_p\"]; V=d[\"V_cum_p\"]; T=d[\"Temp_cum_p\"]; Cr=d[\"C_rate_profile\"]; t_s=d[\"Time_s_p\"]\n",
    "    Bat=float(d[\"Bat_cap_profile\"].flat[0]); Rch=float(d[\"R_ch_profile\"].flat[0])\n",
    "    Vmx=float(d[\"V_max_profile\"].flat[0]); Vmn=float(d[\"V_min_profile\"].flat[0])\n",
    "    \n",
    "    t_abs, dt_norm = _make_time_channels_np(t_s, p95_t, p95_dt)\n",
    "    V_norm = np.clip((V - Vmn)/max(Vmx-Vmn, 1e-6), -1, 2)\n",
    "    T_norm = np.clip((T - 10.0)/(40.0), -1, 2)\n",
    "    \n",
    "    N = min(SOC.size, V_norm.size, t_abs.size, Cr.size)\n",
    "    return {\n",
    "        \"SOC\":SOC[:N], \"V_norm\":V_norm[:N], \"T_norm\":T_norm[:N], \"Cr\":Cr[:N],\n",
    "        \"t_abs\":t_abs[:N], \"dt\":dt_norm[:N], \n",
    "        \"static\": np.array([Bat, Rch, Vmx, Vmn], dtype=np.float32),\n",
    "        \"dq_e\": _positive_deltas_scaled_np(d[\"Q_exp_p\"]),\n",
    "        \"dq_p\": _positive_deltas_scaled_np(d[\"Q_total_p\"]),\n",
    "        \"N\": N\n",
    "    }\n",
    "\n",
    "# --- Validation Generator ---\n",
    "def stream_windows_from_files(file_list, window_size, stride, need_targets=True, shuffle=True, infinite=False, batch_size=128, seed=None):\n",
    "    \n",
    "    # Identify group and load scalers/time stats\n",
    "    delta_scaler = None; feature_scaler = None; p95_t = 1.0; p95_dt = 1.0; group_id = -1\n",
    "    \n",
    "    if file_list:\n",
    "        fn = file_list[0]\n",
    "        if fn in FILE_TO_GROUP_MAP:\n",
    "            gname = FILE_TO_GROUP_MAP[fn]\n",
    "            group_id = GROUP_TO_ID_MAP[gname]\n",
    "            try:\n",
    "                delta_scaler = joblib.load(os.path.join(\"scalers\", f\"delta_scaler_{gname}.pkl\"))\n",
    "                feature_scaler = joblib.load(os.path.join(\"scalers\", f\"feature_scaler_{gname}.pkl\"))\n",
    "                with open(os.path.join(\"scalers\", f\"time_stats_{gname}.json\"),\"r\") as f:\n",
    "                    ts = json.load(f)\n",
    "                    p95_t = float(ts[\"p95_t\"]); p95_dt = float(ts[\"p95_dt\"])\n",
    "            except Exception as e:\n",
    "                print(f\"Err loading val scalers: {e}\"); return\n",
    "        else: return\n",
    "\n",
    "    rng = random.Random(seed)\n",
    "    meta = []\n",
    "    for fn in file_list:\n",
    "        try:\n",
    "            p = load_numpy_series_val(fn, p95_t, p95_dt)\n",
    "            n_win = _window_count(p[\"N\"], window_size, stride)\n",
    "            if n_win>0: meta.append((fn, n_win))\n",
    "        except: pass\n",
    "\n",
    "    total_win = sum(n for _,n in meta)\n",
    "    steps = int(math.ceil(total_win/batch_size))\n",
    "\n",
    "    def one_pass():\n",
    "        series = []\n",
    "        order = rng.sample(meta, k=len(meta)) if shuffle else meta\n",
    "        \n",
    "        for fn, _ in order:\n",
    "            p = load_numpy_series_val(fn, p95_t, p95_dt)\n",
    "            \n",
    "            rows6 = np.stack([p[\"SOC\"], p[\"V_norm\"], p[\"T_norm\"], p[\"t_abs\"], p[\"dt\"], p[\"Cr\"]], axis=1)\n",
    "            rows_sc = feature_scaler.transform(rows6).astype(np.float32)\n",
    "            \n",
    "            static_raw = p[\"static\"].reshape(1,-1)\n",
    "            static_sc = static_scaler.transform(static_raw).astype(np.float32)[0]\n",
    "            win_pos = np.linspace(0, 1, window_size, dtype=np.float32).reshape(-1, 1)\n",
    "            \n",
    "            series.append({\"p\":p, \"rows\":rows_sc, \"win_pos\":win_pos, \"st\":static_sc, \"i\":window_size, \"n\":p[\"N\"], \"done\":False})\n",
    "            \n",
    "        X_d, X_s, X_g, Y = [], [], [], []\n",
    "        alive = len(series)\n",
    "        \n",
    "        while alive > 0:\n",
    "            for b in series:\n",
    "                if b[\"done\"]: continue\n",
    "                end = b[\"i\"]\n",
    "                if end > b[\"n\"]: b[\"done\"]=True; continue\n",
    "                \n",
    "                w6 = b[\"rows\"][end-window_size:end]\n",
    "                w7 = np.concatenate([w6, b[\"win_pos\"]], axis=1)\n",
    "                X_d.append(w7); X_s.append(b[\"st\"]); X_g.append(group_id)\n",
    "                \n",
    "                if need_targets:\n",
    "                    idx = end-1\n",
    "                    y0 = delta_scaler.transform([b[\"p\"][\"dq_e\"][idx]])[0,0] if idx<b[\"p\"][\"dq_e\"].size else 0.0\n",
    "                    y1 = delta_scaler.transform([b[\"p\"][\"dq_p\"][idx]])[0,0] if idx<b[\"p\"][\"dq_p\"].size else 0.0\n",
    "                    Y.append([y0, y1])\n",
    "                \n",
    "                b[\"i\"] += stride\n",
    "                \n",
    "                if len(X_d) == batch_size:\n",
    "                    Xd = np.array(X_d, np.float32); Xs = np.array(X_s, np.float32); Xg = np.array(X_g, np.int32).reshape(-1,1)\n",
    "                    if need_targets:\n",
    "                        yield (Xd, Xs, Xg, np.nan_to_num(np.array(Y, np.float32)))\n",
    "                        Y = []\n",
    "                    else: yield (Xd, Xs, Xg)\n",
    "                    X_d, X_s, X_g = [], [], []\n",
    "                    \n",
    "            alive = sum(1 for b in series if not b[\"done\"])\n",
    "            \n",
    "        if len(X_d) > 0:\n",
    "            Xd = np.array(X_d, np.float32); Xs = np.array(X_s, np.float32); Xg = np.array(X_g, np.int32).reshape(-1,1)\n",
    "            if need_targets: yield (Xd, Xs, Xg, np.nan_to_num(np.array(Y, np.float32)))\n",
    "            else: yield (Xd, Xs, Xg)\n",
    "\n",
    "    def gen():\n",
    "        if infinite: \n",
    "            while True: yield from one_pass()\n",
    "        else: yield from one_pass()\n",
    "\n",
    "    out_sig = (tf.TensorSpec((None,window_size,7),tf.float32), tf.TensorSpec((None,4),tf.float32), tf.TensorSpec((None,1),tf.int32))\n",
    "    if need_targets: out_sig += (tf.TensorSpec((None,2),tf.float32),)\n",
    "    \n",
    "    ds = tf.data.Dataset.from_generator(gen, output_signature=out_sig)\n",
    "    if need_targets: ds = ds.map(lambda d,s,g,y: ((d,s,g),y))\n",
    "    else: ds = ds.map(lambda d,s,g: (d,s,g))\n",
    "    \n",
    "    if infinite: ds = ds.repeat()\n",
    "    return ds.prefetch(1), steps\n",
    "\n",
    "# --- Dataset Creator ---\n",
    "def create_balanced_training_dataset(batch_size, seed):\n",
    "    try: _=X_train_dyn\n",
    "    except: print(\"Run build_training_arrays first\"); return None, 0\n",
    "    ds = tf.data.Dataset.from_tensor_slices(((X_train_dyn, X_train_st, X_train_gid), y_train, train_sample_weights))\n",
    "    ds = ds.map(lambda i,t,w: (i,t,w)).shuffle(len(X_train_dyn), seed=seed).repeat().batch(batch_size).prefetch(1)\n",
    "    return ds, int(math.ceil(len(X_train_dyn)/batch_size))\n",
    "\n",
    "# --- Callbacks (Fixed 'lr' Scope) ---\n",
    "BEST_CKPT = \"\"\n",
    "CSV_PATH = \"\"\n",
    "\n",
    "class MacroValStream(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, val_files, window_size, stride, freq=VAL_FREQ):\n",
    "        super().__init__()\n",
    "        self.val_files = val_files; self.freq = freq\n",
    "        self.best = np.inf; self.wait = 0; self.lr_wait = 0\n",
    "        self.window_size = window_size; self.stride = stride\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        ep = epoch + 1\n",
    "        if ep % self.freq != 0: return\n",
    "        \n",
    "        # ‚≠êÔ∏è FIX: Get LR here so it's available in all branches\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        \n",
    "        per_cell = []\n",
    "        num_gpus = max(1, len(tf.config.list_physical_devices(\"GPU\")))\n",
    "        GLOBAL_BATCH = BATCH_PER_DEVICE * num_gpus\n",
    "        for fn in self.val_files:\n",
    "            ds_cell, steps = stream_windows_from_files(\n",
    "                [fn], self.window_size, self.stride, batch_size=int(GLOBAL_BATCH), seed=SEED\n",
    "            )\n",
    "            loss = float(self.model.evaluate(ds_cell, steps=steps, verbose=0))\n",
    "            per_cell.append(loss)\n",
    "\n",
    "        macro = float(np.mean(per_cell)) if per_cell else np.nan\n",
    "        print(f\"\\n[Val @ epoch {ep}] macro={macro:.6f}  (per-cell: {', '.join(f'{x:.4f}' for x in per_cell)})\")\n",
    "        logs['val_loss_macro'] = macro\n",
    "        \n",
    "        global BEST_CKPT\n",
    "        if BEST_CKPT:\n",
    "            if macro < self.best:\n",
    "                self.best = macro; self.wait = 0; self.lr_wait = 0\n",
    "                self.model.save(BEST_CKPT)\n",
    "                print(f\"  ‚úì Saved BEST checkpoint -> {BEST_CKPT}\")\n",
    "            else:\n",
    "                self.wait += 1; self.lr_wait += 1\n",
    "                if self.lr_wait >= LR_PATIENCE:\n",
    "                    new_lr = max(lr * LR_FACTOR, LR_MIN)\n",
    "                    tf.keras.backend.set_value(self.model.optimizer.learning_rate, new_lr)\n",
    "                    print(f\"  ‚Üí LR reduced: {lr:.6g} -> {new_lr:.6g}\")\n",
    "                    self.lr_wait = 0\n",
    "                if self.wait >= EARLY_STOP_PATIENCE:\n",
    "                    print(\"  ‚Üí Early stopping.\"); self.model.stop_training = True\n",
    "        \n",
    "        if CSV_PATH:\n",
    "            with open(CSV_PATH, \"a\", newline=\"\") as f:\n",
    "                # Handle case where 'loss' might be None in logs\n",
    "                loss_val = logs.get('loss')\n",
    "                loss_str = f\"{loss_val:.6f}\" if loss_val is not None else \"nan\"\n",
    "                csv.writer(f).writerow([ep, loss_str, f\"{macro:.6f}\", f\"{lr:.6g}\"])\n",
    "\n",
    "class LivePlotCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, val_freq=1):\n",
    "        super().__init__()\n",
    "        self.val_freq = val_freq; self.history = {'loss': [], 'val_loss_macro': []}\n",
    "        self.best_val_loss = np.inf; self.best_val_epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.history['loss'].append(logs.get('loss'))\n",
    "        if 'val_loss_macro' in logs:\n",
    "            val_loss = logs.get('val_loss_macro')\n",
    "            self.history['val_loss_macro'].append(val_loss)\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss; self.best_val_epoch = epoch + 1\n",
    "        else: self.history['val_loss_macro'].append(np.nan)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        ax1.plot(range(1, len(self.history['loss'])+1), self.history['loss'], label='Training Loss')\n",
    "        ax1.legend(); ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "        \n",
    "        val_clean = [v if not np.isnan(v) else None for v in self.history['val_loss_macro']]\n",
    "        ax2.plot(range(1, len(self.history['loss'])+1), val_clean, label='Macro Val Loss', marker='o')\n",
    "        if self.best_val_epoch > 0:\n",
    "            ax2.scatter(self.best_val_epoch, self.best_val_loss, s=100, label=f\"Best: {self.best_val_loss:.4f}\")\n",
    "        ax2.legend(); ax2.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "# --- Training Loop ---\n",
    "def train_one_model(run_name, window_size, embed_dim, num_layers, batch_per_device, learning_rate, lambda_phys, do_plot=True):\n",
    "    global BEST_CKPT, CSV_PATH\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.keras.utils.set_random_seed(SEED)\n",
    "\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    strategy = tf.distribute.MirroredStrategy() if len(gpus)>1 else tf.distribute.get_strategy()\n",
    "    GLOBAL_BATCH = batch_per_device * (strategy.num_replicas_in_sync)\n",
    "\n",
    "    build_training_arrays(window_size, STRIDE)\n",
    "    train_ds, t_steps = create_balanced_training_dataset(GLOBAL_BATCH, SEED)\n",
    "    val_ds, v_steps = stream_windows_from_files(VAL_FILES, window_size, STRIDE, batch_size=GLOBAL_BATCH, seed=SEED)\n",
    "\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True); os.makedirs(\"logs\", exist_ok=True)\n",
    "    if run_name == \"main_pitm\":\n",
    "        CSV_PATH = \"logs/train_val.csv\"; BEST_CKPT = \"checkpoints/main_pitm_best_macro.h5\"\n",
    "    else:\n",
    "        CSV_PATH = f\"logs/train_val_{run_name}.csv\"; BEST_CKPT = f\"checkpoints/{run_name}_best.h5\"\n",
    "    if os.path.exists(CSV_PATH): os.remove(CSV_PATH)\n",
    "    with open(CSV_PATH,\"w\") as f: csv.writer(f).writerow([\"epoch\",\"loss\",\"val_loss_macro\",\"lr\"])\n",
    "\n",
    "    cbs = [MacroValStream(VAL_FILES, window_size, STRIDE, VAL_FREQ), tf.keras.callbacks.TerminateOnNaN()]\n",
    "    if do_plot: cbs.insert(1, LivePlotCallback(VAL_FREQ))\n",
    "\n",
    "    with strategy.scope():\n",
    "        model = build_pitm_model(window_size, NUM_GROUPS, embed_dim=embed_dim, num_layers=num_layers, dropout=DROPOUT)\n",
    "        loss = pitm_delta_loss_mp(lambda_phys=lambda_phys)\n",
    "        opt = Adam(learning_rate, amsgrad=AMSGRAD, clipnorm=CLIPNORM)\n",
    "        model.compile(opt, loss=loss)\n",
    "\n",
    "    history = model.fit(train_ds, epochs=EPOCHS, steps_per_epoch=t_steps, callbacks=cbs, verbose=1)\n",
    "    return model, history\n",
    "\n",
    "print(\"‚úÖ Cell 5a complete: Fixed LR variable scope.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1c906c-e423-4ad3-b653-95c60b834092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ======================================\n",
    "# # Cell 5b ‚Äî Main Training Run (uses train_one_model)\n",
    "# # ======================================\n",
    "# import os\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Use hyperparameters from Cell 3\n",
    "# RUN_WINDOW_SIZE = WINDOW_SIZE\n",
    "# RUN_STRIDE      = STRIDE\n",
    "# RUN_EPOCHS      = EPOCHS\n",
    "\n",
    "# # Run the unified training pipeline\n",
    "# run_name = \"main_pitm\"\n",
    "# model, history = train_one_model(\n",
    "#     run_name=run_name,\n",
    "#     window_size=RUN_WINDOW_SIZE,\n",
    "#     embed_dim=EMBED_DIM,\n",
    "#     num_layers=NUM_LAYERS,\n",
    "#     batch_per_device=BATCH_PER_DEVICE,\n",
    "#     learning_rate=LR,\n",
    "#     lambda_phys=LAMBDA_PHYS,\n",
    "#     do_plot=True\n",
    "# )\n",
    "\n",
    "# # Save final weights (optional, as in your original code)\n",
    "# MODEL_WEIGHTS_FINAL = \"checkpoints/main_pitm_final_weights.h5\"\n",
    "# model.save_weights(MODEL_WEIGHTS_FINAL)\n",
    "# print(f\"‚úÖ Saved FINAL run weights ‚Üí {MODEL_WEIGHTS_FINAL}\")\n",
    "# print(f\"Best model was saved to ‚Üí {BEST_CKPT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ef6ff0f9-8a29-4060-90ba-7db1b732bcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cell 6a (Restored Original Plotting) ready.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Cell 6a ‚Äî Testing Setup (Original Style + Group Awareness)\n",
    "# ==========================================================\n",
    "import os, json, joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "# Global constants\n",
    "PRED_BATCH = 1024\n",
    "SCALE_DELTA = 1e5\n",
    "T_MIN=10.0; T_MAX=50.0\n",
    "\n",
    "# --- Helper: Robust Time Channels ---\n",
    "def _make_time_channels_np(Time_s, p95_t_in, p95_dt_in):\n",
    "    t = np.asarray(Time_s, np.float64).flatten()\n",
    "    elapsed = t - t[0]\n",
    "    dt = np.diff(t, prepend=t[0])\n",
    "    t_abs_norm = np.clip(elapsed / max(p95_t_in, 1e-12), 0.0, 4.0)\n",
    "    dt_norm    = np.clip(dt      / max(p95_dt_in, 1e-12), 0.0, 4.0)\n",
    "    return t_abs_norm, dt_norm\n",
    "\n",
    "# --- Helper: Nearest Indices ---\n",
    "def nearest_indices(ts_dense, t_sparse):\n",
    "    ts = np.asarray(ts_dense, np.float64)\n",
    "    te = np.asarray(t_sparse, np.float64)\n",
    "    idx = np.searchsorted(ts, te)\n",
    "    idx = np.clip(idx, 0, len(ts)-1)\n",
    "    left = np.maximum(idx - 1, 0)\n",
    "    take_left = (idx > 0) & (np.abs(ts[left] - te) <= np.abs(ts[idx] - te))\n",
    "    idx[take_left] = left[take_left]\n",
    "    return idx\n",
    "\n",
    "# --- Helper: Positive Deltas ---\n",
    "def _positive_deltas_scaled_np(Q_norm): \n",
    "    Q_norm = np.asarray(Q_norm, np.float64).flatten()\n",
    "    if Q_norm.size < 2: return np.zeros(0, np.float64)\n",
    "    dq_norm = np.maximum(Q_norm[1:] - Q_norm[:-1], 0.0)\n",
    "    dq_scaled = dq_norm * SCALE_DELTA\n",
    "    return dq_scaled.astype(np.float64)\n",
    "\n",
    "# --- Loader (Updated to take per-group time stats) ---\n",
    "def load_numpy_series(file_name, p95_t, p95_dt):\n",
    "    path = os.path.join(DATA_DIR, file_name)\n",
    "    if not os.path.exists(path): return None\n",
    "    \n",
    "    d = {}\n",
    "    with h5py.File(path, 'r') as f:\n",
    "        for k in [\"SOC_p\",\"V_cum_p\",\"Temp_cum_p\",\"C_rate_profile\",\"Time_s_p\",\n",
    "                  \"Q_exp_p\",\"Q_total_p\",\"Bat_cap_profile\",\"R_ch_profile\",\n",
    "                  \"V_max_profile\",\"V_min_profile\",\"Cap_Nom\", \"t_exp\"]:\n",
    "            if k in f: d[k] = np.squeeze(np.array(f[k]))\n",
    "\n",
    "    SOC = np.asarray(d[\"SOC_p\"], np.float64).flatten()\n",
    "    V   = np.asarray(d[\"V_cum_p\"], np.float64).flatten()\n",
    "    T   = np.asarray(d[\"Temp_cum_p\"], np.float64).flatten()\n",
    "    Cr  = np.asarray(d[\"C_rate_profile\"], np.float64).flatten()\n",
    "    t_s = np.asarray(d[\"Time_s_p\"], np.float64).flatten()\n",
    "\n",
    "    Bat = float(d[\"Bat_cap_profile\"].flat[0])\n",
    "    Rch = float(d[\"R_ch_profile\"].flat[0])\n",
    "    Vmx = float(d[\"V_max_profile\"].flat[0])\n",
    "    Vmn = float(d[\"V_min_profile\"].flat[0])\n",
    "    Cap_Nom = float(d[\"Cap_Nom\"].flat[0]) if \"Cap_Nom\" in d else 1.0\n",
    "\n",
    "    Qe_norm = np.asarray(d[\"Q_exp_p\"], np.float64).flatten()\n",
    "    Qp_norm = np.asarray(d[\"Q_total_p\"], np.float64).flatten()\n",
    "\n",
    "    # Use the passed-in Group Stats\n",
    "    t_abs_norm, dt_norm = _make_time_channels_np(t_s, p95_t, p95_dt)\n",
    "    \n",
    "    V_norm = np.clip((V - Vmn) / max(Vmx - Vmn, 1e-6), -1.0, 2.0)\n",
    "    T_norm = np.clip((T - T_MIN) / (T_MAX - T_MIN), -1.0, 2.0)\n",
    "\n",
    "    N = min(SOC.size, V_norm.size, T_norm.size, Cr.size, t_abs_norm.size, dt_norm.size)\n",
    "    \n",
    "    t_exp = d.get(\"t_exp\", np.array([])).flatten()\n",
    "\n",
    "    return {\n",
    "        \"SOC\": SOC[:N], \"V_norm\": V_norm[:N], \"T_norm\": T_norm[:N],\n",
    "        \"Cr\": Cr[:N], \"t_abs_norm\": t_abs_norm[:N], \"dt_norm\": dt_norm[:N],\n",
    "        \"static\": np.array([Bat, Rch, Vmx, Vmn], dtype=np.float32),\n",
    "        \"Cap_Nom\": Cap_Nom,\n",
    "        \"Q_exp_norm\": Qe_norm, \"Q_total_norm\": Qp_norm,\n",
    "        \"dq_exp_scaled\": _positive_deltas_scaled_np(Qe_norm),\n",
    "        \"dq_pb_scaled\":  _positive_deltas_scaled_np(Qp_norm),\n",
    "        \"Time_s_p\": t_s,\n",
    "        \"t_exp\": t_exp,\n",
    "        \"N\": N\n",
    "    }\n",
    "\n",
    "# --- Predict Function (Context-Aware) ---\n",
    "def predict_cell(model, file_name, window_size, stride):\n",
    "    # 1. Get Group Info\n",
    "    if file_name not in FILE_TO_GROUP_MAP: return (np.array([]),)*7\n",
    "    group_name = FILE_TO_GROUP_MAP[file_name]\n",
    "    if group_name not in GROUP_TO_ID_MAP: return (np.array([]),)*7\n",
    "    group_id = GROUP_TO_ID_MAP[group_name]\n",
    "\n",
    "    # 2. Load Group Scalers\n",
    "    try:\n",
    "        delta_scaler_group = joblib.load(os.path.join(\"scalers\", f\"delta_scaler_{group_name}.pkl\"))\n",
    "        feature_scaler_group = joblib.load(os.path.join(\"scalers\", f\"feature_scaler_{group_name}.pkl\"))\n",
    "        with open(os.path.join(\"scalers\", f\"time_stats_{group_name}.json\"), \"r\") as f:\n",
    "            ts = json.load(f)\n",
    "            p95_t = float(ts[\"p95_t\"]); p95_dt = float(ts[\"p95_dt\"])\n",
    "    except: return (np.array([]),)*7\n",
    "\n",
    "    # 3. Load Data\n",
    "    p = load_numpy_series(file_name, p95_t, p95_dt)\n",
    "    if p is None or p[\"N\"] < window_size: return (np.array([]),)*7\n",
    "\n",
    "    # 4. Prepare Features\n",
    "    rows6 = np.stack([p[\"SOC\"], p[\"V_norm\"], p[\"T_norm\"], p[\"t_abs_norm\"], p[\"dt_norm\"], p[\"Cr\"]], axis=1)\n",
    "    rows_scaled = feature_scaler_group.transform(rows6).astype(np.float32)\n",
    "    \n",
    "    win_pos = np.linspace(0, 1, window_size, dtype=np.float32).reshape(-1, 1)\n",
    "    \n",
    "    static_global = joblib.load(os.path.join(\"scalers\", \"static_scaler.pkl\"))\n",
    "    static_vec = p[\"static\"].astype(np.float32).reshape(1, -1)\n",
    "    static_scaled = static_global.transform(static_vec).astype(np.float32)\n",
    "\n",
    "    ends = np.arange(window_size, p[\"N\"] + 1, stride, dtype=np.int64)\n",
    "    num = ends.size\n",
    "    if num == 0: return (np.array([]),)*7\n",
    "\n",
    "    # 5. Construct Batches\n",
    "    dyn_win = np.array([np.concatenate([rows_scaled[e-window_size:e], win_pos], axis=1) for e in ends], dtype=np.float32)\n",
    "    st_win = np.repeat(static_scaled, num, axis=0)\n",
    "    group_id_arr = np.full((num, 1), group_id, dtype=np.int32)\n",
    "\n",
    "    # 6. Predict\n",
    "    y_hat_norm = model.predict((dyn_win, st_win, group_id_arr), batch_size=PRED_BATCH, verbose=0)\n",
    "    \n",
    "    # Inverse Transform\n",
    "    dq_hat_scaled_norm = delta_scaler_group.inverse_transform(y_hat_norm).flatten()\n",
    "    dq_hat_norm = np.maximum(dq_hat_scaled_norm / SCALE_DELTA, 0.0)\n",
    "    q_hat_norm = np.cumsum(dq_hat_norm)\n",
    "\n",
    "    # 7. Get Ground Truth\n",
    "    Time_s = p[\"Time_s_p\"]\n",
    "    t_exp = p[\"t_exp\"]\n",
    "    \n",
    "    # Prepare PBROM benchmark\n",
    "    Q_total_norm = p[\"Q_total_norm\"]\n",
    "    dq_pb_norm = np.maximum(np.diff(Q_total_norm, prepend=Q_total_norm[0]), 0.0)\n",
    "    q_pb_norm = np.cumsum(dq_pb_norm)\n",
    "    \n",
    "    t_dense = Time_s[ends-1]\n",
    "    q_exp_norm_d = p[\"Q_exp_norm\"][ends-1]\n",
    "    q_pb_norm_d = q_pb_norm[ends-1]\n",
    "\n",
    "    # Return original dense Q_exp_norm (not just the subset at ends) so we can do proper matching\n",
    "    return t_dense, p[\"Q_exp_norm\"], q_pb_norm_d, q_hat_norm, p[\"Cap_Nom\"], Time_s, t_exp \n",
    "\n",
    "# --- Evaluator ---\n",
    "def evaluate_model_on_test(model, window_size, stride, plot_suffix=\"\", do_plot=True):\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    results = []\n",
    "\n",
    "    for fn in tqdm(TEST_FILES, desc=\"Evaluating test cells\", ncols=90):\n",
    "        res = predict_cell(model, fn, window_size, stride)\n",
    "        if len(res[0]) == 0: continue\n",
    "            \n",
    "        t_dense, Q_exp_full, q_pb_norm_d, q_hat_norm_d, cap_nom, Time_s_full, t_exp = res\n",
    "\n",
    "        # --- LOGIC FIX: Handling Sparse vs Dense ---\n",
    "        # We need to find where t_exp falls within t_dense\n",
    "        \n",
    "        # 1. Filter t_exp to be within the prediction range\n",
    "        if t_exp.size > 0:\n",
    "            valid_mask = (t_exp >= t_dense[0]) & (t_exp <= t_dense[-1])\n",
    "            t_exp_use = t_exp[valid_mask]\n",
    "        else:\n",
    "            t_exp_use = np.array([])\n",
    "\n",
    "        if t_exp_use.size == 0:\n",
    "            # Fallback: If no sparse points, sample the dense points for metrics\n",
    "            idx_dense_sample = np.linspace(0, len(t_dense)-1, 50, dtype=int)\n",
    "            t_exp_use = t_dense[idx_dense_sample]\n",
    "            # For the \"Experimental Values\", we need to grab the dense Q_exp at these times\n",
    "            # But Q_exp_full corresponds to Time_s_full. We must map t_exp_use -> Time_s_full indices\n",
    "            idx_full = nearest_indices(Time_s_full, t_exp_use)\n",
    "            Q_exp_norm_stamp = Q_exp_full[idx_full]\n",
    "        else:\n",
    "            # Normal case: We have sparse t_exp.\n",
    "            # We need the Experimental Values at these sparse times\n",
    "            # Q_exp_full matches Time_s_full.\n",
    "            idx_full = nearest_indices(Time_s_full, t_exp_use)\n",
    "            Q_exp_norm_stamp = Q_exp_full[idx_full]\n",
    "\n",
    "        # 2. Get Prediction at these specific times\n",
    "        idx_pred = nearest_indices(t_dense, t_exp_use)\n",
    "        Q_pred_norm_stamp = q_hat_norm_d[idx_pred]\n",
    "        \n",
    "        # 3. Metrics\n",
    "        Q_exp_n = Q_exp_norm_stamp.copy()\n",
    "        Q_pred_n = Q_pred_norm_stamp.copy()\n",
    "\n",
    "        mse_pitm_norm = float(np.mean((Q_exp_n - Q_pred_n)**2)) \n",
    "        denom_norm = float(np.sum(Q_exp_n**2))\n",
    "        rsep_pitm = 100.0 * np.sqrt(np.sum((Q_exp_n - Q_pred_n)**2) / denom_norm) if denom_norm > 1e-12 else np.nan\n",
    "        \n",
    "        mask = np.abs(Q_exp_n) > 1e-9 \n",
    "        mape_pitm = 100.0 * np.mean(np.abs((Q_exp_n[mask] - Q_pred_n[mask]) / Q_exp_n[mask])) if np.any(mask) else np.nan\n",
    "        \n",
    "        # (Approximate MSE for PBROM for comparison if needed, assuming q_pb matches prediction steps)\n",
    "        mse_pb_norm = 0.0 # Placeholder\n",
    "        mse_pitm_abs = mse_pitm_norm * (cap_nom**2)\n",
    "        mse_pb_abs = 0.0\n",
    "        \n",
    "        results.append((os.path.basename(fn), mse_pitm_abs, mape_pitm, rsep_pitm, mse_pb_abs, 0.0, 0.0))\n",
    "\n",
    "        # 4. Plotting (Original Style)\n",
    "        if do_plot:\n",
    "            plt.figure(figsize=(6.8, 3.2))\n",
    "            \n",
    "            # Scatter: Experimental (Black Points)\n",
    "            plt.scatter(t_exp_use / 3600.0, 100.0 * Q_exp_norm_stamp, s=18, label=\"Experimental\", zorder=3)\n",
    "            \n",
    "            # Line: PBROM (Blue Line)\n",
    "            plt.plot(t_dense / 3600.0, 100.0 * q_pb_norm_d, lw=1.2, label=\"PB-ROM\", zorder=2)\n",
    "            \n",
    "            # Line: PITM (Red Line)\n",
    "            plt.plot(t_dense / 3600.0, 100.0 * q_hat_norm_d, lw=1.8, label=\"PITM\", zorder=2)\n",
    "            \n",
    "            plt.xlabel(\"Time (h)\"); plt.ylabel(\"Capacity degradation (%)\"); plt.title(os.path.basename(fn))\n",
    "            plt.legend(); plt.grid(alpha=0.3); plt.tight_layout()\n",
    "            \n",
    "            suffix = f\"_{plot_suffix}\" if plot_suffix else \"\"\n",
    "            out_pct = f\"plots/{os.path.basename(fn).replace('.mat', '')}_pred_pct{suffix}.png\"\n",
    "            plt.savefig(out_pct, dpi=300); plt.show(); plt.close()\n",
    "            print(f\"Saved -> {out_pct}\")\n",
    "\n",
    "    print(\"\\nüìä PITM Testing Results (per cell)\")\n",
    "    for name, mse_pitm, mape_pitm, rsep_pitm, mse_pb, mape_pb, rsep_pb in results:\n",
    "        print(f\"  {name:35s}    \"\n",
    "              f\"[PITM] MSE={mse_pitm:.3e} RSEP={rsep_pitm:.2f}% MAPE={mape_pitm:.2f}%     \")   \n",
    "        \n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Cell 6a (Restored Original Plotting) ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca226fad-5b93-4d7b-ada6-cae83cb71e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ======================================\n",
    "# # Cell 6b ‚Äî Test the Best Model\n",
    "# # ======================================\n",
    "\n",
    "# # --- Load the BEST checkpoint from training ---\n",
    "# MODEL_TO_TEST = os.path.join(\"checkpoints\", \"main_pitm_best_macro.h5\")\n",
    "\n",
    "# if not os.path.exists(MODEL_TO_TEST):\n",
    "#     print(f\"‚ö†Ô∏è Warning: Best checkpoint not found at {MODEL_TO_TEST}.\")\n",
    "#     print(\"Falling back to final weights. Re-run 5b if this is wrong.\")\n",
    "#     MODEL_TO_TEST = \"checkpoints/main_pitm_final_weights.h5\"\n",
    "#     if not os.path.exists(MODEL_TO_TEST):\n",
    "#         raise FileNotFoundError(\"No model weights found to test.\")\n",
    "\n",
    "# # --- Use the same hyperparams as training ---\n",
    "# RUN_WINDOW_SIZE = WINDOW_SIZE\n",
    "# RUN_STRIDE = STRIDE\n",
    "\n",
    "# # --- Rebuild the EXACT same architecture (v4) ---\n",
    "# print(\"Rebuilding v4 model architecture...\")\n",
    "# model = build_pitm_model(\n",
    "#     window_size=RUN_WINDOW_SIZE,\n",
    "#     num_groups=NUM_GROUPS,  # <-- From Cell 1\n",
    "#     embed_dim=EMBED_DIM,\n",
    "#     num_heads=NUM_HEADS,\n",
    "#     ff_dim=FF_DIM,\n",
    "#     num_layers=NUM_LAYERS,\n",
    "#     dropout=DROPOUT # Note: dropout is inactive during inference\n",
    "# )\n",
    "\n",
    "# # Load the trained weights\n",
    "# model.load_weights(MODEL_TO_TEST)\n",
    "# print(f\"‚úÖ Loaded BEST run weights from {MODEL_TO_TEST}\")\n",
    "\n",
    "# # --- Run evaluation using the new (Cell 6a) pipeline ---\n",
    "# _ = evaluate_model_on_test(\n",
    "#     model, \n",
    "#     window_size=RUN_WINDOW_SIZE, \n",
    "#     stride=RUN_STRIDE, \n",
    "#     plot_suffix=\"best_model\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a3ebb0-844f-4d19-9649-538aaacad6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d719dbc-f30b-4d76-ad9e-634986ebaa5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12786ed9-41ad-44b4-a01b-96c25e89f412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage 2 Random Search defined: 20 total runs.\n",
      "   window_size candidates:   [100, 50, 10, 30, 80, 40, 60]\n",
      "   batch_size candidates:    [768, 1024]\n",
      "   num_layers candidates:    [3, 4, 5]\n",
      "   embed_dim candidates:     [32, 64, 96, 128]\n",
      "   lambda_phys range:        [0.0, 1.1]\n",
      "   learning_rate log-range:  [1.0e-08, 3.0e-04]\n",
      "   Using the unified training pipeline (train_one_model).\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# Cell 10a ‚Äî Random Search (Stage 2) Definitions\n",
    "# (tuned around the current best config)\n",
    "# ===============================================\n",
    "import numpy as np\n",
    "\n",
    "# --- Number of random runs ---\n",
    "# Increase this (e.g. 10‚Äì20) once you're happy with the space\n",
    "N_RANDOM_RUNS = 20  # or 10+ for a more thorough search\n",
    "\n",
    "RANDOM_SEARCH_SPACE_STAGE2 = {\n",
    "    # Discrete choices (random.choice)\n",
    "    \"window_size\":  [100, 50, 10, 30, 80, 40, 60],       # around 70\n",
    "    \"batch_size\":   [768, 1024],        # around 512 (watch GPU memory)\n",
    "    \"num_layers\":   [3, 4, 5],              # shallow to moderately deep\n",
    "    \"embed_dim\":    [32, 64, 96, 128],           # around 64s\n",
    "\n",
    "    # Continuous ranges (random.uniform / log-uniform)\n",
    "    \"lambda_phys\":  [0.0, 1.1],             # narrow band around ~0.67\n",
    "    \"learning_rate\": [1e-8, 3e-4],          # around 8e-7, still some room\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Stage 2 Random Search defined: {N_RANDOM_RUNS} total runs.\")\n",
    "print(f\"   window_size candidates:   {RANDOM_SEARCH_SPACE_STAGE2['window_size']}\")\n",
    "print(f\"   batch_size candidates:    {RANDOM_SEARCH_SPACE_STAGE2['batch_size']}\")\n",
    "print(f\"   num_layers candidates:    {RANDOM_SEARCH_SPACE_STAGE2['num_layers']}\")\n",
    "print(f\"   embed_dim candidates:     {RANDOM_SEARCH_SPACE_STAGE2['embed_dim']}\")\n",
    "print(f\"   lambda_phys range:        {RANDOM_SEARCH_SPACE_STAGE2['lambda_phys']}\")\n",
    "print(f\"   learning_rate log-range:  [{RANDOM_SEARCH_SPACE_STAGE2['learning_rate'][0]:.1e}, \"\n",
    "      f\"{RANDOM_SEARCH_SPACE_STAGE2['learning_rate'][1]:.1e}]\")\n",
    "print(f\"   Using the unified training pipeline (train_one_model).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d03b9a-6b09-4e72-93e5-4760c984b31f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 1 / 20\n",
      "  window_size   = 40\n",
      "  lambda_phys   = 0.2694\n",
      "  batch_size    = 768\n",
      "  learning_rate = 4.21e-08\n",
      "  num_layers    = 3\n",
      "  embed_dim     = 96\n",
      "==================================================\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\n",
      "--- Counting windows for balancing ---\n",
      "  Group 'PBROM_Cells_1': 150824 windows\n",
      "  Group 'D5_Cells_1': 1199961 windows\n",
      "  -> Weight for 'PBROM_Cells_1': 4.4780\n",
      "  -> Weight for 'D5_Cells_1': 0.5628\n",
      "\n",
      "--- Processing Groups ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PBROM_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.84s/it]\n",
      "  D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:18<00:00, 18.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "‚úÖ Done. 1350783 windows generated. Weights applied.\n",
      "Epoch 1/50\n",
      "1759/1759 [==============================] - 59s 22ms/step - loss: 0.4138\n",
      "Epoch 2/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4099\n",
      "[Val @ epoch 2] macro=0.428562  (per-cell: 0.4502, 0.4069)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 71s 40ms/step - loss: 0.4099 - val_loss_macro: 0.4286\n",
      "Epoch 3/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4072\n",
      "Epoch 4/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4054\n",
      "[Val @ epoch 4] macro=0.406788  (per-cell: 0.4069, 0.4067)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 72s 41ms/step - loss: 0.4054 - val_loss_macro: 0.4068\n",
      "Epoch 5/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4040\n",
      "Epoch 6/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4029\n",
      "[Val @ epoch 6] macro=0.398456  (per-cell: 0.3906, 0.4063)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4029 - val_loss_macro: 0.3985\n",
      "Epoch 7/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4021\n",
      "Epoch 8/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4014\n",
      "[Val @ epoch 8] macro=0.394585  (per-cell: 0.3834, 0.4058)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4014 - val_loss_macro: 0.3946\n",
      "Epoch 9/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4008\n",
      "Epoch 10/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4003\n",
      "[Val @ epoch 10] macro=0.392725  (per-cell: 0.3802, 0.4052)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4003 - val_loss_macro: 0.3927\n",
      "Epoch 11/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3998\n",
      "Epoch 12/50\n",
      "1758/1759 [============================>.] - ETA: 0s - loss: 0.3993\n",
      "[Val @ epoch 12] macro=0.391647  (per-cell: 0.3787, 0.4046)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3993 - val_loss_macro: 0.3916\n",
      "Epoch 13/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3989\n",
      "Epoch 14/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3985\n",
      "[Val @ epoch 14] macro=0.390907  (per-cell: 0.3779, 0.4039)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3985 - val_loss_macro: 0.3909\n",
      "Epoch 15/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3981\n",
      "Epoch 16/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3977\n",
      "[Val @ epoch 16] macro=0.390309  (per-cell: 0.3775, 0.4032)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3977 - val_loss_macro: 0.3903\n",
      "Epoch 17/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3973\n",
      "Epoch 18/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3970\n",
      "[Val @ epoch 18] macro=0.389762  (per-cell: 0.3771, 0.4024)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 70s 40ms/step - loss: 0.3970 - val_loss_macro: 0.3898\n",
      "Epoch 19/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3966\n",
      "Epoch 20/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3962\n",
      "[Val @ epoch 20] macro=0.389215  (per-cell: 0.3769, 0.4016)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3962 - val_loss_macro: 0.3892\n",
      "Epoch 21/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3959\n",
      "Epoch 22/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3954\n",
      "[Val @ epoch 22] macro=0.388640  (per-cell: 0.3766, 0.4007)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3954 - val_loss_macro: 0.3886\n",
      "Epoch 23/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3951\n",
      "Epoch 24/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3946\n",
      "[Val @ epoch 24] macro=0.388019  (per-cell: 0.3764, 0.3997)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3946 - val_loss_macro: 0.3880\n",
      "Epoch 25/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3942\n",
      "Epoch 26/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3939\n",
      "[Val @ epoch 26] macro=0.387325  (per-cell: 0.3761, 0.3985)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3939 - val_loss_macro: 0.3873\n",
      "Epoch 27/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3934\n",
      "Epoch 28/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3929\n",
      "[Val @ epoch 28] macro=0.386537  (per-cell: 0.3759, 0.3972)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3929 - val_loss_macro: 0.3865\n",
      "Epoch 29/50\n",
      "1759/1759 [==============================] - 41s 23ms/step - loss: 0.3925\n",
      "Epoch 30/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3921\n",
      "[Val @ epoch 30] macro=0.385647  (per-cell: 0.3756, 0.3957)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3921 - val_loss_macro: 0.3856\n",
      "Epoch 31/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3915\n",
      "Epoch 32/50\n",
      "1758/1759 [============================>.] - ETA: 0s - loss: 0.3910\n",
      "[Val @ epoch 32] macro=0.384621  (per-cell: 0.3753, 0.3940)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 70s 40ms/step - loss: 0.3910 - val_loss_macro: 0.3846\n",
      "Epoch 33/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3905\n",
      "Epoch 34/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3899\n",
      "[Val @ epoch 34] macro=0.383459  (per-cell: 0.3750, 0.3920)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 40ms/step - loss: 0.3899 - val_loss_macro: 0.3835\n",
      "Epoch 35/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3894\n",
      "Epoch 36/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3887\n",
      "[Val @ epoch 36] macro=0.382177  (per-cell: 0.3746, 0.3897)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3887 - val_loss_macro: 0.3822\n",
      "Epoch 37/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3881\n",
      "Epoch 38/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3874\n",
      "[Val @ epoch 38] macro=0.380775  (per-cell: 0.3743, 0.3872)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 70s 40ms/step - loss: 0.3874 - val_loss_macro: 0.3808\n",
      "Epoch 39/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3868\n",
      "Epoch 40/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3861\n",
      "[Val @ epoch 40] macro=0.379334  (per-cell: 0.3740, 0.3847)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3861 - val_loss_macro: 0.3793\n",
      "Epoch 41/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3854\n",
      "Epoch 42/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3846\n",
      "[Val @ epoch 42] macro=0.377966  (per-cell: 0.3737, 0.3822)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 70s 40ms/step - loss: 0.3846 - val_loss_macro: 0.3780\n",
      "Epoch 43/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3840\n",
      "Epoch 44/50\n",
      "1758/1759 [============================>.] - ETA: 0s - loss: 0.3833\n",
      "[Val @ epoch 44] macro=0.376879  (per-cell: 0.3734, 0.3804)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3833 - val_loss_macro: 0.3769\n",
      "Epoch 45/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3826\n",
      "Epoch 46/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3819\n",
      "[Val @ epoch 46] macro=0.376175  (per-cell: 0.3731, 0.3792)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3819 - val_loss_macro: 0.3762\n",
      "Epoch 47/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3812\n",
      "Epoch 48/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3805\n",
      "[Val @ epoch 48] macro=0.375821  (per-cell: 0.3728, 0.3788)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3805 - val_loss_macro: 0.3758\n",
      "Epoch 49/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3798\n",
      "Epoch 50/50\n",
      "1758/1759 [============================>.] - ETA: 0s - loss: 0.3795\n",
      "[Val @ epoch 50] macro=0.375623  (per-cell: 0.3726, 0.3787)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run1_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3795 - val_loss_macro: 0.3756\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run1_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:14<00:00,  7.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_28.mat                 [PITM] MSE=1.143e-07 RSEP=30.29% MAPE=36.46%     \n",
      "  PBROM_data_cell_D5C78.mat              [PITM] MSE=1.186e-03 RSEP=45.75% MAPE=53.44%     \n",
      "[RandomSearch] Run 1 ‚Üí avg_rsep_pitm=38.0238\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 2 / 20\n",
      "  window_size   = 100\n",
      "  lambda_phys   = 1.0553\n",
      "  batch_size    = 1024\n",
      "  learning_rate = 4.53e-07\n",
      "  num_layers    = 5\n",
      "  embed_dim     = 64\n",
      "==================================================\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\n",
      "--- Counting windows for balancing ---\n",
      "  Group 'PBROM_Cells_1': 150764 windows\n",
      "  Group 'D5_Cells_1': 1199901 windows\n",
      "  -> Weight for 'PBROM_Cells_1': 4.4794\n",
      "  -> Weight for 'D5_Cells_1': 0.5628\n",
      "\n",
      "--- Processing Groups ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PBROM_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.87s/it]\n",
      "  D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:19<00:00, 19.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "‚úÖ Done. 1350663 windows generated. Weights applied.\n",
      "Epoch 1/50\n",
      "1320/1320 [==============================] - 116s 65ms/step - loss: 0.5550\n",
      "Epoch 2/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.5468\n",
      "[Val @ epoch 2] macro=0.561940  (per-cell: 0.5598, 0.5641)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 133s 101ms/step - loss: 0.5468 - val_loss_macro: 0.5619\n",
      "Epoch 3/50\n",
      "1320/1320 [==============================] - 88s 67ms/step - loss: 0.5440\n",
      "Epoch 4/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.5414\n",
      "[Val @ epoch 4] macro=0.556994  (per-cell: 0.5559, 0.5581)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 134s 102ms/step - loss: 0.5414 - val_loss_macro: 0.5570\n",
      "Epoch 5/50\n",
      "1320/1320 [==============================] - 88s 67ms/step - loss: 0.5386\n",
      "Epoch 6/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.5357\n",
      "[Val @ epoch 6] macro=0.550306  (per-cell: 0.5502, 0.5504)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 130s 99ms/step - loss: 0.5357 - val_loss_macro: 0.5503\n",
      "Epoch 7/50\n",
      "1320/1320 [==============================] - 88s 67ms/step - loss: 0.5324\n",
      "Epoch 8/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.5287\n",
      "[Val @ epoch 8] macro=0.541366  (per-cell: 0.5449, 0.5379)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 130s 99ms/step - loss: 0.5287 - val_loss_macro: 0.5414\n",
      "Epoch 9/50\n",
      "1320/1320 [==============================] - 90s 68ms/step - loss: 0.5237\n",
      "Epoch 10/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.5183\n",
      "[Val @ epoch 10] macro=0.531973  (per-cell: 0.5406, 0.5233)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 132s 100ms/step - loss: 0.5183 - val_loss_macro: 0.5320\n",
      "Epoch 11/50\n",
      "1320/1320 [==============================] - 89s 68ms/step - loss: 0.5125\n",
      "Epoch 12/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.5075\n",
      "[Val @ epoch 12] macro=0.528665  (per-cell: 0.5370, 0.5203)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 133s 101ms/step - loss: 0.5075 - val_loss_macro: 0.5287\n",
      "Epoch 13/50\n",
      "1320/1320 [==============================] - 90s 68ms/step - loss: 0.5032\n",
      "Epoch 14/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4999\n",
      "[Val @ epoch 14] macro=0.526816  (per-cell: 0.5338, 0.5198)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 133s 101ms/step - loss: 0.4999 - val_loss_macro: 0.5268\n",
      "Epoch 15/50\n",
      "1320/1320 [==============================] - 90s 68ms/step - loss: 0.4970\n",
      "Epoch 16/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4943\n",
      "[Val @ epoch 16] macro=0.524447  (per-cell: 0.5307, 0.5181)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 133s 101ms/step - loss: 0.4943 - val_loss_macro: 0.5244\n",
      "Epoch 17/50\n",
      "1320/1320 [==============================] - 92s 70ms/step - loss: 0.4921\n",
      "Epoch 18/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4897\n",
      "[Val @ epoch 18] macro=0.521403  (per-cell: 0.5276, 0.5152)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 136s 103ms/step - loss: 0.4897 - val_loss_macro: 0.5214\n",
      "Epoch 19/50\n",
      "1320/1320 [==============================] - 91s 69ms/step - loss: 0.4879\n",
      "Epoch 20/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4857\n",
      "[Val @ epoch 20] macro=0.518063  (per-cell: 0.5244, 0.5117)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 135s 102ms/step - loss: 0.4857 - val_loss_macro: 0.5181\n",
      "Epoch 21/50\n",
      "1320/1320 [==============================] - 93s 70ms/step - loss: 0.4839\n",
      "Epoch 22/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4820\n",
      "[Val @ epoch 22] macro=0.514896  (per-cell: 0.5212, 0.5086)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 134s 101ms/step - loss: 0.4820 - val_loss_macro: 0.5149\n",
      "Epoch 23/50\n",
      "1320/1320 [==============================] - 91s 69ms/step - loss: 0.4801\n",
      "Epoch 24/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4784\n",
      "[Val @ epoch 24] macro=0.511476  (per-cell: 0.5180, 0.5050)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 134s 102ms/step - loss: 0.4784 - val_loss_macro: 0.5115\n",
      "Epoch 25/50\n",
      "1320/1320 [==============================] - 89s 67ms/step - loss: 0.4766\n",
      "Epoch 26/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4749\n",
      "[Val @ epoch 26] macro=0.508126  (per-cell: 0.5147, 0.5016)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 131s 99ms/step - loss: 0.4749 - val_loss_macro: 0.5081\n",
      "Epoch 27/50\n",
      "1320/1320 [==============================] - 88s 67ms/step - loss: 0.4732\n",
      "Epoch 28/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4716\n",
      "[Val @ epoch 28] macro=0.504798  (per-cell: 0.5114, 0.4982)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 131s 99ms/step - loss: 0.4716 - val_loss_macro: 0.5048\n",
      "Epoch 29/50\n",
      "1320/1320 [==============================] - 88s 66ms/step - loss: 0.4699\n",
      "Epoch 30/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4683\n",
      "[Val @ epoch 30] macro=0.501354  (per-cell: 0.5079, 0.4948)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 130s 99ms/step - loss: 0.4683 - val_loss_macro: 0.5014\n",
      "Epoch 31/50\n",
      "1320/1320 [==============================] - 87s 66ms/step - loss: 0.4669\n",
      "Epoch 32/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4651\n",
      "[Val @ epoch 32] macro=0.497899  (per-cell: 0.5045, 0.4913)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 130s 99ms/step - loss: 0.4651 - val_loss_macro: 0.4979\n",
      "Epoch 33/50\n",
      "1320/1320 [==============================] - 88s 66ms/step - loss: 0.4636\n",
      "Epoch 34/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4623\n",
      "[Val @ epoch 34] macro=0.494402  (per-cell: 0.5008, 0.4880)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 131s 99ms/step - loss: 0.4623 - val_loss_macro: 0.4944\n",
      "Epoch 35/50\n",
      "1320/1320 [==============================] - 87s 66ms/step - loss: 0.4605\n",
      "Epoch 36/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4591\n",
      "[Val @ epoch 36] macro=0.490858  (per-cell: 0.4970, 0.4847)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 130s 99ms/step - loss: 0.4591 - val_loss_macro: 0.4909\n",
      "Epoch 37/50\n",
      "1320/1320 [==============================] - 88s 66ms/step - loss: 0.4577\n",
      "Epoch 38/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4564\n",
      "[Val @ epoch 38] macro=0.487465  (per-cell: 0.4930, 0.4819)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 131s 99ms/step - loss: 0.4564 - val_loss_macro: 0.4875\n",
      "Epoch 39/50\n",
      "1320/1320 [==============================] - 88s 67ms/step - loss: 0.4549\n",
      "Epoch 40/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4533\n",
      "[Val @ epoch 40] macro=0.483899  (per-cell: 0.4892, 0.4786)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 130s 99ms/step - loss: 0.4533 - val_loss_macro: 0.4839\n",
      "Epoch 41/50\n",
      "1320/1320 [==============================] - 88s 67ms/step - loss: 0.4518\n",
      "Epoch 42/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4506\n",
      "[Val @ epoch 42] macro=0.480646  (per-cell: 0.4853, 0.4760)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 130s 99ms/step - loss: 0.4506 - val_loss_macro: 0.4806\n",
      "Epoch 43/50\n",
      "1320/1320 [==============================] - 87s 66ms/step - loss: 0.4491\n",
      "Epoch 44/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4478\n",
      "[Val @ epoch 44] macro=0.477293  (per-cell: 0.4815, 0.4731)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 130s 99ms/step - loss: 0.4478 - val_loss_macro: 0.4773\n",
      "Epoch 45/50\n",
      "1320/1320 [==============================] - 87s 66ms/step - loss: 0.4464\n",
      "Epoch 46/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4449\n",
      "[Val @ epoch 46] macro=0.474200  (per-cell: 0.4781, 0.4703)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 130s 98ms/step - loss: 0.4449 - val_loss_macro: 0.4742\n",
      "Epoch 47/50\n",
      "1320/1320 [==============================] - 87s 66ms/step - loss: 0.4437\n",
      "Epoch 48/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4423\n",
      "[Val @ epoch 48] macro=0.471192  (per-cell: 0.4747, 0.4677)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 130s 99ms/step - loss: 0.4423 - val_loss_macro: 0.4712\n",
      "Epoch 49/50\n",
      "1320/1320 [==============================] - 87s 66ms/step - loss: 0.4408\n",
      "Epoch 50/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4395\n",
      "[Val @ epoch 50] macro=0.467904  (per-cell: 0.4711, 0.4648)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run2_best.h5\n",
      "1320/1320 [==============================] - 130s 98ms/step - loss: 0.4395 - val_loss_macro: 0.4679\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run2_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:31<00:00, 15.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_28.mat                 [PITM] MSE=1.542e-08 RSEP=11.13% MAPE=20.16%     \n",
      "  PBROM_data_cell_D5C78.mat              [PITM] MSE=5.622e-04 RSEP=31.50% MAPE=39.47%     \n",
      "[RandomSearch] Run 2 ‚Üí avg_rsep_pitm=21.3136\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 3 / 20\n",
      "  window_size   = 30\n",
      "  lambda_phys   = 0.2477\n",
      "  batch_size    = 768\n",
      "  learning_rate = 1.35e-08\n",
      "  num_layers    = 3\n",
      "  embed_dim     = 128\n",
      "==================================================\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\n",
      "--- Counting windows for balancing ---\n",
      "  Group 'PBROM_Cells_1': 150834 windows\n",
      "  Group 'D5_Cells_1': 1199971 windows\n",
      "  -> Weight for 'PBROM_Cells_1': 4.4778\n",
      "  -> Weight for 'D5_Cells_1': 0.5628\n",
      "\n",
      "--- Processing Groups ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PBROM_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.72s/it]\n",
      "  D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:18<00:00, 18.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "‚úÖ Done. 1350803 windows generated. Weights applied.\n",
      "Epoch 1/50\n",
      "1759/1759 [==============================] - 60s 22ms/step - loss: 0.4354\n",
      "Epoch 2/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4338\n",
      "[Val @ epoch 2] macro=0.457023  (per-cell: 0.4843, 0.4297)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 70s 40ms/step - loss: 0.4338 - val_loss_macro: 0.4570\n",
      "Epoch 3/50\n",
      "1759/1759 [==============================] - 40s 22ms/step - loss: 0.4326\n",
      "Epoch 4/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4315\n",
      "[Val @ epoch 4] macro=0.446103  (per-cell: 0.4628, 0.4294)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 71s 40ms/step - loss: 0.4315 - val_loss_macro: 0.4461\n",
      "Epoch 5/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4306\n",
      "Epoch 6/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4297\n",
      "[Val @ epoch 6] macro=0.441048  (per-cell: 0.4531, 0.4290)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4297 - val_loss_macro: 0.4410\n",
      "Epoch 7/50\n",
      "1759/1759 [==============================] - 40s 22ms/step - loss: 0.4290\n",
      "Epoch 8/50\n",
      "1757/1759 [============================>.] - ETA: 0s - loss: 0.4284\n",
      "[Val @ epoch 8] macro=0.436935  (per-cell: 0.4453, 0.4285)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4284 - val_loss_macro: 0.4369\n",
      "Epoch 9/50\n",
      "1759/1759 [==============================] - 40s 22ms/step - loss: 0.4278\n",
      "Epoch 10/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4273\n",
      "[Val @ epoch 10] macro=0.432120  (per-cell: 0.4363, 0.4280)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 68s 39ms/step - loss: 0.4273 - val_loss_macro: 0.4321\n",
      "Epoch 11/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4268\n",
      "Epoch 12/50\n",
      "1758/1759 [============================>.] - ETA: 0s - loss: 0.4264\n",
      "[Val @ epoch 12] macro=0.428486  (per-cell: 0.4296, 0.4274)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4264 - val_loss_macro: 0.4285\n",
      "Epoch 13/50\n",
      "1759/1759 [==============================] - 40s 22ms/step - loss: 0.4260\n",
      "Epoch 14/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4256\n",
      "[Val @ epoch 14] macro=0.425697  (per-cell: 0.4247, 0.4267)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4256 - val_loss_macro: 0.4257\n",
      "Epoch 15/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4251\n",
      "Epoch 16/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4248\n",
      "[Val @ epoch 16] macro=0.423399  (per-cell: 0.4208, 0.4260)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4248 - val_loss_macro: 0.4234\n",
      "Epoch 17/50\n",
      "1759/1759 [==============================] - 40s 22ms/step - loss: 0.4244\n",
      "Epoch 18/50\n",
      "1758/1759 [============================>.] - ETA: 0s - loss: 0.4241\n",
      "[Val @ epoch 18] macro=0.421459  (per-cell: 0.4177, 0.4252)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4241 - val_loss_macro: 0.4215\n",
      "Epoch 19/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4237\n",
      "Epoch 20/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4234\n",
      "[Val @ epoch 20] macro=0.419778  (per-cell: 0.4151, 0.4244)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4234 - val_loss_macro: 0.4198\n",
      "Epoch 21/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4231\n",
      "Epoch 22/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4228\n",
      "[Val @ epoch 22] macro=0.418307  (per-cell: 0.4131, 0.4236)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 68s 39ms/step - loss: 0.4228 - val_loss_macro: 0.4183\n",
      "Epoch 23/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4225\n",
      "Epoch 24/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4222\n",
      "[Val @ epoch 24] macro=0.417014  (per-cell: 0.4114, 0.4227)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 68s 39ms/step - loss: 0.4222 - val_loss_macro: 0.4170\n",
      "Epoch 25/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4220\n",
      "Epoch 26/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4216\n",
      "[Val @ epoch 26] macro=0.415873  (per-cell: 0.4100, 0.4217)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4216 - val_loss_macro: 0.4159\n",
      "Epoch 27/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4214\n",
      "Epoch 28/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4210\n",
      "[Val @ epoch 28] macro=0.414842  (per-cell: 0.4089, 0.4208)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 68s 39ms/step - loss: 0.4210 - val_loss_macro: 0.4148\n",
      "Epoch 29/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4208\n",
      "Epoch 30/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4205\n",
      "[Val @ epoch 30] macro=0.413890  (per-cell: 0.4080, 0.4198)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4205 - val_loss_macro: 0.4139\n",
      "Epoch 31/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4202\n",
      "Epoch 32/50\n",
      "1758/1759 [============================>.] - ETA: 0s - loss: 0.4199\n",
      "[Val @ epoch 32] macro=0.412977  (per-cell: 0.4072, 0.4188)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4199 - val_loss_macro: 0.4130\n",
      "Epoch 33/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4197\n",
      "Epoch 34/50\n",
      "1758/1759 [============================>.] - ETA: 0s - loss: 0.4193\n",
      "[Val @ epoch 34] macro=0.412132  (per-cell: 0.4065, 0.4178)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4193 - val_loss_macro: 0.4121\n",
      "Epoch 35/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4191\n",
      "Epoch 36/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4188\n",
      "[Val @ epoch 36] macro=0.411323  (per-cell: 0.4059, 0.4168)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 68s 39ms/step - loss: 0.4188 - val_loss_macro: 0.4113\n",
      "Epoch 37/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4185\n",
      "Epoch 38/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4182\n",
      "[Val @ epoch 38] macro=0.410584  (per-cell: 0.4053, 0.4158)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 68s 39ms/step - loss: 0.4182 - val_loss_macro: 0.4106\n",
      "Epoch 39/50\n",
      "1759/1759 [==============================] - 40s 22ms/step - loss: 0.4179\n",
      "Epoch 40/50\n",
      "1758/1759 [============================>.] - ETA: 0s - loss: 0.4177\n",
      "[Val @ epoch 40] macro=0.409904  (per-cell: 0.4048, 0.4150)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4177 - val_loss_macro: 0.4099\n",
      "Epoch 41/50\n",
      "1759/1759 [==============================] - 40s 22ms/step - loss: 0.4173\n",
      "Epoch 42/50\n",
      "1758/1759 [============================>.] - ETA: 0s - loss: 0.4171\n",
      "[Val @ epoch 42] macro=0.409263  (per-cell: 0.4044, 0.4141)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4171 - val_loss_macro: 0.4093\n",
      "Epoch 43/50\n",
      "1759/1759 [==============================] - 40s 22ms/step - loss: 0.4168\n",
      "Epoch 44/50\n",
      "1757/1759 [============================>.] - ETA: 0s - loss: 0.4165\n",
      "[Val @ epoch 44] macro=0.408674  (per-cell: 0.4040, 0.4133)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 68s 39ms/step - loss: 0.4165 - val_loss_macro: 0.4087\n",
      "Epoch 45/50\n",
      "1759/1759 [==============================] - 40s 22ms/step - loss: 0.4162\n",
      "Epoch 46/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4160\n",
      "[Val @ epoch 46] macro=0.408122  (per-cell: 0.4037, 0.4126)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4160 - val_loss_macro: 0.4081\n",
      "Epoch 47/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4156\n",
      "Epoch 48/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4154\n",
      "[Val @ epoch 48] macro=0.407611  (per-cell: 0.4033, 0.4119)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 68s 39ms/step - loss: 0.4154 - val_loss_macro: 0.4076\n",
      "Epoch 49/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4152\n",
      "Epoch 50/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4149\n",
      "[Val @ epoch 50] macro=0.407146  (per-cell: 0.4030, 0.4113)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run3_best.h5\n",
      "1759/1759 [==============================] - 68s 39ms/step - loss: 0.4149 - val_loss_macro: 0.4071\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run3_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:13<00:00,  6.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_28.mat                 [PITM] MSE=4.534e-08 RSEP=19.08% MAPE=26.06%     \n",
      "  PBROM_data_cell_D5C78.mat              [PITM] MSE=1.002e-03 RSEP=42.05% MAPE=50.45%     \n",
      "[RandomSearch] Run 3 ‚Üí avg_rsep_pitm=30.5668\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 4 / 20\n",
      "  window_size   = 10\n",
      "  lambda_phys   = 0.0901\n",
      "  batch_size    = 1024\n",
      "  learning_rate = 3.29e-07\n",
      "  num_layers    = 4\n",
      "  embed_dim     = 96\n",
      "==================================================\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\n",
      "--- Counting windows for balancing ---\n",
      "  Group 'PBROM_Cells_1': 150854 windows\n",
      "  Group 'D5_Cells_1': 1199991 windows\n",
      "  -> Weight for 'PBROM_Cells_1': 4.4773\n",
      "  -> Weight for 'D5_Cells_1': 0.5629\n",
      "\n",
      "--- Processing Groups ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PBROM_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.50s/it]\n",
      "  D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:18<00:00, 18.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "‚úÖ Done. 1350843 windows generated. Weights applied.\n",
      "Epoch 1/50\n",
      "1320/1320 [==============================] - 51s 20ms/step - loss: 0.4800\n",
      "Epoch 2/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4627\n",
      "[Val @ epoch 2] macro=0.451237  (per-cell: 0.4435, 0.4590)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 56s 42ms/step - loss: 0.4627 - val_loss_macro: 0.4512\n",
      "Epoch 3/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.4586\n",
      "Epoch 4/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4563\n",
      "[Val @ epoch 4] macro=0.446609  (per-cell: 0.4368, 0.4564)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 57s 43ms/step - loss: 0.4563 - val_loss_macro: 0.4466\n",
      "Epoch 5/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.4543\n",
      "Epoch 6/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4523\n",
      "[Val @ epoch 6] macro=0.442436  (per-cell: 0.4340, 0.4508)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 53s 41ms/step - loss: 0.4523 - val_loss_macro: 0.4424\n",
      "Epoch 7/50\n",
      "1320/1320 [==============================] - 29s 22ms/step - loss: 0.4501\n",
      "Epoch 8/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4477\n",
      "[Val @ epoch 8] macro=0.436749  (per-cell: 0.4312, 0.4423)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.4477 - val_loss_macro: 0.4367\n",
      "Epoch 9/50\n",
      "1320/1320 [==============================] - 29s 22ms/step - loss: 0.4451\n",
      "Epoch 10/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4423\n",
      "[Val @ epoch 10] macro=0.432618  (per-cell: 0.4279, 0.4373)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.4423 - val_loss_macro: 0.4326\n",
      "Epoch 11/50\n",
      "1320/1320 [==============================] - 29s 22ms/step - loss: 0.4397\n",
      "Epoch 12/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4373\n",
      "[Val @ epoch 12] macro=0.429508  (per-cell: 0.4245, 0.4345)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.4373 - val_loss_macro: 0.4295\n",
      "Epoch 13/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.4348\n",
      "Epoch 14/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4328\n",
      "[Val @ epoch 14] macro=0.427298  (per-cell: 0.4215, 0.4331)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.4328 - val_loss_macro: 0.4273\n",
      "Epoch 15/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.4309\n",
      "Epoch 16/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4293\n",
      "[Val @ epoch 16] macro=0.425245  (per-cell: 0.4186, 0.4318)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 53s 41ms/step - loss: 0.4293 - val_loss_macro: 0.4252\n",
      "Epoch 17/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.4276\n",
      "Epoch 18/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4260\n",
      "[Val @ epoch 18] macro=0.423071  (per-cell: 0.4158, 0.4303)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.4260 - val_loss_macro: 0.4231\n",
      "Epoch 19/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.4246\n",
      "Epoch 20/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4233\n",
      "[Val @ epoch 20] macro=0.420721  (per-cell: 0.4129, 0.4286)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.4233 - val_loss_macro: 0.4207\n",
      "Epoch 21/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.4219\n",
      "Epoch 22/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4206\n",
      "[Val @ epoch 22] macro=0.418118  (per-cell: 0.4098, 0.4265)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.4206 - val_loss_macro: 0.4181\n",
      "Epoch 23/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.4196\n",
      "Epoch 24/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4184\n",
      "[Val @ epoch 24] macro=0.415575  (per-cell: 0.4066, 0.4245)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.4184 - val_loss_macro: 0.4156\n",
      "Epoch 25/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.4171\n",
      "Epoch 26/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4161\n",
      "[Val @ epoch 26] macro=0.412937  (per-cell: 0.4034, 0.4225)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.4161 - val_loss_macro: 0.4129\n",
      "Epoch 27/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.4150\n",
      "Epoch 28/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4140\n",
      "[Val @ epoch 28] macro=0.410251  (per-cell: 0.4002, 0.4203)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.4140 - val_loss_macro: 0.4103\n",
      "Epoch 29/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.4129\n",
      "Epoch 30/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.4119\n",
      "[Val @ epoch 30] macro=0.407837  (per-cell: 0.3974, 0.4183)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.4119 - val_loss_macro: 0.4078\n",
      "Epoch 31/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.4108\n",
      "Epoch 32/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4099\n",
      "[Val @ epoch 32] macro=0.405391  (per-cell: 0.3947, 0.4161)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.4099 - val_loss_macro: 0.4054\n",
      "Epoch 33/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.4088\n",
      "Epoch 34/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4079\n",
      "[Val @ epoch 34] macro=0.403102  (per-cell: 0.3922, 0.4140)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.4079 - val_loss_macro: 0.4031\n",
      "Epoch 35/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.4069\n",
      "Epoch 36/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4058\n",
      "[Val @ epoch 36] macro=0.400789  (per-cell: 0.3897, 0.4119)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 53s 40ms/step - loss: 0.4058 - val_loss_macro: 0.4008\n",
      "Epoch 37/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.4049\n",
      "Epoch 38/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4040\n",
      "[Val @ epoch 38] macro=0.398506  (per-cell: 0.3872, 0.4098)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.4040 - val_loss_macro: 0.3985\n",
      "Epoch 39/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.4031\n",
      "Epoch 40/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4020\n",
      "[Val @ epoch 40] macro=0.396200  (per-cell: 0.3846, 0.4078)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.4020 - val_loss_macro: 0.3962\n",
      "Epoch 41/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.4012\n",
      "Epoch 42/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.4003\n",
      "[Val @ epoch 42] macro=0.393950  (per-cell: 0.3821, 0.4058)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.4003 - val_loss_macro: 0.3940\n",
      "Epoch 43/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.3993\n",
      "Epoch 44/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.3984\n",
      "[Val @ epoch 44] macro=0.391734  (per-cell: 0.3796, 0.4039)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.3984 - val_loss_macro: 0.3917\n",
      "Epoch 45/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.3974\n",
      "Epoch 46/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.3966\n",
      "[Val @ epoch 46] macro=0.389533  (per-cell: 0.3772, 0.4019)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.3966 - val_loss_macro: 0.3895\n",
      "Epoch 47/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.3956\n",
      "Epoch 48/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.3947\n",
      "[Val @ epoch 48] macro=0.387390  (per-cell: 0.3747, 0.4000)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.3947 - val_loss_macro: 0.3874\n",
      "Epoch 49/50\n",
      "1320/1320 [==============================] - 28s 21ms/step - loss: 0.3939\n",
      "Epoch 50/50\n",
      "1318/1320 [============================>.] - ETA: 0s - loss: 0.3928\n",
      "[Val @ epoch 50] macro=0.385265  (per-cell: 0.3724, 0.3982)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run4_best.h5\n",
      "1320/1320 [==============================] - 54s 41ms/step - loss: 0.3928 - val_loss_macro: 0.3853\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run4_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:12<00:00,  6.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_28.mat                 [PITM] MSE=1.103e-07 RSEP=29.76% MAPE=41.98%     \n",
      "  PBROM_data_cell_D5C78.mat              [PITM] MSE=8.060e-04 RSEP=37.71% MAPE=44.21%     \n",
      "[RandomSearch] Run 4 ‚Üí avg_rsep_pitm=33.7383\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 5 / 20\n",
      "  window_size   = 100\n",
      "  lambda_phys   = 0.6980\n",
      "  batch_size    = 1024\n",
      "  learning_rate = 4.79e-08\n",
      "  num_layers    = 3\n",
      "  embed_dim     = 64\n",
      "==================================================\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\n",
      "--- Counting windows for balancing ---\n",
      "  Group 'PBROM_Cells_1': 150764 windows\n",
      "  Group 'D5_Cells_1': 1199901 windows\n",
      "  -> Weight for 'PBROM_Cells_1': 4.4794\n",
      "  -> Weight for 'D5_Cells_1': 0.5628\n",
      "\n",
      "--- Processing Groups ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PBROM_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.87s/it]\n",
      "  D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:19<00:00, 19.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "‚úÖ Done. 1350663 windows generated. Weights applied.\n",
      "Epoch 1/50\n",
      "1320/1320 [==============================] - 79s 44ms/step - loss: 0.5120\n",
      "Epoch 2/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.4880\n",
      "[Val @ epoch 2] macro=0.435607  (per-cell: 0.3995, 0.4717)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 96s 73ms/step - loss: 0.4880 - val_loss_macro: 0.4356\n",
      "Epoch 3/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.4690\n",
      "Epoch 4/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.4542\n",
      "[Val @ epoch 4] macro=0.418470  (per-cell: 0.3963, 0.4406)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 98s 74ms/step - loss: 0.4542 - val_loss_macro: 0.4185\n",
      "Epoch 5/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.4429\n",
      "Epoch 6/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.4341\n",
      "[Val @ epoch 6] macro=0.409208  (per-cell: 0.3943, 0.4241)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 96s 73ms/step - loss: 0.4341 - val_loss_macro: 0.4092\n",
      "Epoch 7/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.4273\n",
      "Epoch 8/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.4219\n",
      "[Val @ epoch 8] macro=0.404014  (per-cell: 0.3929, 0.4151)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 96s 73ms/step - loss: 0.4220 - val_loss_macro: 0.4040\n",
      "Epoch 9/50\n",
      "1320/1320 [==============================] - 60s 45ms/step - loss: 0.4173\n",
      "Epoch 10/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.4138\n",
      "[Val @ epoch 10] macro=0.400989  (per-cell: 0.3921, 0.4099)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 96s 73ms/step - loss: 0.4138 - val_loss_macro: 0.4010\n",
      "Epoch 11/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.4108\n",
      "Epoch 12/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.4082\n",
      "[Val @ epoch 12] macro=0.399078  (per-cell: 0.3915, 0.4067)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 95s 72ms/step - loss: 0.4082 - val_loss_macro: 0.3991\n",
      "Epoch 13/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.4058\n",
      "Epoch 14/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.4041\n",
      "[Val @ epoch 14] macro=0.397820  (per-cell: 0.3910, 0.4046)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 95s 72ms/step - loss: 0.4041 - val_loss_macro: 0.3978\n",
      "Epoch 15/50\n",
      "1320/1320 [==============================] - 61s 46ms/step - loss: 0.4024\n",
      "Epoch 16/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.4009\n",
      "[Val @ epoch 16] macro=0.396974  (per-cell: 0.3907, 0.4032)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 96s 72ms/step - loss: 0.4009 - val_loss_macro: 0.3970\n",
      "Epoch 17/50\n",
      "1320/1320 [==============================] - 60s 45ms/step - loss: 0.3996\n",
      "Epoch 18/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3983\n",
      "[Val @ epoch 18] macro=0.396393  (per-cell: 0.3905, 0.4023)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 96s 72ms/step - loss: 0.3983 - val_loss_macro: 0.3964\n",
      "Epoch 19/50\n",
      "1320/1320 [==============================] - 60s 46ms/step - loss: 0.3976\n",
      "Epoch 20/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3967\n",
      "[Val @ epoch 20] macro=0.395984  (per-cell: 0.3903, 0.4016)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 96s 73ms/step - loss: 0.3967 - val_loss_macro: 0.3960\n",
      "Epoch 21/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.3959\n",
      "Epoch 22/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3953\n",
      "[Val @ epoch 22] macro=0.395682  (per-cell: 0.3902, 0.4012)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 95s 72ms/step - loss: 0.3953 - val_loss_macro: 0.3957\n",
      "Epoch 23/50\n",
      "1320/1320 [==============================] - 61s 46ms/step - loss: 0.3947\n",
      "Epoch 24/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3940\n",
      "[Val @ epoch 24] macro=0.395449  (per-cell: 0.3901, 0.4008)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 95s 72ms/step - loss: 0.3940 - val_loss_macro: 0.3954\n",
      "Epoch 25/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.3937\n",
      "Epoch 26/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3931\n",
      "[Val @ epoch 26] macro=0.395263  (per-cell: 0.3899, 0.4006)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 96s 73ms/step - loss: 0.3931 - val_loss_macro: 0.3953\n",
      "Epoch 27/50\n",
      "1320/1320 [==============================] - 60s 45ms/step - loss: 0.3928\n",
      "Epoch 28/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3923\n",
      "[Val @ epoch 28] macro=0.395105  (per-cell: 0.3898, 0.4004)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 95s 72ms/step - loss: 0.3923 - val_loss_macro: 0.3951\n",
      "Epoch 29/50\n",
      "1320/1320 [==============================] - 59s 44ms/step - loss: 0.3919\n",
      "Epoch 30/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3916\n",
      "[Val @ epoch 30] macro=0.394967  (per-cell: 0.3897, 0.4002)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 95s 72ms/step - loss: 0.3916 - val_loss_macro: 0.3950\n",
      "Epoch 31/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.3913\n",
      "Epoch 32/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3910\n",
      "[Val @ epoch 32] macro=0.394840  (per-cell: 0.3896, 0.4000)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 95s 72ms/step - loss: 0.3910 - val_loss_macro: 0.3948\n",
      "Epoch 33/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.3907\n",
      "Epoch 34/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3906\n",
      "[Val @ epoch 34] macro=0.394721  (per-cell: 0.3895, 0.3999)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 96s 72ms/step - loss: 0.3906 - val_loss_macro: 0.3947\n",
      "Epoch 35/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.3902\n",
      "Epoch 36/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3899\n",
      "[Val @ epoch 36] macro=0.394606  (per-cell: 0.3894, 0.3998)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 94s 72ms/step - loss: 0.3899 - val_loss_macro: 0.3946\n",
      "Epoch 37/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.3899\n",
      "Epoch 38/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3897\n",
      "[Val @ epoch 38] macro=0.394493  (per-cell: 0.3893, 0.3997)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 95s 72ms/step - loss: 0.3897 - val_loss_macro: 0.3945\n",
      "Epoch 39/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.3894\n",
      "Epoch 40/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3891\n",
      "[Val @ epoch 40] macro=0.394380  (per-cell: 0.3892, 0.3995)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 95s 72ms/step - loss: 0.3891 - val_loss_macro: 0.3944\n",
      "Epoch 41/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.3889\n",
      "Epoch 42/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3889\n",
      "[Val @ epoch 42] macro=0.394266  (per-cell: 0.3891, 0.3994)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 95s 72ms/step - loss: 0.3889 - val_loss_macro: 0.3943\n",
      "Epoch 43/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.3886\n",
      "Epoch 44/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3885\n",
      "[Val @ epoch 44] macro=0.394153  (per-cell: 0.3890, 0.3993)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 96s 72ms/step - loss: 0.3885 - val_loss_macro: 0.3942\n",
      "Epoch 45/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.3884\n",
      "Epoch 46/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3880\n",
      "[Val @ epoch 46] macro=0.394037  (per-cell: 0.3889, 0.3992)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 95s 72ms/step - loss: 0.3880 - val_loss_macro: 0.3940\n",
      "Epoch 47/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.3883\n",
      "Epoch 48/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3878\n",
      "[Val @ epoch 48] macro=0.393921  (per-cell: 0.3887, 0.3991)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 95s 72ms/step - loss: 0.3878 - val_loss_macro: 0.3939\n",
      "Epoch 49/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.3877\n",
      "Epoch 50/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3876\n",
      "[Val @ epoch 50] macro=0.393803  (per-cell: 0.3886, 0.3990)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run5_best.h5\n",
      "1320/1320 [==============================] - 95s 72ms/step - loss: 0.3876 - val_loss_macro: 0.3938\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run5_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:24<00:00, 12.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_28.mat                 [PITM] MSE=6.653e-08 RSEP=23.12% MAPE=27.96%     \n",
      "  PBROM_data_cell_D5C78.mat              [PITM] MSE=1.729e-03 RSEP=55.24% MAPE=60.76%     \n",
      "[RandomSearch] Run 5 ‚Üí avg_rsep_pitm=39.1792\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 6 / 20\n",
      "  window_size   = 10\n",
      "  lambda_phys   = 0.6279\n",
      "  batch_size    = 768\n",
      "  learning_rate = 1.42e-07\n",
      "  num_layers    = 4\n",
      "  embed_dim     = 128\n",
      "==================================================\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\n",
      "--- Counting windows for balancing ---\n",
      "  Group 'PBROM_Cells_1': 150854 windows\n",
      "  Group 'D5_Cells_1': 1199991 windows\n",
      "  -> Weight for 'PBROM_Cells_1': 4.4773\n",
      "  -> Weight for 'D5_Cells_1': 0.5629\n",
      "\n",
      "--- Processing Groups ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PBROM_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.47s/it]\n",
      "  D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:18<00:00, 18.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "‚úÖ Done. 1350843 windows generated. Weights applied.\n",
      "Epoch 1/50\n",
      "1759/1759 [==============================] - 55s 18ms/step - loss: 0.5493\n",
      "Epoch 2/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5395\n",
      "[Val @ epoch 2] macro=0.543360  (per-cell: 0.5429, 0.5438)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 61s 35ms/step - loss: 0.5395 - val_loss_macro: 0.5434\n",
      "Epoch 3/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.5343\n",
      "Epoch 4/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5294\n",
      "[Val @ epoch 4] macro=0.533377  (per-cell: 0.5429, 0.5238)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 61s 35ms/step - loss: 0.5294 - val_loss_macro: 0.5334\n",
      "Epoch 5/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.5257\n",
      "Epoch 6/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5230\n",
      "[Val @ epoch 6] macro=0.530159  (per-cell: 0.5398, 0.5205)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 58s 33ms/step - loss: 0.5230 - val_loss_macro: 0.5302\n",
      "Epoch 7/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.5210\n",
      "Epoch 8/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5191\n",
      "[Val @ epoch 8] macro=0.527041  (per-cell: 0.5350, 0.5191)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 58s 33ms/step - loss: 0.5191 - val_loss_macro: 0.5270\n",
      "Epoch 9/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.5175\n",
      "Epoch 10/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5160\n",
      "[Val @ epoch 10] macro=0.523995  (per-cell: 0.5300, 0.5180)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 59s 33ms/step - loss: 0.5160 - val_loss_macro: 0.5240\n",
      "Epoch 11/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.5145\n",
      "Epoch 12/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5133\n",
      "[Val @ epoch 12] macro=0.520780  (per-cell: 0.5251, 0.5165)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 59s 33ms/step - loss: 0.5133 - val_loss_macro: 0.5208\n",
      "Epoch 13/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.5119\n",
      "Epoch 14/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5107\n",
      "[Val @ epoch 14] macro=0.517830  (per-cell: 0.5211, 0.5146)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 58s 33ms/step - loss: 0.5107 - val_loss_macro: 0.5178\n",
      "Epoch 15/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.5096\n",
      "Epoch 16/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5084\n",
      "[Val @ epoch 16] macro=0.515223  (per-cell: 0.5179, 0.5125)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 58s 33ms/step - loss: 0.5084 - val_loss_macro: 0.5152\n",
      "Epoch 17/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.5074\n",
      "Epoch 18/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5063\n",
      "[Val @ epoch 18] macro=0.513130  (per-cell: 0.5151, 0.5111)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 58s 33ms/step - loss: 0.5063 - val_loss_macro: 0.5131\n",
      "Epoch 19/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.5053\n",
      "Epoch 20/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5043\n",
      "[Val @ epoch 20] macro=0.511429  (per-cell: 0.5125, 0.5104)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 59s 33ms/step - loss: 0.5043 - val_loss_macro: 0.5114\n",
      "Epoch 21/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.5033\n",
      "Epoch 22/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5024\n",
      "[Val @ epoch 22] macro=0.509764  (per-cell: 0.5101, 0.5094)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 59s 33ms/step - loss: 0.5024 - val_loss_macro: 0.5098\n",
      "Epoch 23/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.5014\n",
      "Epoch 24/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5006\n",
      "[Val @ epoch 24] macro=0.507931  (per-cell: 0.5075, 0.5083)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 58s 33ms/step - loss: 0.5006 - val_loss_macro: 0.5079\n",
      "Epoch 25/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.4998\n",
      "Epoch 26/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4989\n",
      "[Val @ epoch 26] macro=0.505900  (per-cell: 0.5048, 0.5070)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 59s 33ms/step - loss: 0.4989 - val_loss_macro: 0.5059\n",
      "Epoch 27/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.4980\n",
      "Epoch 28/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4971\n",
      "[Val @ epoch 28] macro=0.503861  (per-cell: 0.5023, 0.5054)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 58s 33ms/step - loss: 0.4971 - val_loss_macro: 0.5039\n",
      "Epoch 29/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.4965\n",
      "Epoch 30/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4956\n",
      "[Val @ epoch 30] macro=0.501592  (per-cell: 0.4993, 0.5039)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 59s 33ms/step - loss: 0.4956 - val_loss_macro: 0.5016\n",
      "Epoch 31/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.4948\n",
      "Epoch 32/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4940\n",
      "[Val @ epoch 32] macro=0.499635  (per-cell: 0.4969, 0.5024)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 59s 33ms/step - loss: 0.4940 - val_loss_macro: 0.4996\n",
      "Epoch 33/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.4932\n",
      "Epoch 34/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4925\n",
      "[Val @ epoch 34] macro=0.497454  (per-cell: 0.4942, 0.5007)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 58s 33ms/step - loss: 0.4925 - val_loss_macro: 0.4975\n",
      "Epoch 35/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.4917\n",
      "Epoch 36/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4910\n",
      "[Val @ epoch 36] macro=0.495353  (per-cell: 0.4914, 0.4994)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 58s 33ms/step - loss: 0.4910 - val_loss_macro: 0.4954\n",
      "Epoch 37/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.4902\n",
      "Epoch 38/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4895\n",
      "[Val @ epoch 38] macro=0.493130  (per-cell: 0.4884, 0.4979)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 60s 34ms/step - loss: 0.4895 - val_loss_macro: 0.4931\n",
      "Epoch 39/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.4888\n",
      "Epoch 40/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4880\n",
      "[Val @ epoch 40] macro=0.490995  (per-cell: 0.4855, 0.4965)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 59s 33ms/step - loss: 0.4880 - val_loss_macro: 0.4910\n",
      "Epoch 41/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.4873\n",
      "Epoch 42/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4866\n",
      "[Val @ epoch 42] macro=0.489016  (per-cell: 0.4829, 0.4951)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 58s 33ms/step - loss: 0.4866 - val_loss_macro: 0.4890\n",
      "Epoch 43/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.4859\n",
      "Epoch 44/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4851\n",
      "[Val @ epoch 44] macro=0.487058  (per-cell: 0.4803, 0.4938)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 59s 33ms/step - loss: 0.4851 - val_loss_macro: 0.4871\n",
      "Epoch 45/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.4845\n",
      "Epoch 46/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4838\n",
      "[Val @ epoch 46] macro=0.485266  (per-cell: 0.4782, 0.4923)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 58s 33ms/step - loss: 0.4838 - val_loss_macro: 0.4853\n",
      "Epoch 47/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.4830\n",
      "Epoch 48/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4824\n",
      "[Val @ epoch 48] macro=0.483637  (per-cell: 0.4763, 0.4910)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 58s 33ms/step - loss: 0.4824 - val_loss_macro: 0.4836\n",
      "Epoch 49/50\n",
      "1759/1759 [==============================] - 32s 18ms/step - loss: 0.4818\n",
      "Epoch 50/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4810\n",
      "[Val @ epoch 50] macro=0.482107  (per-cell: 0.4747, 0.4895)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run6_best.h5\n",
      "1759/1759 [==============================] - 58s 33ms/step - loss: 0.4810 - val_loss_macro: 0.4821\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run6_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:13<00:00,  6.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_28.mat                 [PITM] MSE=1.099e-07 RSEP=29.72% MAPE=42.22%     \n",
      "  PBROM_data_cell_D5C78.mat              [PITM] MSE=6.403e-04 RSEP=33.61% MAPE=39.98%     \n",
      "[RandomSearch] Run 6 ‚Üí avg_rsep_pitm=31.6647\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 7 / 20\n",
      "  window_size   = 80\n",
      "  lambda_phys   = 0.8725\n",
      "  batch_size    = 1024\n",
      "  learning_rate = 1.83e-06\n",
      "  num_layers    = 3\n",
      "  embed_dim     = 96\n",
      "==================================================\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\n",
      "--- Counting windows for balancing ---\n",
      "  Group 'PBROM_Cells_1': 150784 windows\n",
      "  Group 'D5_Cells_1': 1199921 windows\n",
      "  -> Weight for 'PBROM_Cells_1': 4.4789\n",
      "  -> Weight for 'D5_Cells_1': 0.5628\n",
      "\n",
      "--- Processing Groups ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PBROM_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.58s/it]\n",
      "  D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:19<00:00, 19.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "‚úÖ Done. 1350703 windows generated. Weights applied.\n",
      "Epoch 1/50\n",
      "1320/1320 [==============================] - 81s 47ms/step - loss: 0.4484\n",
      "Epoch 2/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.4190\n",
      "[Val @ epoch 2] macro=0.433557  (per-cell: 0.4416, 0.4255)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 100s 75ms/step - loss: 0.4190 - val_loss_macro: 0.4336\n",
      "Epoch 3/50\n",
      "1320/1320 [==============================] - 63s 47ms/step - loss: 0.4051\n",
      "Epoch 4/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3963\n",
      "[Val @ epoch 4] macro=0.417445  (per-cell: 0.4253, 0.4096)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 101s 76ms/step - loss: 0.3963 - val_loss_macro: 0.4174\n",
      "Epoch 5/50\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.3890\n",
      "Epoch 6/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3823\n",
      "[Val @ epoch 6] macro=0.401659  (per-cell: 0.4080, 0.3953)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.3823 - val_loss_macro: 0.4017\n",
      "Epoch 7/50\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.3760\n",
      "Epoch 8/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3698\n",
      "[Val @ epoch 8] macro=0.386978  (per-cell: 0.3909, 0.3830)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.3698 - val_loss_macro: 0.3870\n",
      "Epoch 9/50\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.3635\n",
      "Epoch 10/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3569\n",
      "[Val @ epoch 10] macro=0.377018  (per-cell: 0.3791, 0.3749)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 98s 74ms/step - loss: 0.3569 - val_loss_macro: 0.3770\n",
      "Epoch 11/50\n",
      "1320/1320 [==============================] - 63s 47ms/step - loss: 0.3492\n",
      "Epoch 12/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3375\n",
      "[Val @ epoch 12] macro=0.370710  (per-cell: 0.3695, 0.3719)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 98s 74ms/step - loss: 0.3375 - val_loss_macro: 0.3707\n",
      "Epoch 13/50\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.3255\n",
      "Epoch 14/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3186\n",
      "[Val @ epoch 14] macro=0.362466  (per-cell: 0.3595, 0.3654)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 98s 74ms/step - loss: 0.3186 - val_loss_macro: 0.3625\n",
      "Epoch 15/50\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.3136\n",
      "Epoch 16/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3090\n",
      "[Val @ epoch 16] macro=0.355077  (per-cell: 0.3516, 0.3585)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.3090 - val_loss_macro: 0.3551\n",
      "Epoch 17/50\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.3050\n",
      "Epoch 18/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3010\n",
      "[Val @ epoch 18] macro=0.347935  (per-cell: 0.3439, 0.3520)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.3011 - val_loss_macro: 0.3479\n",
      "Epoch 19/50\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.2973\n",
      "Epoch 20/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2938\n",
      "[Val @ epoch 20] macro=0.340941  (per-cell: 0.3360, 0.3459)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 98s 74ms/step - loss: 0.2938 - val_loss_macro: 0.3409\n",
      "Epoch 21/50\n",
      "1320/1320 [==============================] - 63s 47ms/step - loss: 0.2905\n",
      "Epoch 22/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2871\n",
      "[Val @ epoch 22] macro=0.334667  (per-cell: 0.3292, 0.3402)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.2871 - val_loss_macro: 0.3347\n",
      "Epoch 23/50\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.2839\n",
      "Epoch 24/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2808\n",
      "[Val @ epoch 24] macro=0.328938  (per-cell: 0.3224, 0.3355)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 98s 74ms/step - loss: 0.2808 - val_loss_macro: 0.3289\n",
      "Epoch 25/50\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.2778\n",
      "Epoch 26/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2747\n",
      "[Val @ epoch 26] macro=0.323473  (per-cell: 0.3148, 0.3321)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.2747 - val_loss_macro: 0.3235\n",
      "Epoch 27/50\n",
      "1320/1320 [==============================] - 63s 47ms/step - loss: 0.2720\n",
      "Epoch 28/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.2692\n",
      "[Val @ epoch 28] macro=0.319942  (per-cell: 0.3102, 0.3297)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.2692 - val_loss_macro: 0.3199\n",
      "Epoch 29/50\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.2663\n",
      "Epoch 30/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.2637\n",
      "[Val @ epoch 30] macro=0.314625  (per-cell: 0.3028, 0.3264)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.2637 - val_loss_macro: 0.3146\n",
      "Epoch 31/50\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.2610\n",
      "Epoch 32/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2584\n",
      "[Val @ epoch 32] macro=0.310333  (per-cell: 0.2965, 0.3241)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 98s 75ms/step - loss: 0.2584 - val_loss_macro: 0.3103\n",
      "Epoch 33/50\n",
      "1320/1320 [==============================] - 63s 47ms/step - loss: 0.2559\n",
      "Epoch 34/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2535\n",
      "[Val @ epoch 34] macro=0.307134  (per-cell: 0.2901, 0.3242)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 98s 74ms/step - loss: 0.2535 - val_loss_macro: 0.3071\n",
      "Epoch 35/50\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.2509\n",
      "Epoch 36/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2485\n",
      "[Val @ epoch 36] macro=0.303396  (per-cell: 0.2838, 0.3230)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.2485 - val_loss_macro: 0.3034\n",
      "Epoch 37/50\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.2462\n",
      "Epoch 38/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2439\n",
      "[Val @ epoch 38] macro=0.298985  (per-cell: 0.2772, 0.3207)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 98s 75ms/step - loss: 0.2439 - val_loss_macro: 0.2990\n",
      "Epoch 39/50\n",
      "1320/1320 [==============================] - 63s 47ms/step - loss: 0.2415\n",
      "Epoch 40/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2394\n",
      "[Val @ epoch 40] macro=0.295477  (per-cell: 0.2712, 0.3197)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.2394 - val_loss_macro: 0.2955\n",
      "Epoch 41/50\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.2370\n",
      "Epoch 42/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2351\n",
      "[Val @ epoch 42] macro=0.295442  (per-cell: 0.2723, 0.3185)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.2351 - val_loss_macro: 0.2954\n",
      "Epoch 43/50\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.2328\n",
      "Epoch 44/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2309\n",
      "[Val @ epoch 44] macro=0.292552  (per-cell: 0.2700, 0.3151)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 98s 75ms/step - loss: 0.2309 - val_loss_macro: 0.2926\n",
      "Epoch 45/50\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.2288\n",
      "Epoch 46/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.2268\n",
      "[Val @ epoch 46] macro=0.288954  (per-cell: 0.2662, 0.3117)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.2268 - val_loss_macro: 0.2890\n",
      "Epoch 47/50\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.2248\n",
      "Epoch 48/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.2229\n",
      "[Val @ epoch 48] macro=0.285883  (per-cell: 0.2626, 0.3092)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 98s 74ms/step - loss: 0.2229 - val_loss_macro: 0.2859\n",
      "Epoch 49/50\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.2210\n",
      "Epoch 50/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2191\n",
      "[Val @ epoch 50] macro=0.285871  (per-cell: 0.2616, 0.3101)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run7_best.h5\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.2191 - val_loss_macro: 0.2859\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run7_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:26<00:00, 13.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_28.mat                 [PITM] MSE=9.983e-09 RSEP=8.95% MAPE=15.69%     \n",
      "  PBROM_data_cell_D5C78.mat              [PITM] MSE=4.610e-05 RSEP=9.02% MAPE=10.87%     \n",
      "[RandomSearch] Run 7 ‚Üí avg_rsep_pitm=8.9872\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 8 / 20\n",
      "  window_size   = 100\n",
      "  lambda_phys   = 0.3558\n",
      "  batch_size    = 1024\n",
      "  learning_rate = 3.03e-06\n",
      "  num_layers    = 4\n",
      "  embed_dim     = 32\n",
      "==================================================\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\n",
      "--- Counting windows for balancing ---\n",
      "  Group 'PBROM_Cells_1': 150764 windows\n",
      "  Group 'D5_Cells_1': 1199901 windows\n",
      "  -> Weight for 'PBROM_Cells_1': 4.4794\n",
      "  -> Weight for 'D5_Cells_1': 0.5628\n",
      "\n",
      "--- Processing Groups ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PBROM_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.59s/it]\n",
      "  D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:19<00:00, 19.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "‚úÖ Done. 1350663 windows generated. Weights applied.\n",
      "Epoch 1/50\n",
      "1320/1320 [==============================] - 83s 44ms/step - loss: 0.3660\n",
      "Epoch 2/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3232\n",
      "[Val @ epoch 2] macro=0.318299  (per-cell: 0.3082, 0.3283)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.3232 - val_loss_macro: 0.3183\n",
      "Epoch 3/50\n",
      "1320/1320 [==============================] - 60s 45ms/step - loss: 0.3174\n",
      "Epoch 4/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3120\n",
      "[Val @ epoch 4] macro=0.309296  (per-cell: 0.3039, 0.3147)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 100s 76ms/step - loss: 0.3120 - val_loss_macro: 0.3093\n",
      "Epoch 5/50\n",
      "1320/1320 [==============================] - 60s 45ms/step - loss: 0.3061\n",
      "Epoch 6/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3005\n",
      "[Val @ epoch 6] macro=0.299800  (per-cell: 0.2990, 0.3006)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 97s 74ms/step - loss: 0.3005 - val_loss_macro: 0.2998\n",
      "Epoch 7/50\n",
      "1320/1320 [==============================] - 60s 45ms/step - loss: 0.2952\n",
      "Epoch 8/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2911\n",
      "[Val @ epoch 8] macro=0.294940  (per-cell: 0.2945, 0.2954)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 96s 73ms/step - loss: 0.2912 - val_loss_macro: 0.2949\n",
      "Epoch 9/50\n",
      "1320/1320 [==============================] - 60s 45ms/step - loss: 0.2876\n",
      "Epoch 10/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2846\n",
      "[Val @ epoch 10] macro=0.290613  (per-cell: 0.2899, 0.2913)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 97s 73ms/step - loss: 0.2846 - val_loss_macro: 0.2906\n",
      "Epoch 11/50\n",
      "1320/1320 [==============================] - 61s 46ms/step - loss: 0.2817\n",
      "Epoch 12/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2791\n",
      "[Val @ epoch 12] macro=0.286039  (per-cell: 0.2854, 0.2867)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 98s 74ms/step - loss: 0.2791 - val_loss_macro: 0.2860\n",
      "Epoch 13/50\n",
      "1320/1320 [==============================] - 60s 46ms/step - loss: 0.2765\n",
      "Epoch 14/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.2741\n",
      "[Val @ epoch 14] macro=0.281561  (per-cell: 0.2811, 0.2820)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 96s 73ms/step - loss: 0.2741 - val_loss_macro: 0.2816\n",
      "Epoch 15/50\n",
      "1320/1320 [==============================] - 60s 45ms/step - loss: 0.2718\n",
      "Epoch 16/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2694\n",
      "[Val @ epoch 16] macro=0.277281  (per-cell: 0.2771, 0.2775)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 97s 73ms/step - loss: 0.2694 - val_loss_macro: 0.2773\n",
      "Epoch 17/50\n",
      "1320/1320 [==============================] - 60s 45ms/step - loss: 0.2672\n",
      "Epoch 18/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2650\n",
      "[Val @ epoch 18] macro=0.273123  (per-cell: 0.2732, 0.2730)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 96s 73ms/step - loss: 0.2650 - val_loss_macro: 0.2731\n",
      "Epoch 19/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.2630\n",
      "Epoch 20/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2609\n",
      "[Val @ epoch 20] macro=0.269102  (per-cell: 0.2696, 0.2686)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 96s 73ms/step - loss: 0.2609 - val_loss_macro: 0.2691\n",
      "Epoch 21/50\n",
      "1320/1320 [==============================] - 60s 45ms/step - loss: 0.2588\n",
      "Epoch 22/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.2568\n",
      "[Val @ epoch 22] macro=0.265047  (per-cell: 0.2660, 0.2641)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 96s 73ms/step - loss: 0.2568 - val_loss_macro: 0.2650\n",
      "Epoch 23/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.2548\n",
      "Epoch 24/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2527\n",
      "[Val @ epoch 24] macro=0.261029  (per-cell: 0.2626, 0.2594)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 97s 73ms/step - loss: 0.2527 - val_loss_macro: 0.2610\n",
      "Epoch 25/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.2509\n",
      "Epoch 26/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2490\n",
      "[Val @ epoch 26] macro=0.257038  (per-cell: 0.2594, 0.2547)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 95s 72ms/step - loss: 0.2490 - val_loss_macro: 0.2570\n",
      "Epoch 27/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.2470\n",
      "Epoch 28/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2452\n",
      "[Val @ epoch 28] macro=0.253267  (per-cell: 0.2563, 0.2503)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 96s 72ms/step - loss: 0.2452 - val_loss_macro: 0.2533\n",
      "Epoch 29/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.2432\n",
      "Epoch 30/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2412\n",
      "[Val @ epoch 30] macro=0.249755  (per-cell: 0.2532, 0.2463)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 96s 73ms/step - loss: 0.2412 - val_loss_macro: 0.2498\n",
      "Epoch 31/50\n",
      "1320/1320 [==============================] - 60s 45ms/step - loss: 0.2393\n",
      "Epoch 32/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2370\n",
      "[Val @ epoch 32] macro=0.246473  (per-cell: 0.2501, 0.2429)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 95s 72ms/step - loss: 0.2370 - val_loss_macro: 0.2465\n",
      "Epoch 33/50\n",
      "1320/1320 [==============================] - 60s 45ms/step - loss: 0.2348\n",
      "Epoch 34/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2326\n",
      "[Val @ epoch 34] macro=0.243410  (per-cell: 0.2470, 0.2398)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 96s 73ms/step - loss: 0.2327 - val_loss_macro: 0.2434\n",
      "Epoch 35/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.2302\n",
      "Epoch 36/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2280\n",
      "[Val @ epoch 36] macro=0.240584  (per-cell: 0.2441, 0.2371)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 96s 73ms/step - loss: 0.2280 - val_loss_macro: 0.2406\n",
      "Epoch 37/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.2260\n",
      "Epoch 38/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2241\n",
      "[Val @ epoch 38] macro=0.238185  (per-cell: 0.2413, 0.2351)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 95s 72ms/step - loss: 0.2241 - val_loss_macro: 0.2382\n",
      "Epoch 39/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.2222\n",
      "Epoch 40/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2204\n",
      "[Val @ epoch 40] macro=0.235763  (per-cell: 0.2384, 0.2331)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 97s 74ms/step - loss: 0.2204 - val_loss_macro: 0.2358\n",
      "Epoch 41/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.2188\n",
      "Epoch 42/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2172\n",
      "[Val @ epoch 42] macro=0.233371  (per-cell: 0.2356, 0.2312)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 95s 72ms/step - loss: 0.2172 - val_loss_macro: 0.2334\n",
      "Epoch 43/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.2156\n",
      "Epoch 44/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2142\n",
      "[Val @ epoch 44] macro=0.230978  (per-cell: 0.2326, 0.2294)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 96s 73ms/step - loss: 0.2142 - val_loss_macro: 0.2310\n",
      "Epoch 45/50\n",
      "1320/1320 [==============================] - 59s 45ms/step - loss: 0.2126\n",
      "Epoch 46/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2112\n",
      "[Val @ epoch 46] macro=0.228543  (per-cell: 0.2295, 0.2276)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 96s 72ms/step - loss: 0.2112 - val_loss_macro: 0.2285\n",
      "Epoch 47/50\n",
      "1320/1320 [==============================] - 60s 46ms/step - loss: 0.2098\n",
      "Epoch 48/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2082\n",
      "[Val @ epoch 48] macro=0.226068  (per-cell: 0.2262, 0.2259)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 96s 73ms/step - loss: 0.2082 - val_loss_macro: 0.2261\n",
      "Epoch 49/50\n",
      "1320/1320 [==============================] - 60s 45ms/step - loss: 0.2068\n",
      "Epoch 50/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2054\n",
      "[Val @ epoch 50] macro=0.223366  (per-cell: 0.2231, 0.2236)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run8_best.h5\n",
      "1320/1320 [==============================] - 96s 72ms/step - loss: 0.2054 - val_loss_macro: 0.2234\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run8_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:25<00:00, 12.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_28.mat                 [PITM] MSE=5.198e-08 RSEP=20.43% MAPE=30.90%     \n",
      "  PBROM_data_cell_D5C78.mat              [PITM] MSE=3.882e-04 RSEP=26.17% MAPE=31.99%     \n",
      "[RandomSearch] Run 8 ‚Üí avg_rsep_pitm=23.3037\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 9 / 20\n",
      "  window_size   = 30\n",
      "  lambda_phys   = 0.7618\n",
      "  batch_size    = 1024\n",
      "  learning_rate = 2.71e-05\n",
      "  num_layers    = 4\n",
      "  embed_dim     = 64\n",
      "==================================================\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\n",
      "--- Counting windows for balancing ---\n",
      "  Group 'PBROM_Cells_1': 150834 windows\n",
      "  Group 'D5_Cells_1': 1199971 windows\n",
      "  -> Weight for 'PBROM_Cells_1': 4.4778\n",
      "  -> Weight for 'D5_Cells_1': 0.5628\n",
      "\n",
      "--- Processing Groups ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PBROM_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.53s/it]\n",
      "  D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:17<00:00, 17.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "‚úÖ Done. 1350803 windows generated. Weights applied.\n",
      "Epoch 1/50\n",
      "1320/1320 [==============================] - 59s 26ms/step - loss: 0.4100\n",
      "Epoch 2/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.3291\n",
      "[Val @ epoch 2] macro=0.344300  (per-cell: 0.3358, 0.3528)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 65s 50ms/step - loss: 0.3291 - val_loss_macro: 0.3443\n",
      "Epoch 3/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.2781\n",
      "Epoch 4/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2444\n",
      "[Val @ epoch 4] macro=0.275547  (per-cell: 0.2571, 0.2940)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 67s 51ms/step - loss: 0.2444 - val_loss_macro: 0.2755\n",
      "Epoch 5/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.2199\n",
      "Epoch 6/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.2011\n",
      "[Val @ epoch 6] macro=0.243405  (per-cell: 0.2158, 0.2710)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.2011 - val_loss_macro: 0.2434\n",
      "Epoch 7/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.1860\n",
      "Epoch 8/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.1735\n",
      "[Val @ epoch 8] macro=0.222259  (per-cell: 0.1902, 0.2543)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 64s 49ms/step - loss: 0.1735 - val_loss_macro: 0.2223\n",
      "Epoch 9/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.1630\n",
      "Epoch 10/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.1542\n",
      "[Val @ epoch 10] macro=0.207656  (per-cell: 0.1728, 0.2425)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.1542 - val_loss_macro: 0.2077\n",
      "Epoch 11/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.1465\n",
      "Epoch 12/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.1396\n",
      "[Val @ epoch 12] macro=0.194148  (per-cell: 0.1584, 0.2298)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 64s 48ms/step - loss: 0.1396 - val_loss_macro: 0.1941\n",
      "Epoch 13/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.1337\n",
      "Epoch 14/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.1283\n",
      "[Val @ epoch 14] macro=0.186664  (per-cell: 0.1475, 0.2258)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.1283 - val_loss_macro: 0.1867\n",
      "Epoch 15/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.1235\n",
      "Epoch 16/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.1192\n",
      "[Val @ epoch 16] macro=0.176737  (per-cell: 0.1391, 0.2144)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.1192 - val_loss_macro: 0.1767\n",
      "Epoch 17/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.1151\n",
      "Epoch 18/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.1115\n",
      "[Val @ epoch 18] macro=0.167726  (per-cell: 0.1304, 0.2050)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.1115 - val_loss_macro: 0.1677\n",
      "Epoch 19/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.1081\n",
      "Epoch 20/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.1050\n",
      "[Val @ epoch 20] macro=0.164443  (per-cell: 0.1243, 0.2046)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.1050 - val_loss_macro: 0.1644\n",
      "Epoch 21/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.1021\n",
      "Epoch 22/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0995\n",
      "[Val @ epoch 22] macro=0.156570  (per-cell: 0.1188, 0.1943)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 64s 48ms/step - loss: 0.0995 - val_loss_macro: 0.1566\n",
      "Epoch 23/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.0970\n",
      "Epoch 24/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0948\n",
      "[Val @ epoch 24] macro=0.149452  (per-cell: 0.1136, 0.1853)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.0948 - val_loss_macro: 0.1495\n",
      "Epoch 25/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.0927\n",
      "Epoch 26/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0908\n",
      "[Val @ epoch 26] macro=0.143907  (per-cell: 0.1097, 0.1781)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 64s 48ms/step - loss: 0.0908 - val_loss_macro: 0.1439\n",
      "Epoch 27/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.0880\n",
      "Epoch 28/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0857\n",
      "[Val @ epoch 28] macro=0.140515  (per-cell: 0.1067, 0.1743)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.0856 - val_loss_macro: 0.1405\n",
      "Epoch 29/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.0839\n",
      "Epoch 30/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0824\n",
      "[Val @ epoch 30] macro=0.135188  (per-cell: 0.1039, 0.1665)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 64s 48ms/step - loss: 0.0824 - val_loss_macro: 0.1352\n",
      "Epoch 31/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.0809\n",
      "Epoch 32/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0793\n",
      "[Val @ epoch 32] macro=0.130516  (per-cell: 0.1004, 0.1606)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.0793 - val_loss_macro: 0.1305\n",
      "Epoch 33/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.0779\n",
      "Epoch 34/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0766\n",
      "[Val @ epoch 34] macro=0.129169  (per-cell: 0.0988, 0.1596)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.0766 - val_loss_macro: 0.1292\n",
      "Epoch 35/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.0754\n",
      "Epoch 36/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0742\n",
      "[Val @ epoch 36] macro=0.124201  (per-cell: 0.0965, 0.1519)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 64s 48ms/step - loss: 0.0742 - val_loss_macro: 0.1242\n",
      "Epoch 37/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.0732\n",
      "Epoch 38/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0722\n",
      "[Val @ epoch 38] macro=0.122840  (per-cell: 0.0951, 0.1505)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.0722 - val_loss_macro: 0.1228\n",
      "Epoch 39/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.0712\n",
      "Epoch 40/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0703\n",
      "[Val @ epoch 40] macro=0.121282  (per-cell: 0.0922, 0.1503)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.0703 - val_loss_macro: 0.1213\n",
      "Epoch 41/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.0693\n",
      "Epoch 42/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0684\n",
      "[Val @ epoch 42] macro=0.120244  (per-cell: 0.0932, 0.1473)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.0684 - val_loss_macro: 0.1202\n",
      "Epoch 43/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.0675\n",
      "Epoch 44/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0668\n",
      "[Val @ epoch 44] macro=0.117321  (per-cell: 0.0898, 0.1448)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 64s 48ms/step - loss: 0.0668 - val_loss_macro: 0.1173\n",
      "Epoch 45/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.0660\n",
      "Epoch 46/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0654\n",
      "[Val @ epoch 46] macro=0.117157  (per-cell: 0.0877, 0.1466)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.0654 - val_loss_macro: 0.1172\n",
      "Epoch 47/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.0647\n",
      "Epoch 48/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0639\n",
      "[Val @ epoch 48] macro=0.114576  (per-cell: 0.0867, 0.1425)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 63s 48ms/step - loss: 0.0639 - val_loss_macro: 0.1146\n",
      "Epoch 49/50\n",
      "1320/1320 [==============================] - 36s 27ms/step - loss: 0.0634\n",
      "Epoch 50/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0628\n",
      "[Val @ epoch 50] macro=0.113274  (per-cell: 0.0846, 0.1420)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run9_best.h5\n",
      "1320/1320 [==============================] - 64s 48ms/step - loss: 0.0628 - val_loss_macro: 0.1133\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run9_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:12<00:00,  6.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_28.mat                 [PITM] MSE=1.378e-08 RSEP=10.52% MAPE=19.95%     \n",
      "  PBROM_data_cell_D5C78.mat              [PITM] MSE=5.894e-05 RSEP=10.20% MAPE=12.50%     \n",
      "[RandomSearch] Run 9 ‚Üí avg_rsep_pitm=10.3594\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 10 / 20\n",
      "  window_size   = 50\n",
      "  lambda_phys   = 0.9159\n",
      "  batch_size    = 768\n",
      "  learning_rate = 1.40e-07\n",
      "  num_layers    = 3\n",
      "  embed_dim     = 64\n",
      "==================================================\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\n",
      "--- Counting windows for balancing ---\n",
      "  Group 'PBROM_Cells_1': 150814 windows\n",
      "  Group 'D5_Cells_1': 1199951 windows\n",
      "  -> Weight for 'PBROM_Cells_1': 4.4782\n",
      "  -> Weight for 'D5_Cells_1': 0.5628\n",
      "\n",
      "--- Processing Groups ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PBROM_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.54s/it]\n",
      "  D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:18<00:00, 18.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "‚úÖ Done. 1350763 windows generated. Weights applied.\n",
      "Epoch 1/50\n",
      "1759/1759 [==============================] - 59s 22ms/step - loss: 0.5105\n",
      "Epoch 2/50\n",
      "1757/1759 [============================>.] - ETA: 0s - loss: 0.4534\n",
      "[Val @ epoch 2] macro=0.428352  (per-cell: 0.4177, 0.4390)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 71s 40ms/step - loss: 0.4534 - val_loss_macro: 0.4284\n",
      "Epoch 3/50\n",
      "1759/1759 [==============================] - 40s 22ms/step - loss: 0.4310\n",
      "Epoch 4/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4211\n",
      "[Val @ epoch 4] macro=0.421080  (per-cell: 0.4169, 0.4252)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 71s 41ms/step - loss: 0.4211 - val_loss_macro: 0.4211\n",
      "Epoch 5/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4156\n",
      "Epoch 6/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4125\n",
      "[Val @ epoch 6] macro=0.419825  (per-cell: 0.4168, 0.4228)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4125 - val_loss_macro: 0.4198\n",
      "Epoch 7/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4104\n",
      "Epoch 8/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4088\n",
      "[Val @ epoch 8] macro=0.419326  (per-cell: 0.4167, 0.4220)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4088 - val_loss_macro: 0.4193\n",
      "Epoch 9/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4076\n",
      "Epoch 10/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4067\n",
      "[Val @ epoch 10] macro=0.418867  (per-cell: 0.4163, 0.4214)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4067 - val_loss_macro: 0.4189\n",
      "Epoch 11/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4059\n",
      "Epoch 12/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4051\n",
      "[Val @ epoch 12] macro=0.418317  (per-cell: 0.4158, 0.4208)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4051 - val_loss_macro: 0.4183\n",
      "Epoch 13/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4045\n",
      "Epoch 14/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4040\n",
      "[Val @ epoch 14] macro=0.417685  (per-cell: 0.4153, 0.4201)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4040 - val_loss_macro: 0.4177\n",
      "Epoch 15/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.4034\n",
      "Epoch 16/50\n",
      "1758/1759 [============================>.] - ETA: 0s - loss: 0.4028\n",
      "[Val @ epoch 16] macro=0.416950  (per-cell: 0.4147, 0.4192)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4028 - val_loss_macro: 0.4170\n",
      "Epoch 17/50\n",
      "1759/1759 [==============================] - 39s 22ms/step - loss: 0.4022\n",
      "Epoch 18/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4018\n",
      "[Val @ epoch 18] macro=0.416141  (per-cell: 0.4140, 0.4183)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4018 - val_loss_macro: 0.4161\n",
      "Epoch 19/50\n",
      "1759/1759 [==============================] - 40s 22ms/step - loss: 0.4011\n",
      "Epoch 20/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4007\n",
      "[Val @ epoch 20] macro=0.415248  (per-cell: 0.4133, 0.4172)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.4007 - val_loss_macro: 0.4152\n",
      "Epoch 21/50\n",
      "1759/1759 [==============================] - 40s 22ms/step - loss: 0.4001\n",
      "Epoch 22/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3997\n",
      "[Val @ epoch 22] macro=0.414289  (per-cell: 0.4127, 0.4159)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3997 - val_loss_macro: 0.4143\n",
      "Epoch 23/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3991\n",
      "Epoch 24/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3985\n",
      "[Val @ epoch 24] macro=0.413243  (per-cell: 0.4120, 0.4145)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 68s 39ms/step - loss: 0.3985 - val_loss_macro: 0.4132\n",
      "Epoch 25/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3980\n",
      "Epoch 26/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3973\n",
      "[Val @ epoch 26] macro=0.412113  (per-cell: 0.4112, 0.4130)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3973 - val_loss_macro: 0.4121\n",
      "Epoch 27/50\n",
      "1759/1759 [==============================] - 40s 22ms/step - loss: 0.3967\n",
      "Epoch 28/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3961\n",
      "[Val @ epoch 28] macro=0.410898  (per-cell: 0.4105, 0.4113)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3961 - val_loss_macro: 0.4109\n",
      "Epoch 29/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3956\n",
      "Epoch 30/50\n",
      "1757/1759 [============================>.] - ETA: 0s - loss: 0.3949\n",
      "[Val @ epoch 30] macro=0.409594  (per-cell: 0.4097, 0.4094)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 71s 40ms/step - loss: 0.3949 - val_loss_macro: 0.4096\n",
      "Epoch 31/50\n",
      "1759/1759 [==============================] - 41s 24ms/step - loss: 0.3942\n",
      "Epoch 32/50\n",
      "1758/1759 [============================>.] - ETA: 0s - loss: 0.3936\n",
      "[Val @ epoch 32] macro=0.408189  (per-cell: 0.4090, 0.4074)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 70s 40ms/step - loss: 0.3936 - val_loss_macro: 0.4082\n",
      "Epoch 33/50\n",
      "1759/1759 [==============================] - 40s 22ms/step - loss: 0.3928\n",
      "Epoch 34/50\n",
      "1758/1759 [============================>.] - ETA: 0s - loss: 0.3921\n",
      "[Val @ epoch 34] macro=0.406726  (per-cell: 0.4083, 0.4052)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 68s 39ms/step - loss: 0.3921 - val_loss_macro: 0.4067\n",
      "Epoch 35/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3913\n",
      "Epoch 36/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3906\n",
      "[Val @ epoch 36] macro=0.405145  (per-cell: 0.4075, 0.4028)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3906 - val_loss_macro: 0.4051\n",
      "Epoch 37/50\n",
      "1759/1759 [==============================] - 40s 22ms/step - loss: 0.3898\n",
      "Epoch 38/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3890\n",
      "[Val @ epoch 38] macro=0.403517  (per-cell: 0.4068, 0.4003)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 68s 39ms/step - loss: 0.3890 - val_loss_macro: 0.4035\n",
      "Epoch 39/50\n",
      "1759/1759 [==============================] - 40s 22ms/step - loss: 0.3882\n",
      "Epoch 40/50\n",
      "1758/1759 [============================>.] - ETA: 0s - loss: 0.3875\n",
      "[Val @ epoch 40] macro=0.401849  (per-cell: 0.4060, 0.3977)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3875 - val_loss_macro: 0.4018\n",
      "Epoch 41/50\n",
      "1759/1759 [==============================] - 40s 22ms/step - loss: 0.3865\n",
      "Epoch 42/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3857\n",
      "[Val @ epoch 42] macro=0.400178  (per-cell: 0.4052, 0.3951)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3857 - val_loss_macro: 0.4002\n",
      "Epoch 43/50\n",
      "1759/1759 [==============================] - 39s 22ms/step - loss: 0.3847\n",
      "Epoch 44/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3838\n",
      "[Val @ epoch 44] macro=0.398539  (per-cell: 0.4044, 0.3926)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3838 - val_loss_macro: 0.3985\n",
      "Epoch 45/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3829\n",
      "Epoch 46/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3820\n",
      "[Val @ epoch 46] macro=0.396900  (per-cell: 0.4036, 0.3902)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 68s 39ms/step - loss: 0.3820 - val_loss_macro: 0.3969\n",
      "Epoch 47/50\n",
      "1759/1759 [==============================] - 40s 23ms/step - loss: 0.3811\n",
      "Epoch 48/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3802\n",
      "[Val @ epoch 48] macro=0.395260  (per-cell: 0.4029, 0.3877)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 68s 39ms/step - loss: 0.3802 - val_loss_macro: 0.3953\n",
      "Epoch 49/50\n",
      "1759/1759 [==============================] - 39s 22ms/step - loss: 0.3792\n",
      "Epoch 50/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3784\n",
      "[Val @ epoch 50] macro=0.393804  (per-cell: 0.4021, 0.3855)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run10_best.h5\n",
      "1759/1759 [==============================] - 69s 39ms/step - loss: 0.3784 - val_loss_macro: 0.3938\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run10_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:14<00:00,  7.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_28.mat                 [PITM] MSE=7.848e-08 RSEP=25.11% MAPE=30.40%     \n",
      "  PBROM_data_cell_D5C78.mat              [PITM] MSE=1.207e-03 RSEP=46.16% MAPE=53.52%     \n",
      "[RandomSearch] Run 10 ‚Üí avg_rsep_pitm=35.6324\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 11 / 20\n",
      "  window_size   = 10\n",
      "  lambda_phys   = 0.9406\n",
      "  batch_size    = 768\n",
      "  learning_rate = 4.58e-07\n",
      "  num_layers    = 5\n",
      "  embed_dim     = 128\n",
      "==================================================\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\n",
      "--- Counting windows for balancing ---\n",
      "  Group 'PBROM_Cells_1': 150854 windows\n",
      "  Group 'D5_Cells_1': 1199991 windows\n",
      "  -> Weight for 'PBROM_Cells_1': 4.4773\n",
      "  -> Weight for 'D5_Cells_1': 0.5629\n",
      "\n",
      "--- Processing Groups ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PBROM_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.49s/it]\n",
      "  D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:18<00:00, 18.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "‚úÖ Done. 1350843 windows generated. Weights applied.\n",
      "Epoch 1/50\n",
      "1759/1759 [==============================] - 64s 21ms/step - loss: 0.6578\n",
      "Epoch 2/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.6387\n",
      "[Val @ epoch 2] macro=0.642138  (per-cell: 0.6590, 0.6253)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 66s 38ms/step - loss: 0.6387 - val_loss_macro: 0.6421\n",
      "Epoch 3/50\n",
      "1759/1759 [==============================] - 37s 21ms/step - loss: 0.6244\n",
      "Epoch 4/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.6175\n",
      "[Val @ epoch 4] macro=0.635416  (per-cell: 0.6501, 0.6207)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 68s 38ms/step - loss: 0.6175 - val_loss_macro: 0.6354\n",
      "Epoch 5/50\n",
      "1759/1759 [==============================] - 38s 21ms/step - loss: 0.6123\n",
      "Epoch 6/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.6079\n",
      "[Val @ epoch 6] macro=0.627467  (per-cell: 0.6400, 0.6150)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 64s 37ms/step - loss: 0.6079 - val_loss_macro: 0.6275\n",
      "Epoch 7/50\n",
      "1759/1759 [==============================] - 38s 21ms/step - loss: 0.6040\n",
      "Epoch 8/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.6003\n",
      "[Val @ epoch 8] macro=0.618075  (per-cell: 0.6270, 0.6092)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 64s 36ms/step - loss: 0.6003 - val_loss_macro: 0.6181\n",
      "Epoch 9/50\n",
      "1759/1759 [==============================] - 37s 21ms/step - loss: 0.5967\n",
      "Epoch 10/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5935\n",
      "[Val @ epoch 10] macro=0.608341  (per-cell: 0.6145, 0.6022)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 65s 37ms/step - loss: 0.5935 - val_loss_macro: 0.6083\n",
      "Epoch 11/50\n",
      "1759/1759 [==============================] - 38s 21ms/step - loss: 0.5902\n",
      "Epoch 12/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5871\n",
      "[Val @ epoch 12] macro=0.598723  (per-cell: 0.6012, 0.5963)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 64s 37ms/step - loss: 0.5871 - val_loss_macro: 0.5987\n",
      "Epoch 13/50\n",
      "1759/1759 [==============================] - 37s 21ms/step - loss: 0.5838\n",
      "Epoch 14/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5806\n",
      "[Val @ epoch 14] macro=0.589810  (per-cell: 0.5891, 0.5905)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 64s 37ms/step - loss: 0.5806 - val_loss_macro: 0.5898\n",
      "Epoch 15/50\n",
      "1759/1759 [==============================] - 37s 21ms/step - loss: 0.5775\n",
      "Epoch 16/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5746\n",
      "[Val @ epoch 16] macro=0.584058  (per-cell: 0.5830, 0.5851)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 65s 37ms/step - loss: 0.5746 - val_loss_macro: 0.5841\n",
      "Epoch 17/50\n",
      "1759/1759 [==============================] - 37s 21ms/step - loss: 0.5717\n",
      "Epoch 18/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5688\n",
      "[Val @ epoch 18] macro=0.579313  (per-cell: 0.5791, 0.5795)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 64s 37ms/step - loss: 0.5688 - val_loss_macro: 0.5793\n",
      "Epoch 19/50\n",
      "1759/1759 [==============================] - 37s 21ms/step - loss: 0.5660\n",
      "Epoch 20/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5633\n",
      "[Val @ epoch 20] macro=0.574089  (per-cell: 0.5745, 0.5737)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 64s 37ms/step - loss: 0.5633 - val_loss_macro: 0.5741\n",
      "Epoch 21/50\n",
      "1759/1759 [==============================] - 37s 21ms/step - loss: 0.5606\n",
      "Epoch 22/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5577\n",
      "[Val @ epoch 22] macro=0.569085  (per-cell: 0.5703, 0.5679)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 64s 37ms/step - loss: 0.5577 - val_loss_macro: 0.5691\n",
      "Epoch 23/50\n",
      "1759/1759 [==============================] - 37s 21ms/step - loss: 0.5545\n",
      "Epoch 24/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5512\n",
      "[Val @ epoch 24] macro=0.564101  (per-cell: 0.5663, 0.5619)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 64s 37ms/step - loss: 0.5512 - val_loss_macro: 0.5641\n",
      "Epoch 25/50\n",
      "1759/1759 [==============================] - 38s 21ms/step - loss: 0.5476\n",
      "Epoch 26/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5440\n",
      "[Val @ epoch 26] macro=0.559294  (per-cell: 0.5622, 0.5564)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 65s 37ms/step - loss: 0.5440 - val_loss_macro: 0.5593\n",
      "Epoch 27/50\n",
      "1759/1759 [==============================] - 38s 21ms/step - loss: 0.5408\n",
      "Epoch 28/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5378\n",
      "[Val @ epoch 28] macro=0.554357  (per-cell: 0.5573, 0.5514)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 64s 37ms/step - loss: 0.5378 - val_loss_macro: 0.5544\n",
      "Epoch 29/50\n",
      "1759/1759 [==============================] - 38s 21ms/step - loss: 0.5351\n",
      "Epoch 30/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5325\n",
      "[Val @ epoch 30] macro=0.549908  (per-cell: 0.5529, 0.5469)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 65s 37ms/step - loss: 0.5325 - val_loss_macro: 0.5499\n",
      "Epoch 31/50\n",
      "1759/1759 [==============================] - 38s 21ms/step - loss: 0.5299\n",
      "Epoch 32/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5276\n",
      "[Val @ epoch 32] macro=0.545153  (per-cell: 0.5481, 0.5422)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 64s 37ms/step - loss: 0.5276 - val_loss_macro: 0.5452\n",
      "Epoch 33/50\n",
      "1759/1759 [==============================] - 38s 21ms/step - loss: 0.5251\n",
      "Epoch 34/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5227\n",
      "[Val @ epoch 34] macro=0.541137  (per-cell: 0.5440, 0.5383)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 65s 37ms/step - loss: 0.5227 - val_loss_macro: 0.5411\n",
      "Epoch 35/50\n",
      "1759/1759 [==============================] - 38s 21ms/step - loss: 0.5203\n",
      "Epoch 36/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5179\n",
      "[Val @ epoch 36] macro=0.536998  (per-cell: 0.5396, 0.5344)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 64s 36ms/step - loss: 0.5179 - val_loss_macro: 0.5370\n",
      "Epoch 37/50\n",
      "1759/1759 [==============================] - 38s 21ms/step - loss: 0.5155\n",
      "Epoch 38/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5131\n",
      "[Val @ epoch 38] macro=0.532945  (per-cell: 0.5350, 0.5309)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 64s 37ms/step - loss: 0.5131 - val_loss_macro: 0.5329\n",
      "Epoch 39/50\n",
      "1759/1759 [==============================] - 37s 21ms/step - loss: 0.5108\n",
      "Epoch 40/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5085\n",
      "[Val @ epoch 40] macro=0.529259  (per-cell: 0.5309, 0.5276)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 64s 37ms/step - loss: 0.5085 - val_loss_macro: 0.5293\n",
      "Epoch 41/50\n",
      "1759/1759 [==============================] - 38s 21ms/step - loss: 0.5061\n",
      "Epoch 42/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5038\n",
      "[Val @ epoch 42] macro=0.525676  (per-cell: 0.5264, 0.5249)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 64s 36ms/step - loss: 0.5038 - val_loss_macro: 0.5257\n",
      "Epoch 43/50\n",
      "1759/1759 [==============================] - 37s 21ms/step - loss: 0.5015\n",
      "Epoch 44/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4992\n",
      "[Val @ epoch 44] macro=0.521999  (per-cell: 0.5218, 0.5222)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 64s 37ms/step - loss: 0.4992 - val_loss_macro: 0.5220\n",
      "Epoch 45/50\n",
      "1759/1759 [==============================] - 37s 21ms/step - loss: 0.4970\n",
      "Epoch 46/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4947\n",
      "[Val @ epoch 46] macro=0.518389  (per-cell: 0.5178, 0.5190)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 64s 37ms/step - loss: 0.4947 - val_loss_macro: 0.5184\n",
      "Epoch 47/50\n",
      "1759/1759 [==============================] - 37s 21ms/step - loss: 0.4927\n",
      "Epoch 48/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4906\n",
      "[Val @ epoch 48] macro=0.514713  (per-cell: 0.5135, 0.5160)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 65s 37ms/step - loss: 0.4906 - val_loss_macro: 0.5147\n",
      "Epoch 49/50\n",
      "1759/1759 [==============================] - 37s 21ms/step - loss: 0.4886\n",
      "Epoch 50/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4865\n",
      "[Val @ epoch 50] macro=0.511137  (per-cell: 0.5099, 0.5124)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run11_best.h5\n",
      "1759/1759 [==============================] - 64s 37ms/step - loss: 0.4865 - val_loss_macro: 0.5111\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run11_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:14<00:00,  7.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_28.mat                 [PITM] MSE=2.846e-08 RSEP=15.12% MAPE=24.89%     \n",
      "  PBROM_data_cell_D5C78.mat              [PITM] MSE=2.582e-04 RSEP=21.34% MAPE=25.08%     \n",
      "[RandomSearch] Run 11 ‚Üí avg_rsep_pitm=18.2311\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 12 / 20\n",
      "  window_size   = 80\n",
      "  lambda_phys   = 1.0307\n",
      "  batch_size    = 768\n",
      "  learning_rate = 2.14e-06\n",
      "  num_layers    = 4\n",
      "  embed_dim     = 128\n",
      "==================================================\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\n",
      "--- Counting windows for balancing ---\n",
      "  Group 'PBROM_Cells_1': 150784 windows\n",
      "  Group 'D5_Cells_1': 1199921 windows\n",
      "  -> Weight for 'PBROM_Cells_1': 4.4789\n",
      "  -> Weight for 'D5_Cells_1': 0.5628\n",
      "\n",
      "--- Processing Groups ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PBROM_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.38s/it]\n",
      "  D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:19<00:00, 19.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "‚úÖ Done. 1350703 windows generated. Weights applied.\n",
      "Epoch 1/50\n",
      "1759/1759 [==============================] - 112s 50ms/step - loss: 0.5575\n",
      "Epoch 2/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.5272\n",
      "[Val @ epoch 2] macro=0.542518  (per-cell: 0.5435, 0.5415)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 133s 76ms/step - loss: 0.5272 - val_loss_macro: 0.5425\n",
      "Epoch 3/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.5099\n",
      "Epoch 4/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4940\n",
      "[Val @ epoch 4] macro=0.515007  (per-cell: 0.5086, 0.5214)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 134s 76ms/step - loss: 0.4940 - val_loss_macro: 0.5150\n",
      "Epoch 5/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.4700\n",
      "Epoch 6/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4498\n",
      "[Val @ epoch 6] macro=0.498524  (per-cell: 0.4890, 0.5080)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 75ms/step - loss: 0.4498 - val_loss_macro: 0.4985\n",
      "Epoch 7/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.4388\n",
      "Epoch 8/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4297\n",
      "[Val @ epoch 8] macro=0.483391  (per-cell: 0.4720, 0.4948)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 75ms/step - loss: 0.4297 - val_loss_macro: 0.4834\n",
      "Epoch 9/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.4213\n",
      "Epoch 10/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.4135\n",
      "[Val @ epoch 10] macro=0.468524  (per-cell: 0.4548, 0.4823)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 74ms/step - loss: 0.4135 - val_loss_macro: 0.4685\n",
      "Epoch 11/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.4060\n",
      "Epoch 12/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3987\n",
      "[Val @ epoch 12] macro=0.453045  (per-cell: 0.4360, 0.4701)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 75ms/step - loss: 0.3987 - val_loss_macro: 0.4530\n",
      "Epoch 13/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.3917\n",
      "Epoch 14/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3851\n",
      "[Val @ epoch 14] macro=0.440222  (per-cell: 0.4196, 0.4609)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 74ms/step - loss: 0.3851 - val_loss_macro: 0.4402\n",
      "Epoch 15/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.3788\n",
      "Epoch 16/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3726\n",
      "[Val @ epoch 16] macro=0.430337  (per-cell: 0.4088, 0.4519)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 75ms/step - loss: 0.3726 - val_loss_macro: 0.4303\n",
      "Epoch 17/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.3666\n",
      "Epoch 18/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3609\n",
      "[Val @ epoch 18] macro=0.422216  (per-cell: 0.3986, 0.4458)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 75ms/step - loss: 0.3609 - val_loss_macro: 0.4222\n",
      "Epoch 19/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.3554\n",
      "Epoch 20/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3499\n",
      "[Val @ epoch 20] macro=0.412504  (per-cell: 0.3864, 0.4386)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 74ms/step - loss: 0.3499 - val_loss_macro: 0.4125\n",
      "Epoch 21/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.3447\n",
      "Epoch 22/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3397\n",
      "[Val @ epoch 22] macro=0.401208  (per-cell: 0.3724, 0.4301)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 75ms/step - loss: 0.3397 - val_loss_macro: 0.4012\n",
      "Epoch 23/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.3348\n",
      "Epoch 24/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3300\n",
      "[Val @ epoch 24] macro=0.390671  (per-cell: 0.3583, 0.4230)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 74ms/step - loss: 0.3300 - val_loss_macro: 0.3907\n",
      "Epoch 25/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.3254\n",
      "Epoch 26/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3210\n",
      "[Val @ epoch 26] macro=0.382262  (per-cell: 0.3485, 0.4160)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 74ms/step - loss: 0.3210 - val_loss_macro: 0.3823\n",
      "Epoch 27/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.3166\n",
      "Epoch 28/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3123\n",
      "[Val @ epoch 28] macro=0.379072  (per-cell: 0.3487, 0.4094)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 74ms/step - loss: 0.3123 - val_loss_macro: 0.3791\n",
      "Epoch 29/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.3082\n",
      "Epoch 30/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3041\n",
      "[Val @ epoch 30] macro=0.371081  (per-cell: 0.3364, 0.4058)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 74ms/step - loss: 0.3041 - val_loss_macro: 0.3711\n",
      "Epoch 31/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.3002\n",
      "Epoch 32/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2963\n",
      "[Val @ epoch 32] macro=0.364208  (per-cell: 0.3277, 0.4007)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 74ms/step - loss: 0.2963 - val_loss_macro: 0.3642\n",
      "Epoch 33/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.2926\n",
      "Epoch 34/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2889\n",
      "[Val @ epoch 34] macro=0.358210  (per-cell: 0.3205, 0.3959)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 75ms/step - loss: 0.2889 - val_loss_macro: 0.3582\n",
      "Epoch 35/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.2853\n",
      "Epoch 36/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2817\n",
      "[Val @ epoch 36] macro=0.352257  (per-cell: 0.3114, 0.3931)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 75ms/step - loss: 0.2817 - val_loss_macro: 0.3523\n",
      "Epoch 37/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.2783\n",
      "Epoch 38/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2750\n",
      "[Val @ epoch 38] macro=0.346740  (per-cell: 0.3028, 0.3906)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 74ms/step - loss: 0.2750 - val_loss_macro: 0.3467\n",
      "Epoch 39/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.2717\n",
      "Epoch 40/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2685\n",
      "[Val @ epoch 40] macro=0.339714  (per-cell: 0.2953, 0.3841)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 75ms/step - loss: 0.2685 - val_loss_macro: 0.3397\n",
      "Epoch 41/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.2654\n",
      "Epoch 42/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2623\n",
      "[Val @ epoch 42] macro=0.336336  (per-cell: 0.2913, 0.3813)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 74ms/step - loss: 0.2623 - val_loss_macro: 0.3363\n",
      "Epoch 43/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.2593\n",
      "Epoch 44/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2564\n",
      "[Val @ epoch 44] macro=0.332101  (per-cell: 0.2860, 0.3782)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 75ms/step - loss: 0.2564 - val_loss_macro: 0.3321\n",
      "Epoch 45/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.2535\n",
      "Epoch 46/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2508\n",
      "[Val @ epoch 46] macro=0.324970  (per-cell: 0.2810, 0.3689)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 74ms/step - loss: 0.2508 - val_loss_macro: 0.3250\n",
      "Epoch 47/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.2481\n",
      "Epoch 48/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2453\n",
      "[Val @ epoch 48] macro=0.320034  (per-cell: 0.2721, 0.3680)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 75ms/step - loss: 0.2453 - val_loss_macro: 0.3200\n",
      "Epoch 49/50\n",
      "1759/1759 [==============================] - 90s 51ms/step - loss: 0.2427\n",
      "Epoch 50/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2401\n",
      "[Val @ epoch 50] macro=0.316474  (per-cell: 0.2716, 0.3614)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run12_best.h5\n",
      "1759/1759 [==============================] - 131s 74ms/step - loss: 0.2401 - val_loss_macro: 0.3165\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run12_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:33<00:00, 16.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_28.mat                 [PITM] MSE=1.147e-08 RSEP=9.60% MAPE=17.03%     \n",
      "  PBROM_data_cell_D5C78.mat              [PITM] MSE=1.181e-04 RSEP=14.44% MAPE=17.78%     \n",
      "[RandomSearch] Run 12 ‚Üí avg_rsep_pitm=12.0179\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 13 / 20\n",
      "  window_size   = 50\n",
      "  lambda_phys   = 0.5313\n",
      "  batch_size    = 1024\n",
      "  learning_rate = 1.97e-04\n",
      "  num_layers    = 5\n",
      "  embed_dim     = 96\n",
      "==================================================\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\n",
      "--- Counting windows for balancing ---\n",
      "  Group 'PBROM_Cells_1': 150814 windows\n",
      "  Group 'D5_Cells_1': 1199951 windows\n",
      "  -> Weight for 'PBROM_Cells_1': 4.4782\n",
      "  -> Weight for 'D5_Cells_1': 0.5628\n",
      "\n",
      "--- Processing Groups ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PBROM_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.83s/it]\n",
      "  D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:18<00:00, 18.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "‚úÖ Done. 1350763 windows generated. Weights applied.\n",
      "Epoch 1/50\n",
      "1320/1320 [==============================] - 92s 47ms/step - loss: 0.2401\n",
      "Epoch 2/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0725\n",
      "[Val @ epoch 2] macro=0.101940  (per-cell: 0.0732, 0.1306)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run13_best.h5\n",
      "1320/1320 [==============================] - 102s 77ms/step - loss: 0.0725 - val_loss_macro: 0.1019\n",
      "Epoch 3/50\n",
      "1320/1320 [==============================] - 64s 49ms/step - loss: 0.0511\n",
      "Epoch 4/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.0445\n",
      "[Val @ epoch 4] macro=0.083961  (per-cell: 0.0598, 0.1082)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run13_best.h5\n",
      "1320/1320 [==============================] - 103s 78ms/step - loss: 0.0445 - val_loss_macro: 0.0840\n",
      "Epoch 5/50\n",
      "1320/1320 [==============================] - 64s 49ms/step - loss: 0.0405\n",
      "Epoch 6/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0380\n",
      "[Val @ epoch 6] macro=0.077239  (per-cell: 0.0574, 0.0971)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run13_best.h5\n",
      "1320/1320 [==============================] - 100s 75ms/step - loss: 0.0380 - val_loss_macro: 0.0772\n",
      "Epoch 7/50\n",
      "1320/1320 [==============================] - 64s 49ms/step - loss: 0.0366\n",
      "Epoch 8/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0358\n",
      "[Val @ epoch 8] macro=0.071057  (per-cell: 0.0517, 0.0904)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run13_best.h5\n",
      "1320/1320 [==============================] - 100s 75ms/step - loss: 0.0358 - val_loss_macro: 0.0711\n",
      "Epoch 9/50\n",
      "1320/1320 [==============================] - 64s 49ms/step - loss: 0.0349\n",
      "Epoch 10/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.0345\n",
      "[Val @ epoch 10] macro=0.070277  (per-cell: 0.0509, 0.0897)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run13_best.h5\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.0345 - val_loss_macro: 0.0703\n",
      "Epoch 11/50\n",
      "1320/1320 [==============================] - 64s 49ms/step - loss: 0.0340\n",
      "Epoch 12/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.0336\n",
      "[Val @ epoch 12] macro=0.067561  (per-cell: 0.0499, 0.0853)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run13_best.h5\n",
      "1320/1320 [==============================] - 100s 76ms/step - loss: 0.0336 - val_loss_macro: 0.0676\n",
      "Epoch 13/50\n",
      "1320/1320 [==============================] - 64s 49ms/step - loss: 0.0332\n",
      "Epoch 14/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.0329\n",
      "[Val @ epoch 14] macro=0.069246  (per-cell: 0.0505, 0.0880)\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.0329 - val_loss_macro: 0.0692\n",
      "Epoch 15/50\n",
      "1320/1320 [==============================] - 66s 50ms/step - loss: 0.0327\n",
      "Epoch 16/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.0326\n",
      "[Val @ epoch 16] macro=0.067384  (per-cell: 0.0496, 0.0852)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run13_best.h5\n",
      "1320/1320 [==============================] - 102s 77ms/step - loss: 0.0326 - val_loss_macro: 0.0674\n",
      "Epoch 17/50\n",
      "1320/1320 [==============================] - 67s 50ms/step - loss: 0.0322\n",
      "Epoch 18/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0321\n",
      "[Val @ epoch 18] macro=0.065218  (per-cell: 0.0488, 0.0817)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run13_best.h5\n",
      "1320/1320 [==============================] - 102s 77ms/step - loss: 0.0321 - val_loss_macro: 0.0652\n",
      "Epoch 19/50\n",
      "1320/1320 [==============================] - 66s 50ms/step - loss: 0.0321\n",
      "Epoch 20/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0319\n",
      "[Val @ epoch 20] macro=0.067152  (per-cell: 0.0506, 0.0837)\n",
      "1320/1320 [==============================] - 102s 77ms/step - loss: 0.0319 - val_loss_macro: 0.0672\n",
      "Epoch 21/50\n",
      "1320/1320 [==============================] - 66s 50ms/step - loss: 0.0317\n",
      "Epoch 22/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0316\n",
      "[Val @ epoch 22] macro=0.065702  (per-cell: 0.0481, 0.0833)\n",
      "1320/1320 [==============================] - 101s 77ms/step - loss: 0.0316 - val_loss_macro: 0.0657\n",
      "Epoch 23/50\n",
      "1320/1320 [==============================] - 66s 50ms/step - loss: 0.0314\n",
      "Epoch 24/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0315\n",
      "[Val @ epoch 24] macro=0.064722  (per-cell: 0.0474, 0.0820)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run13_best.h5\n",
      "1320/1320 [==============================] - 100s 76ms/step - loss: 0.0315 - val_loss_macro: 0.0647\n",
      "Epoch 25/50\n",
      "1320/1320 [==============================] - 64s 49ms/step - loss: 0.0312\n",
      "Epoch 26/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0311\n",
      "[Val @ epoch 26] macro=0.065430  (per-cell: 0.0494, 0.0814)\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.0311 - val_loss_macro: 0.0654\n",
      "Epoch 27/50\n",
      "1320/1320 [==============================] - 64s 48ms/step - loss: 0.0311\n",
      "Epoch 28/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0309\n",
      "[Val @ epoch 28] macro=0.064810  (per-cell: 0.0475, 0.0822)\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.0309 - val_loss_macro: 0.0648\n",
      "Epoch 29/50\n",
      "1320/1320 [==============================] - 64s 49ms/step - loss: 0.0310\n",
      "Epoch 30/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.0309\n",
      "[Val @ epoch 30] macro=0.064001  (per-cell: 0.0469, 0.0811)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run13_best.h5\n",
      "1320/1320 [==============================] - 100s 75ms/step - loss: 0.0309 - val_loss_macro: 0.0640\n",
      "Epoch 31/50\n",
      "1320/1320 [==============================] - 64s 49ms/step - loss: 0.0307\n",
      "Epoch 32/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.0307\n",
      "[Val @ epoch 32] macro=0.066012  (per-cell: 0.0489, 0.0832)\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.0307 - val_loss_macro: 0.0660\n",
      "Epoch 33/50\n",
      "1320/1320 [==============================] - 64s 48ms/step - loss: 0.0306\n",
      "Epoch 34/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.0305\n",
      "[Val @ epoch 34] macro=0.064257  (per-cell: 0.0474, 0.0811)\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.0305 - val_loss_macro: 0.0643\n",
      "Epoch 35/50\n",
      "1320/1320 [==============================] - 64s 48ms/step - loss: 0.0307\n",
      "Epoch 36/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.0304\n",
      "[Val @ epoch 36] macro=0.063437  (per-cell: 0.0460, 0.0809)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run13_best.h5\n",
      "1320/1320 [==============================] - 100s 76ms/step - loss: 0.0304 - val_loss_macro: 0.0634\n",
      "Epoch 37/50\n",
      "1320/1320 [==============================] - 64s 48ms/step - loss: 0.0304\n",
      "Epoch 38/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0305\n",
      "[Val @ epoch 38] macro=0.062608  (per-cell: 0.0482, 0.0771)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run13_best.h5\n",
      "1320/1320 [==============================] - 100s 76ms/step - loss: 0.0305 - val_loss_macro: 0.0626\n",
      "Epoch 39/50\n",
      "1320/1320 [==============================] - 64s 48ms/step - loss: 0.0303\n",
      "Epoch 40/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.0302\n",
      "[Val @ epoch 40] macro=0.062905  (per-cell: 0.0463, 0.0795)\n",
      "1320/1320 [==============================] - 100s 75ms/step - loss: 0.0302 - val_loss_macro: 0.0629\n",
      "Epoch 41/50\n",
      "1320/1320 [==============================] - 65s 49ms/step - loss: 0.0302\n",
      "Epoch 42/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0302\n",
      "[Val @ epoch 42] macro=0.063166  (per-cell: 0.0487, 0.0777)\n",
      "1320/1320 [==============================] - 100s 76ms/step - loss: 0.0302 - val_loss_macro: 0.0632\n",
      "Epoch 43/50\n",
      "1320/1320 [==============================] - 64s 49ms/step - loss: 0.0302\n",
      "Epoch 44/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0301\n",
      "[Val @ epoch 44] macro=0.063386  (per-cell: 0.0466, 0.0802)\n",
      "  ‚Üí LR reduced: 0.000196549 -> 9.82747e-05\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.0301 - val_loss_macro: 0.0634\n",
      "Epoch 45/50\n",
      "1320/1320 [==============================] - 64s 49ms/step - loss: 0.0298\n",
      "Epoch 46/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.0298\n",
      "[Val @ epoch 46] macro=0.062701  (per-cell: 0.0466, 0.0788)\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.0298 - val_loss_macro: 0.0627\n",
      "Epoch 47/50\n",
      "1320/1320 [==============================] - 64s 48ms/step - loss: 0.0297\n",
      "Epoch 48/50\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.0298\n",
      "[Val @ epoch 48] macro=0.064143  (per-cell: 0.0484, 0.0799)\n",
      "  ‚Üí Early stopping.\n",
      "1320/1320 [==============================] - 99s 75ms/step - loss: 0.0298 - val_loss_macro: 0.0641\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run13_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:26<00:00, 13.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_28.mat                 [PITM] MSE=1.114e-08 RSEP=9.46% MAPE=17.60%     \n",
      "  PBROM_data_cell_D5C78.mat              [PITM] MSE=7.276e-05 RSEP=11.33% MAPE=13.97%     \n",
      "[RandomSearch] Run 13 ‚Üí avg_rsep_pitm=10.3963\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 14 / 20\n",
      "  window_size   = 100\n",
      "  lambda_phys   = 0.9254\n",
      "  batch_size    = 768\n",
      "  learning_rate = 2.21e-05\n",
      "  num_layers    = 3\n",
      "  embed_dim     = 96\n",
      "==================================================\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\n",
      "--- Counting windows for balancing ---\n",
      "  Group 'PBROM_Cells_1': 150764 windows\n",
      "  Group 'D5_Cells_1': 1199901 windows\n",
      "  -> Weight for 'PBROM_Cells_1': 4.4794\n",
      "  -> Weight for 'D5_Cells_1': 0.5628\n",
      "\n",
      "--- Processing Groups ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PBROM_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.62s/it]\n",
      "  D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:19<00:00, 19.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "‚úÖ Done. 1350663 windows generated. Weights applied.\n",
      "Epoch 1/50\n",
      "1759/1759 [==============================] - 97s 43ms/step - loss: 0.3660\n",
      "Epoch 2/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2695\n",
      "[Val @ epoch 2] macro=0.290326  (per-cell: 0.2803, 0.3003)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 117s 67ms/step - loss: 0.2695 - val_loss_macro: 0.2903\n",
      "Epoch 3/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.2204\n",
      "Epoch 4/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.1863\n",
      "[Val @ epoch 4] macro=0.228606  (per-cell: 0.2139, 0.2433)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 119s 68ms/step - loss: 0.1863 - val_loss_macro: 0.2286\n",
      "Epoch 5/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.1615\n",
      "Epoch 6/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.1428\n",
      "[Val @ epoch 6] macro=0.186998  (per-cell: 0.1658, 0.2082)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 117s 66ms/step - loss: 0.1428 - val_loss_macro: 0.1870\n",
      "Epoch 7/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.1286\n",
      "Epoch 8/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.1175\n",
      "[Val @ epoch 8] macro=0.170141  (per-cell: 0.1537, 0.1866)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 116s 66ms/step - loss: 0.1175 - val_loss_macro: 0.1701\n",
      "Epoch 9/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.1086\n",
      "Epoch 10/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.1013\n",
      "[Val @ epoch 10] macro=0.146806  (per-cell: 0.1253, 0.1683)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 117s 66ms/step - loss: 0.1013 - val_loss_macro: 0.1468\n",
      "Epoch 11/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.0955\n",
      "Epoch 12/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0905\n",
      "[Val @ epoch 12] macro=0.137595  (per-cell: 0.1139, 0.1613)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 116s 66ms/step - loss: 0.0905 - val_loss_macro: 0.1376\n",
      "Epoch 13/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.0864\n",
      "Epoch 14/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0829\n",
      "[Val @ epoch 14] macro=0.133126  (per-cell: 0.1072, 0.1591)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 116s 66ms/step - loss: 0.0829 - val_loss_macro: 0.1331\n",
      "Epoch 15/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.0798\n",
      "Epoch 16/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0757\n",
      "[Val @ epoch 16] macro=0.125642  (per-cell: 0.0999, 0.1514)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 116s 66ms/step - loss: 0.0757 - val_loss_macro: 0.1256\n",
      "Epoch 17/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.0728\n",
      "Epoch 18/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0707\n",
      "[Val @ epoch 18] macro=0.118747  (per-cell: 0.0956, 0.1419)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 116s 66ms/step - loss: 0.0707 - val_loss_macro: 0.1187\n",
      "Epoch 19/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.0689\n",
      "Epoch 20/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0673\n",
      "[Val @ epoch 20] macro=0.113104  (per-cell: 0.0922, 0.1340)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 116s 66ms/step - loss: 0.0673 - val_loss_macro: 0.1131\n",
      "Epoch 21/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.0659\n",
      "Epoch 22/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0646\n",
      "[Val @ epoch 22] macro=0.108500  (per-cell: 0.0882, 0.1288)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 115s 66ms/step - loss: 0.0646 - val_loss_macro: 0.1085\n",
      "Epoch 23/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.0634\n",
      "Epoch 24/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0624\n",
      "[Val @ epoch 24] macro=0.107105  (per-cell: 0.0875, 0.1267)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 116s 66ms/step - loss: 0.0624 - val_loss_macro: 0.1071\n",
      "Epoch 25/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.0614\n",
      "Epoch 26/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0606\n",
      "[Val @ epoch 26] macro=0.103580  (per-cell: 0.0834, 0.1237)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 116s 66ms/step - loss: 0.0606 - val_loss_macro: 0.1036\n",
      "Epoch 27/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.0598\n",
      "Epoch 28/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0591\n",
      "[Val @ epoch 28] macro=0.101371  (per-cell: 0.0826, 0.1202)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 116s 66ms/step - loss: 0.0591 - val_loss_macro: 0.1014\n",
      "Epoch 29/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.0584\n",
      "Epoch 30/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0578\n",
      "[Val @ epoch 30] macro=0.099953  (per-cell: 0.0807, 0.1192)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 115s 66ms/step - loss: 0.0578 - val_loss_macro: 0.1000\n",
      "Epoch 31/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.0572\n",
      "Epoch 32/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0566\n",
      "[Val @ epoch 32] macro=0.097748  (per-cell: 0.0811, 0.1144)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 116s 66ms/step - loss: 0.0566 - val_loss_macro: 0.0977\n",
      "Epoch 33/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.0561\n",
      "Epoch 34/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0557\n",
      "[Val @ epoch 34] macro=0.095249  (per-cell: 0.0778, 0.1127)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 116s 66ms/step - loss: 0.0557 - val_loss_macro: 0.0952\n",
      "Epoch 35/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.0552\n",
      "Epoch 36/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0548\n",
      "[Val @ epoch 36] macro=0.094235  (per-cell: 0.0770, 0.1114)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 116s 66ms/step - loss: 0.0548 - val_loss_macro: 0.0942\n",
      "Epoch 37/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.0544\n",
      "Epoch 38/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0540\n",
      "[Val @ epoch 38] macro=0.093658  (per-cell: 0.0771, 0.1102)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 116s 66ms/step - loss: 0.0540 - val_loss_macro: 0.0937\n",
      "Epoch 39/50\n",
      "1759/1759 [==============================] - 79s 45ms/step - loss: 0.0537\n",
      "Epoch 40/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0533\n",
      "[Val @ epoch 40] macro=0.092666  (per-cell: 0.0750, 0.1103)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 116s 66ms/step - loss: 0.0533 - val_loss_macro: 0.0927\n",
      "Epoch 41/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.0530\n",
      "Epoch 42/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0527\n",
      "[Val @ epoch 42] macro=0.091456  (per-cell: 0.0756, 0.1073)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 117s 66ms/step - loss: 0.0527 - val_loss_macro: 0.0915\n",
      "Epoch 43/50\n",
      "1759/1759 [==============================] - 78s 44ms/step - loss: 0.0525\n",
      "Epoch 44/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0522\n",
      "[Val @ epoch 44] macro=0.091090  (per-cell: 0.0751, 0.1070)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 116s 66ms/step - loss: 0.0522 - val_loss_macro: 0.0911\n",
      "Epoch 45/50\n",
      "1759/1759 [==============================] - 78s 44ms/step - loss: 0.0519\n",
      "Epoch 46/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0517\n",
      "[Val @ epoch 46] macro=0.090870  (per-cell: 0.0742, 0.1075)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 116s 66ms/step - loss: 0.0517 - val_loss_macro: 0.0909\n",
      "Epoch 47/50\n",
      "1759/1759 [==============================] - 77s 44ms/step - loss: 0.0515\n",
      "Epoch 48/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0512\n",
      "[Val @ epoch 48] macro=0.090304  (per-cell: 0.0739, 0.1067)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 118s 67ms/step - loss: 0.0512 - val_loss_macro: 0.0903\n",
      "Epoch 49/50\n",
      "1759/1759 [==============================] - 78s 44ms/step - loss: 0.0511\n",
      "Epoch 50/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0508\n",
      "[Val @ epoch 50] macro=0.089923  (per-cell: 0.0739, 0.1059)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run14_best.h5\n",
      "1759/1759 [==============================] - 116s 66ms/step - loss: 0.0508 - val_loss_macro: 0.0899\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run14_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:27<00:00, 13.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_28.mat                 [PITM] MSE=8.191e-09 RSEP=8.11% MAPE=15.95%     \n",
      "  PBROM_data_cell_D5C78.mat              [PITM] MSE=4.749e-05 RSEP=9.15% MAPE=11.38%     \n",
      "[RandomSearch] Run 14 ‚Üí avg_rsep_pitm=8.6327\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 15 / 20\n",
      "  window_size   = 60\n",
      "  lambda_phys   = 0.8444\n",
      "  batch_size    = 768\n",
      "  learning_rate = 2.67e-04\n",
      "  num_layers    = 4\n",
      "  embed_dim     = 96\n",
      "==================================================\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\n",
      "--- Counting windows for balancing ---\n",
      "  Group 'PBROM_Cells_1': 150804 windows\n",
      "  Group 'D5_Cells_1': 1199941 windows\n",
      "  -> Weight for 'PBROM_Cells_1': 4.4785\n",
      "  -> Weight for 'D5_Cells_1': 0.5628\n",
      "\n",
      "--- Processing Groups ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PBROM_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.84s/it]\n",
      "  D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:18<00:00, 18.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "‚úÖ Done. 1350743 windows generated. Weights applied.\n",
      "Epoch 1/50\n",
      "1759/1759 [==============================] - 87s 35ms/step - loss: 0.1946\n",
      "Epoch 2/50\n",
      "1758/1759 [============================>.] - ETA: 0s - loss: 0.0718\n",
      "[Val @ epoch 2] macro=0.103242  (per-cell: 0.0895, 0.1170)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run15_best.h5\n",
      "1759/1759 [==============================] - 101s 57ms/step - loss: 0.0717 - val_loss_macro: 0.1032\n",
      "Epoch 3/50\n",
      "1759/1759 [==============================] - 62s 36ms/step - loss: 0.0572\n",
      "Epoch 4/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0523\n",
      "[Val @ epoch 4] macro=0.092901  (per-cell: 0.0708, 0.1150)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run15_best.h5\n",
      "1759/1759 [==============================] - 101s 57ms/step - loss: 0.0523 - val_loss_macro: 0.0929\n",
      "Epoch 5/50\n",
      "1759/1759 [==============================] - 63s 36ms/step - loss: 0.0486\n",
      "Epoch 6/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0464\n",
      "[Val @ epoch 6] macro=0.090136  (per-cell: 0.0702, 0.1100)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run15_best.h5\n",
      "1759/1759 [==============================] - 98s 55ms/step - loss: 0.0464 - val_loss_macro: 0.0901\n",
      "Epoch 7/50\n",
      "1759/1759 [==============================] - 63s 36ms/step - loss: 0.0452\n",
      "Epoch 8/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0445\n",
      "[Val @ epoch 8] macro=0.088603  (per-cell: 0.0662, 0.1110)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run15_best.h5\n",
      "1759/1759 [==============================] - 98s 55ms/step - loss: 0.0445 - val_loss_macro: 0.0886\n",
      "Epoch 9/50\n",
      "1759/1759 [==============================] - 64s 36ms/step - loss: 0.0439\n",
      "Epoch 10/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0435\n",
      "[Val @ epoch 10] macro=0.086782  (per-cell: 0.0659, 0.1077)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run15_best.h5\n",
      "1759/1759 [==============================] - 98s 56ms/step - loss: 0.0435 - val_loss_macro: 0.0868\n",
      "Epoch 11/50\n",
      "1759/1759 [==============================] - 63s 36ms/step - loss: 0.0431\n",
      "Epoch 12/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0428\n",
      "[Val @ epoch 12] macro=0.085714  (per-cell: 0.0655, 0.1060)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run15_best.h5\n",
      "1759/1759 [==============================] - 99s 56ms/step - loss: 0.0428 - val_loss_macro: 0.0857\n",
      "Epoch 13/50\n",
      "1759/1759 [==============================] - 64s 37ms/step - loss: 0.0425\n",
      "Epoch 14/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0425\n",
      "[Val @ epoch 14] macro=0.083727  (per-cell: 0.0647, 0.1027)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run15_best.h5\n",
      "1759/1759 [==============================] - 98s 56ms/step - loss: 0.0425 - val_loss_macro: 0.0837\n",
      "Epoch 15/50\n",
      "1759/1759 [==============================] - 63s 36ms/step - loss: 0.0422\n",
      "Epoch 16/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0420\n",
      "[Val @ epoch 16] macro=0.084677  (per-cell: 0.0650, 0.1044)\n",
      "1759/1759 [==============================] - 98s 55ms/step - loss: 0.0420 - val_loss_macro: 0.0847\n",
      "Epoch 17/50\n",
      "1759/1759 [==============================] - 62s 35ms/step - loss: 0.0419\n",
      "Epoch 18/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0417\n",
      "[Val @ epoch 18] macro=0.083182  (per-cell: 0.0639, 0.1024)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run15_best.h5\n",
      "1759/1759 [==============================] - 97s 55ms/step - loss: 0.0417 - val_loss_macro: 0.0832\n",
      "Epoch 19/50\n",
      "1759/1759 [==============================] - 62s 36ms/step - loss: 0.0414\n",
      "Epoch 20/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0414\n",
      "[Val @ epoch 20] macro=0.083076  (per-cell: 0.0623, 0.1039)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run15_best.h5\n",
      "1759/1759 [==============================] - 97s 55ms/step - loss: 0.0414 - val_loss_macro: 0.0831\n",
      "Epoch 21/50\n",
      "1759/1759 [==============================] - 62s 35ms/step - loss: 0.0413\n",
      "Epoch 22/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0411\n",
      "[Val @ epoch 22] macro=0.082451  (per-cell: 0.0623, 0.1026)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run15_best.h5\n",
      "1759/1759 [==============================] - 97s 55ms/step - loss: 0.0411 - val_loss_macro: 0.0825\n",
      "Epoch 23/50\n",
      "1759/1759 [==============================] - 62s 35ms/step - loss: 0.0412\n",
      "Epoch 24/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0409\n",
      "[Val @ epoch 24] macro=0.081680  (per-cell: 0.0602, 0.1031)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run15_best.h5\n",
      "1759/1759 [==============================] - 97s 55ms/step - loss: 0.0409 - val_loss_macro: 0.0817\n",
      "Epoch 25/50\n",
      "1759/1759 [==============================] - 62s 35ms/step - loss: 0.0409\n",
      "Epoch 26/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0409\n",
      "[Val @ epoch 26] macro=0.081281  (per-cell: 0.0610, 0.1015)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run15_best.h5\n",
      "1759/1759 [==============================] - 97s 55ms/step - loss: 0.0409 - val_loss_macro: 0.0813\n",
      "Epoch 27/50\n",
      "1759/1759 [==============================] - 62s 35ms/step - loss: 0.0408\n",
      "Epoch 28/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0407\n",
      "[Val @ epoch 28] macro=0.083124  (per-cell: 0.0605, 0.1057)\n",
      "1759/1759 [==============================] - 97s 55ms/step - loss: 0.0407 - val_loss_macro: 0.0831\n",
      "Epoch 29/50\n",
      "1759/1759 [==============================] - 62s 35ms/step - loss: 0.0406\n",
      "Epoch 30/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0405\n",
      "[Val @ epoch 30] macro=0.082118  (per-cell: 0.0607, 0.1035)\n",
      "1759/1759 [==============================] - 97s 55ms/step - loss: 0.0405 - val_loss_macro: 0.0821\n",
      "Epoch 31/50\n",
      "1759/1759 [==============================] - 62s 35ms/step - loss: 0.0406\n",
      "Epoch 32/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0405\n",
      "[Val @ epoch 32] macro=0.085949  (per-cell: 0.0605, 0.1114)\n",
      "  ‚Üí LR reduced: 0.000266753 -> 0.000133376\n",
      "1759/1759 [==============================] - 97s 55ms/step - loss: 0.0405 - val_loss_macro: 0.0859\n",
      "Epoch 33/50\n",
      "1759/1759 [==============================] - 62s 35ms/step - loss: 0.0402\n",
      "Epoch 34/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0402\n",
      "[Val @ epoch 34] macro=0.082378  (per-cell: 0.0604, 0.1044)\n",
      "1759/1759 [==============================] - 97s 55ms/step - loss: 0.0402 - val_loss_macro: 0.0824\n",
      "Epoch 35/50\n",
      "1759/1759 [==============================] - 62s 35ms/step - loss: 0.0401\n",
      "Epoch 36/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.0401\n",
      "[Val @ epoch 36] macro=0.082727  (per-cell: 0.0600, 0.1055)\n",
      "  ‚Üí Early stopping.\n",
      "1759/1759 [==============================] - 97s 55ms/step - loss: 0.0401 - val_loss_macro: 0.0827\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run15_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:26<00:00, 13.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_28.mat                 [PITM] MSE=6.975e-09 RSEP=7.48% MAPE=14.65%     \n",
      "  PBROM_data_cell_D5C78.mat              [PITM] MSE=2.427e-05 RSEP=6.54% MAPE=7.32%     \n",
      "[RandomSearch] Run 15 ‚Üí avg_rsep_pitm=7.0142\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 16 / 20\n",
      "  window_size   = 100\n",
      "  lambda_phys   = 0.2473\n",
      "  batch_size    = 1024\n",
      "  learning_rate = 2.74e-07\n",
      "  num_layers    = 5\n",
      "  embed_dim     = 32\n",
      "==================================================\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\n",
      "--- Counting windows for balancing ---\n",
      "  Group 'PBROM_Cells_1': 150764 windows\n",
      "  Group 'D5_Cells_1': 1199901 windows\n",
      "  -> Weight for 'PBROM_Cells_1': 4.4794\n",
      "  -> Weight for 'D5_Cells_1': 0.5628\n",
      "\n",
      "--- Processing Groups ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PBROM_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.60s/it]\n",
      "  D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:19<00:00, 19.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "‚úÖ Done. 1350663 windows generated. Weights applied.\n",
      "Epoch 1/50\n",
      "1320/1320 [==============================] - 98s 52ms/step - loss: 0.3653\n",
      "Epoch 2/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3614\n",
      "[Val @ epoch 2] macro=0.353556  (per-cell: 0.3446, 0.3625)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 112s 85ms/step - loss: 0.3614 - val_loss_macro: 0.3536\n",
      "Epoch 3/50\n",
      "1320/1320 [==============================] - 71s 53ms/step - loss: 0.3595\n",
      "Epoch 4/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3582\n",
      "[Val @ epoch 4] macro=0.351463  (per-cell: 0.3422, 0.3607)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 113s 86ms/step - loss: 0.3582 - val_loss_macro: 0.3515\n",
      "Epoch 5/50\n",
      "1320/1320 [==============================] - 71s 54ms/step - loss: 0.3570\n",
      "Epoch 6/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3560\n",
      "[Val @ epoch 6] macro=0.349597  (per-cell: 0.3408, 0.3584)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 110s 83ms/step - loss: 0.3560 - val_loss_macro: 0.3496\n",
      "Epoch 7/50\n",
      "1320/1320 [==============================] - 71s 53ms/step - loss: 0.3549\n",
      "Epoch 8/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3539\n",
      "[Val @ epoch 8] macro=0.347677  (per-cell: 0.3396, 0.3557)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 110s 83ms/step - loss: 0.3539 - val_loss_macro: 0.3477\n",
      "Epoch 9/50\n",
      "1320/1320 [==============================] - 71s 54ms/step - loss: 0.3529\n",
      "Epoch 10/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3518\n",
      "[Val @ epoch 10] macro=0.345660  (per-cell: 0.3384, 0.3529)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 110s 83ms/step - loss: 0.3518 - val_loss_macro: 0.3457\n",
      "Epoch 11/50\n",
      "1320/1320 [==============================] - 71s 54ms/step - loss: 0.3508\n",
      "Epoch 12/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3497\n",
      "[Val @ epoch 12] macro=0.343620  (per-cell: 0.3372, 0.3500)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 109s 83ms/step - loss: 0.3497 - val_loss_macro: 0.3436\n",
      "Epoch 13/50\n",
      "1320/1320 [==============================] - 71s 54ms/step - loss: 0.3486\n",
      "Epoch 14/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3477\n",
      "[Val @ epoch 14] macro=0.341497  (per-cell: 0.3360, 0.3470)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 110s 83ms/step - loss: 0.3477 - val_loss_macro: 0.3415\n",
      "Epoch 15/50\n",
      "1320/1320 [==============================] - 71s 54ms/step - loss: 0.3465\n",
      "Epoch 16/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3454\n",
      "[Val @ epoch 16] macro=0.339281  (per-cell: 0.3345, 0.3441)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 109s 83ms/step - loss: 0.3454 - val_loss_macro: 0.3393\n",
      "Epoch 17/50\n",
      "1320/1320 [==============================] - 71s 54ms/step - loss: 0.3443\n",
      "Epoch 18/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3431\n",
      "[Val @ epoch 18] macro=0.337001  (per-cell: 0.3329, 0.3411)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 110s 84ms/step - loss: 0.3431 - val_loss_macro: 0.3370\n",
      "Epoch 19/50\n",
      "1320/1320 [==============================] - 71s 54ms/step - loss: 0.3421\n",
      "Epoch 20/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3408\n",
      "[Val @ epoch 20] macro=0.334737  (per-cell: 0.3313, 0.3381)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 109s 83ms/step - loss: 0.3408 - val_loss_macro: 0.3347\n",
      "Epoch 21/50\n",
      "1320/1320 [==============================] - 71s 53ms/step - loss: 0.3397\n",
      "Epoch 22/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3385\n",
      "[Val @ epoch 22] macro=0.332637  (per-cell: 0.3298, 0.3355)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 109s 83ms/step - loss: 0.3385 - val_loss_macro: 0.3326\n",
      "Epoch 23/50\n",
      "1320/1320 [==============================] - 70s 53ms/step - loss: 0.3373\n",
      "Epoch 24/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3360\n",
      "[Val @ epoch 24] macro=0.330745  (per-cell: 0.3283, 0.3331)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 109s 83ms/step - loss: 0.3360 - val_loss_macro: 0.3307\n",
      "Epoch 25/50\n",
      "1320/1320 [==============================] - 70s 53ms/step - loss: 0.3349\n",
      "Epoch 26/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3336\n",
      "[Val @ epoch 26] macro=0.329162  (per-cell: 0.3269, 0.3314)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 109s 83ms/step - loss: 0.3336 - val_loss_macro: 0.3292\n",
      "Epoch 27/50\n",
      "1320/1320 [==============================] - 70s 53ms/step - loss: 0.3324\n",
      "Epoch 28/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3313\n",
      "[Val @ epoch 28] macro=0.327872  (per-cell: 0.3256, 0.3302)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 109s 83ms/step - loss: 0.3313 - val_loss_macro: 0.3279\n",
      "Epoch 29/50\n",
      "1320/1320 [==============================] - 70s 53ms/step - loss: 0.3301\n",
      "Epoch 30/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3290\n",
      "[Val @ epoch 30] macro=0.326860  (per-cell: 0.3242, 0.3295)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 109s 83ms/step - loss: 0.3290 - val_loss_macro: 0.3269\n",
      "Epoch 31/50\n",
      "1320/1320 [==============================] - 70s 53ms/step - loss: 0.3280\n",
      "Epoch 32/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3268\n",
      "[Val @ epoch 32] macro=0.326027  (per-cell: 0.3229, 0.3292)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 109s 83ms/step - loss: 0.3268 - val_loss_macro: 0.3260\n",
      "Epoch 33/50\n",
      "1320/1320 [==============================] - 70s 53ms/step - loss: 0.3258\n",
      "Epoch 34/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3251\n",
      "[Val @ epoch 34] macro=0.325231  (per-cell: 0.3216, 0.3289)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 109s 83ms/step - loss: 0.3251 - val_loss_macro: 0.3252\n",
      "Epoch 35/50\n",
      "1320/1320 [==============================] - 70s 53ms/step - loss: 0.3239\n",
      "Epoch 36/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3230\n",
      "[Val @ epoch 36] macro=0.324419  (per-cell: 0.3202, 0.3286)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 110s 83ms/step - loss: 0.3230 - val_loss_macro: 0.3244\n",
      "Epoch 37/50\n",
      "1320/1320 [==============================] - 70s 53ms/step - loss: 0.3223\n",
      "Epoch 38/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3215\n",
      "[Val @ epoch 38] macro=0.323510  (per-cell: 0.3189, 0.3281)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 109s 82ms/step - loss: 0.3215 - val_loss_macro: 0.3235\n",
      "Epoch 39/50\n",
      "1320/1320 [==============================] - 70s 53ms/step - loss: 0.3206\n",
      "Epoch 40/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3197\n",
      "[Val @ epoch 40] macro=0.322481  (per-cell: 0.3177, 0.3273)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 109s 83ms/step - loss: 0.3197 - val_loss_macro: 0.3225\n",
      "Epoch 41/50\n",
      "1320/1320 [==============================] - 70s 53ms/step - loss: 0.3190\n",
      "Epoch 42/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3183\n",
      "[Val @ epoch 42] macro=0.321443  (per-cell: 0.3165, 0.3264)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 110s 83ms/step - loss: 0.3183 - val_loss_macro: 0.3214\n",
      "Epoch 43/50\n",
      "1320/1320 [==============================] - 70s 53ms/step - loss: 0.3174\n",
      "Epoch 44/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3167\n",
      "[Val @ epoch 44] macro=0.320322  (per-cell: 0.3153, 0.3254)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 110s 83ms/step - loss: 0.3167 - val_loss_macro: 0.3203\n",
      "Epoch 45/50\n",
      "1320/1320 [==============================] - 70s 53ms/step - loss: 0.3159\n",
      "Epoch 46/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3153\n",
      "[Val @ epoch 46] macro=0.319162  (per-cell: 0.3141, 0.3243)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 109s 83ms/step - loss: 0.3153 - val_loss_macro: 0.3192\n",
      "Epoch 47/50\n",
      "1320/1320 [==============================] - 70s 53ms/step - loss: 0.3147\n",
      "Epoch 48/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3140\n",
      "[Val @ epoch 48] macro=0.318014  (per-cell: 0.3129, 0.3231)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 109s 83ms/step - loss: 0.3140 - val_loss_macro: 0.3180\n",
      "Epoch 49/50\n",
      "1320/1320 [==============================] - 70s 53ms/step - loss: 0.3132\n",
      "Epoch 50/50\n",
      "1320/1320 [==============================] - ETA: 0s - loss: 0.3125\n",
      "[Val @ epoch 50] macro=0.316780  (per-cell: 0.3117, 0.3218)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run16_best.h5\n",
      "1320/1320 [==============================] - 110s 83ms/step - loss: 0.3125 - val_loss_macro: 0.3168\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run16_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:28<00:00, 14.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_28.mat                 [PITM] MSE=3.778e-08 RSEP=17.42% MAPE=24.51%     \n",
      "  PBROM_data_cell_D5C78.mat              [PITM] MSE=7.996e-04 RSEP=37.56% MAPE=45.76%     \n",
      "[RandomSearch] Run 16 ‚Üí avg_rsep_pitm=27.4919\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 17 / 20\n",
      "  window_size   = 80\n",
      "  lambda_phys   = 0.0453\n",
      "  batch_size    = 768\n",
      "  learning_rate = 1.03e-06\n",
      "  num_layers    = 3\n",
      "  embed_dim     = 64\n",
      "==================================================\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\n",
      "--- Counting windows for balancing ---\n",
      "  Group 'PBROM_Cells_1': 150784 windows\n",
      "  Group 'D5_Cells_1': 1199921 windows\n",
      "  -> Weight for 'PBROM_Cells_1': 4.4789\n",
      "  -> Weight for 'D5_Cells_1': 0.5628\n",
      "\n",
      "--- Processing Groups ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PBROM_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.64s/it]\n",
      "  D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:18<00:00, 18.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "‚úÖ Done. 1350703 windows generated. Weights applied.\n",
      "Epoch 1/50\n",
      "1759/1759 [==============================] - 70s 29ms/step - loss: 0.3496\n",
      "Epoch 2/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3309\n",
      "[Val @ epoch 2] macro=0.317387  (per-cell: 0.3052, 0.3296)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 87s 49ms/step - loss: 0.3309 - val_loss_macro: 0.3174\n",
      "Epoch 3/50\n",
      "1759/1759 [==============================] - 52s 30ms/step - loss: 0.3269\n",
      "Epoch 4/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3229\n",
      "[Val @ epoch 4] macro=0.309161  (per-cell: 0.2980, 0.3203)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 88s 50ms/step - loss: 0.3229 - val_loss_macro: 0.3092\n",
      "Epoch 5/50\n",
      "1759/1759 [==============================] - 52s 30ms/step - loss: 0.3186\n",
      "Epoch 6/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3138\n",
      "[Val @ epoch 6] macro=0.300150  (per-cell: 0.2909, 0.3094)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 48ms/step - loss: 0.3138 - val_loss_macro: 0.3002\n",
      "Epoch 7/50\n",
      "1759/1759 [==============================] - 52s 29ms/step - loss: 0.3088\n",
      "Epoch 8/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.3044\n",
      "[Val @ epoch 8] macro=0.295282  (per-cell: 0.2845, 0.3061)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 48ms/step - loss: 0.3044 - val_loss_macro: 0.2953\n",
      "Epoch 9/50\n",
      "1759/1759 [==============================] - 52s 30ms/step - loss: 0.3006\n",
      "Epoch 10/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2974\n",
      "[Val @ epoch 10] macro=0.291589  (per-cell: 0.2785, 0.3047)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 86s 49ms/step - loss: 0.2974 - val_loss_macro: 0.2916\n",
      "Epoch 11/50\n",
      "1759/1759 [==============================] - 52s 29ms/step - loss: 0.2944\n",
      "Epoch 12/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2917\n",
      "[Val @ epoch 12] macro=0.286790  (per-cell: 0.2727, 0.3008)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 48ms/step - loss: 0.2917 - val_loss_macro: 0.2868\n",
      "Epoch 13/50\n",
      "1759/1759 [==============================] - 52s 29ms/step - loss: 0.2891\n",
      "Epoch 14/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2865\n",
      "[Val @ epoch 14] macro=0.281759  (per-cell: 0.2674, 0.2961)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 48ms/step - loss: 0.2865 - val_loss_macro: 0.2818\n",
      "Epoch 15/50\n",
      "1759/1759 [==============================] - 52s 29ms/step - loss: 0.2840\n",
      "Epoch 16/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2816\n",
      "[Val @ epoch 16] macro=0.276613  (per-cell: 0.2621, 0.2912)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 48ms/step - loss: 0.2816 - val_loss_macro: 0.2766\n",
      "Epoch 17/50\n",
      "1759/1759 [==============================] - 52s 29ms/step - loss: 0.2793\n",
      "Epoch 18/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2770\n",
      "[Val @ epoch 18] macro=0.271295  (per-cell: 0.2568, 0.2858)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 86s 49ms/step - loss: 0.2770 - val_loss_macro: 0.2713\n",
      "Epoch 19/50\n",
      "1759/1759 [==============================] - 52s 30ms/step - loss: 0.2748\n",
      "Epoch 20/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2725\n",
      "[Val @ epoch 20] macro=0.266037  (per-cell: 0.2514, 0.2806)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 48ms/step - loss: 0.2725 - val_loss_macro: 0.2660\n",
      "Epoch 21/50\n",
      "1759/1759 [==============================] - 52s 29ms/step - loss: 0.2704\n",
      "Epoch 22/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2683\n",
      "[Val @ epoch 22] macro=0.260948  (per-cell: 0.2461, 0.2758)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 48ms/step - loss: 0.2683 - val_loss_macro: 0.2609\n",
      "Epoch 23/50\n",
      "1759/1759 [==============================] - 52s 30ms/step - loss: 0.2662\n",
      "Epoch 24/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2642\n",
      "[Val @ epoch 24] macro=0.256027  (per-cell: 0.2409, 0.2712)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 49ms/step - loss: 0.2642 - val_loss_macro: 0.2560\n",
      "Epoch 25/50\n",
      "1759/1759 [==============================] - 52s 30ms/step - loss: 0.2622\n",
      "Epoch 26/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2603\n",
      "[Val @ epoch 26] macro=0.251404  (per-cell: 0.2361, 0.2667)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 48ms/step - loss: 0.2603 - val_loss_macro: 0.2514\n",
      "Epoch 27/50\n",
      "1759/1759 [==============================] - 52s 30ms/step - loss: 0.2584\n",
      "Epoch 28/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2564\n",
      "[Val @ epoch 28] macro=0.247477  (per-cell: 0.2321, 0.2629)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 49ms/step - loss: 0.2564 - val_loss_macro: 0.2475\n",
      "Epoch 29/50\n",
      "1759/1759 [==============================] - 52s 29ms/step - loss: 0.2544\n",
      "Epoch 30/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2522\n",
      "[Val @ epoch 30] macro=0.244347  (per-cell: 0.2286, 0.2601)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 48ms/step - loss: 0.2522 - val_loss_macro: 0.2443\n",
      "Epoch 31/50\n",
      "1759/1759 [==============================] - 52s 30ms/step - loss: 0.2501\n",
      "Epoch 32/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2480\n",
      "[Val @ epoch 32] macro=0.241332  (per-cell: 0.2256, 0.2571)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 48ms/step - loss: 0.2480 - val_loss_macro: 0.2413\n",
      "Epoch 33/50\n",
      "1759/1759 [==============================] - 52s 30ms/step - loss: 0.2460\n",
      "Epoch 34/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2441\n",
      "[Val @ epoch 34] macro=0.238256  (per-cell: 0.2228, 0.2537)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 48ms/step - loss: 0.2441 - val_loss_macro: 0.2383\n",
      "Epoch 35/50\n",
      "1759/1759 [==============================] - 52s 30ms/step - loss: 0.2422\n",
      "Epoch 36/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2402\n",
      "[Val @ epoch 36] macro=0.235426  (per-cell: 0.2203, 0.2506)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 86s 49ms/step - loss: 0.2402 - val_loss_macro: 0.2354\n",
      "Epoch 37/50\n",
      "1759/1759 [==============================] - 52s 30ms/step - loss: 0.2386\n",
      "Epoch 38/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2368\n",
      "[Val @ epoch 38] macro=0.232392  (per-cell: 0.2175, 0.2473)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 49ms/step - loss: 0.2368 - val_loss_macro: 0.2324\n",
      "Epoch 39/50\n",
      "1759/1759 [==============================] - 52s 30ms/step - loss: 0.2352\n",
      "Epoch 40/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2335\n",
      "[Val @ epoch 40] macro=0.229352  (per-cell: 0.2149, 0.2438)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 48ms/step - loss: 0.2335 - val_loss_macro: 0.2294\n",
      "Epoch 41/50\n",
      "1759/1759 [==============================] - 52s 30ms/step - loss: 0.2320\n",
      "Epoch 42/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2305\n",
      "[Val @ epoch 42] macro=0.226205  (per-cell: 0.2123, 0.2401)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 49ms/step - loss: 0.2305 - val_loss_macro: 0.2262\n",
      "Epoch 43/50\n",
      "1759/1759 [==============================] - 51s 29ms/step - loss: 0.2290\n",
      "Epoch 44/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2275\n",
      "[Val @ epoch 44] macro=0.223045  (per-cell: 0.2097, 0.2364)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 48ms/step - loss: 0.2275 - val_loss_macro: 0.2230\n",
      "Epoch 45/50\n",
      "1759/1759 [==============================] - 52s 29ms/step - loss: 0.2262\n",
      "Epoch 46/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2248\n",
      "[Val @ epoch 46] macro=0.220176  (per-cell: 0.2073, 0.2331)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 48ms/step - loss: 0.2248 - val_loss_macro: 0.2202\n",
      "Epoch 47/50\n",
      "1759/1759 [==============================] - 52s 29ms/step - loss: 0.2234\n",
      "Epoch 48/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2222\n",
      "[Val @ epoch 48] macro=0.217419  (per-cell: 0.2048, 0.2300)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 48ms/step - loss: 0.2222 - val_loss_macro: 0.2174\n",
      "Epoch 49/50\n",
      "1759/1759 [==============================] - 52s 29ms/step - loss: 0.2208\n",
      "Epoch 50/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.2195\n",
      "[Val @ epoch 50] macro=0.214740  (per-cell: 0.2025, 0.2270)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run17_best.h5\n",
      "1759/1759 [==============================] - 85s 48ms/step - loss: 0.2195 - val_loss_macro: 0.2147\n",
      "Loading BEST checkpoint for evaluation: checkpoints/rs2_run17_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:24<00:00, 12.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_28.mat                 [PITM] MSE=6.296e-08 RSEP=22.49% MAPE=32.28%     \n",
      "  PBROM_data_cell_D5C78.mat              [PITM] MSE=3.660e-04 RSEP=25.42% MAPE=31.13%     \n",
      "[RandomSearch] Run 17 ‚Üí avg_rsep_pitm=23.9512\n",
      "\n",
      "==================================================\n",
      "RANDOM SEARCH RUN 18 / 20\n",
      "  window_size   = 50\n",
      "  lambda_phys   = 0.0250\n",
      "  batch_size    = 768\n",
      "  learning_rate = 6.19e-05\n",
      "  num_layers    = 5\n",
      "  embed_dim     = 128\n",
      "==================================================\n",
      "\n",
      "--- ‚öôÔ∏è Pass 1.5: Building training arrays (Weighted + Per-Group) ---\n",
      "--- Counting windows for balancing ---\n",
      "  Group 'PBROM_Cells_1': 150814 windows\n",
      "  Group 'D5_Cells_1': 1199951 windows\n",
      "  -> Weight for 'PBROM_Cells_1': 4.4782\n",
      "  -> Weight for 'D5_Cells_1': 0.5628\n",
      "\n",
      "--- Processing Groups ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PBROM_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.58s/it]\n",
      "  D5_Cells_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:18<00:00, 18.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "‚úÖ Done. 1350763 windows generated. Weights applied.\n",
      "Epoch 1/50\n",
      "1759/1759 [==============================] - 102s 41ms/step - loss: 0.3415\n",
      "Epoch 2/50\n",
      "1759/1759 [==============================] - ETA: 0s - loss: 0.1309\n",
      "[Val @ epoch 2] macro=0.108500  (per-cell: 0.0986, 0.1184)\n",
      "  ‚úì Saved BEST checkpoint -> checkpoints/rs2_run18_best.h5\n",
      "1759/1759 [==============================] - 115s 65ms/step - loss: 0.1309 - val_loss_macro: 0.1085\n",
      "Epoch 3/50\n",
      "1759/1759 [==============================] - 74s 42ms/step - loss: 0.0704\n",
      "Epoch 4/50\n",
      " 239/1759 [===>..........................] - ETA: 1:03 - loss: 0.0548"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# Cell 10b ‚Äî Random Search Execution (using train_one_model)\n",
    "# ===============================================\n",
    "import numpy as np, tensorflow as tf, os, csv, random\n",
    "\n",
    "# Helper to write CSV\n",
    "def _write_csv_row(path, header, row_dict):\n",
    "    write_header = not os.path.exists(path)\n",
    "    with open(path, \"a\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=header)\n",
    "        if write_header:\n",
    "            w.writeheader()\n",
    "        w.writerow(row_dict)\n",
    "\n",
    "# Reset any leftover graphs\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Results CSV\n",
    "ABLATION_CSV_PATH = os.path.join(\"ablation\", \"random_search_stage2_results.csv\")\n",
    "if os.path.exists(ABLATION_CSV_PATH):\n",
    "    os.remove(ABLATION_CSV_PATH)\n",
    "\n",
    "CSV_HEADER = [\n",
    "    \"run_num\",\n",
    "    \"window_size\",\n",
    "    \"lambda_phys\",\n",
    "    \"batch_size\",\n",
    "    \"learning_rate\",\n",
    "    \"num_layers\",\n",
    "    \"embed_dim\",\n",
    "    \"avg_rsep_pitm\"\n",
    "]\n",
    "\n",
    "for run_num in range(N_RANDOM_RUNS):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # üîë Make Python & NumPy RNG state different per run\n",
    "    random.seed(SEED + run_num)\n",
    "    np.random.seed(SEED + run_num)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Sample hyperparameters with a constraint:\n",
    "    #   Do NOT allow any combination where 2 or 3 of\n",
    "    #   {window_size=400, batch_size=1024, num_layers=5}\n",
    "    #   are selected simultaneously.\n",
    "    #   (At most ONE of these can be active.)\n",
    "    # --------------------------------------------------\n",
    "    while True:\n",
    "        # Discrete hyperparameters\n",
    "        run_ws = random.choice(RANDOM_SEARCH_SPACE_STAGE2[\"window_size\"])\n",
    "        run_bs = random.choice(RANDOM_SEARCH_SPACE_STAGE2[\"batch_size\"])\n",
    "        run_layers = random.choice(RANDOM_SEARCH_SPACE_STAGE2[\"num_layers\"])\n",
    "        run_embed  = random.choice(RANDOM_SEARCH_SPACE_STAGE2[\"embed_dim\"])\n",
    "\n",
    "        # Continuous hyperparameters\n",
    "        run_lp_min, run_lp_max = RANDOM_SEARCH_SPACE_STAGE2[\"lambda_phys\"]\n",
    "        run_lp = random.uniform(run_lp_min, run_lp_max)\n",
    "\n",
    "        lr_min, lr_max = RANDOM_SEARCH_SPACE_STAGE2[\"learning_rate\"]\n",
    "        run_lr = 10 ** random.uniform(np.log10(lr_min), np.log10(lr_max))\n",
    "\n",
    "        # Count how many of the \"heavy\" settings are active\n",
    "        heavy_flags = int(run_ws == 400) + int(run_bs == 2048) + int(run_layers == 15)\n",
    "\n",
    "        # Accept only if at most ONE of them is active\n",
    "        if heavy_flags <= 1:\n",
    "            break\n",
    "        # otherwise, resample\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"RANDOM SEARCH RUN {run_num+1} / {N_RANDOM_RUNS}\")\n",
    "    print(f\"  window_size   = {run_ws}\")\n",
    "    print(f\"  lambda_phys   = {run_lp:.4f}\")\n",
    "    print(f\"  batch_size    = {run_bs}\")\n",
    "    print(f\"  learning_rate = {run_lr:.2e}\")\n",
    "    print(f\"  num_layers    = {run_layers}\")\n",
    "    print(f\"  embed_dim     = {run_embed}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Unique run name for this random-search trial\n",
    "    run_name = f\"rs2_run{run_num+1}\"\n",
    "\n",
    "    # --- Train model using EXACT same pipeline as main training ---\n",
    "    model, history = train_one_model(\n",
    "        run_name=run_name,\n",
    "        window_size=run_ws,\n",
    "        embed_dim=run_embed,\n",
    "        num_layers=run_layers,\n",
    "        batch_per_device=run_bs,\n",
    "        learning_rate=run_lr,\n",
    "        lambda_phys=run_lp,\n",
    "        do_plot=False  # no live plots during random search\n",
    "    )\n",
    "\n",
    "    # BEST_CKPT was set inside train_one_model for this run_name\n",
    "    # We now load that checkpoint before evaluating\n",
    "    if os.path.exists(BEST_CKPT):\n",
    "        print(f\"Loading BEST checkpoint for evaluation: {BEST_CKPT}\")\n",
    "        model.load_weights(BEST_CKPT)\n",
    "    else:\n",
    "        print(f\"WARNING: BEST_CKPT not found at {BEST_CKPT}. Using final weights.\")\n",
    "\n",
    "    # --- Evaluate on TEST set using the shared testing pipeline ---\n",
    "    test_results = evaluate_model_on_test(\n",
    "        model,\n",
    "        window_size=run_ws,\n",
    "        stride=STRIDE,\n",
    "        plot_suffix=run_name,\n",
    "        do_plot=False\n",
    "    )\n",
    "\n",
    "    rsep_values = [res[3] for res in test_results if np.isfinite(res[3])]\n",
    "    avg_rsep_pitm = np.mean(rsep_values) if rsep_values else np.nan\n",
    "    print(f\"[RandomSearch] Run {run_num+1} ‚Üí avg_rsep_pitm={avg_rsep_pitm:.4f}\")\n",
    "\n",
    "    row_dict = {\n",
    "        \"run_num\": run_num+1,\n",
    "        \"window_size\": run_ws,\n",
    "        \"lambda_phys\": run_lp,\n",
    "        \"batch_size\": run_bs,\n",
    "        \"learning_rate\": run_lr,\n",
    "        \"num_layers\": run_layers,\n",
    "        \"embed_dim\": run_embed,\n",
    "        \"avg_rsep_pitm\": avg_rsep_pitm\n",
    "    }\n",
    "    _write_csv_row(ABLATION_CSV_PATH, CSV_HEADER, row_dict)\n",
    "\n",
    "print(\"\\n‚úÖ Stage 2 Random Search complete.\")\n",
    "print(f\"Results saved to {ABLATION_CSV_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c342f6e2-be75-4a2a-a72a-d7871a4a4262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Top 10 Best Models from Random Search (Lower RSEP is Better)\n",
      "   (Reading from: ablation/random_search_stage2_results.csv)\n",
      "    run_num  window_size  lambda_phys  batch_size  learning_rate  num_layers  embed_dim  avg_rsep_pitm\n",
      "14       15           60     0.844426         768   2.667528e-04           4         96       7.014223\n",
      "13       14          100     0.925367         768   2.213211e-05           3         96       8.632719\n",
      "6         7           80     0.872478        1024   1.829556e-06           3         96       8.987160\n",
      "8         9           30     0.761797        1024   2.713411e-05           4         64      10.359409\n",
      "12       13           50     0.531325        1024   1.965493e-04           5         96      10.396296\n",
      "17       18           50     0.025034         768   6.190844e-05           5        128      10.594311\n",
      "11       12           80     1.030679         768   2.140965e-06           4        128      12.017873\n",
      "18       19           10     0.292180        1024   4.140460e-05           5         64      13.272258\n",
      "10       11           10     0.940638         768   4.582592e-07           5        128      18.231128\n",
      "1         2          100     1.055347        1024   4.528819e-07           5         64      21.313627\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# Cell 10c ‚Äî Random Search Analysis\n",
    "# ======================================\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- ‚≠êÔ∏è FIX: Point to the correct \"Stage 2\" CSV file ---\n",
    "RESULTS_CSV = os.path.join(\"ablation\", \"random_search_stage2_results.csv\")\n",
    "if not os.path.exists(RESULTS_CSV):\n",
    "    print(f\"Error: Results file not found. Run Cell 10b first.\")\n",
    "    # You can't proceed if the file doesn't exist\n",
    "else:\n",
    "    pd.set_option('display.width', 1000)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "\n",
    "    df_results = pd.read_csv(RESULTS_CSV)\n",
    "    \n",
    "    # --- Sort by the metric (RSEP) to find the best runs ---\n",
    "    # ascending=True is correct because lower RSEP is better\n",
    "    df_sorted = df_results.sort_values(by=\"avg_rsep_pitm\", ascending=True)\n",
    "\n",
    "    print(f\"üèÜ Top 10 Best Models from Random Search (Lower RSEP is Better)\")\n",
    "    print(f\"   (Reading from: {RESULTS_CSV})\")\n",
    "    print(df_sorted.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "973bf8a5-f9ae-4ee5-972e-ee28e1c97c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ  Best model found from Random Search (Stage 2)\n",
      "run_num           15.000000\n",
      "window_size       60.000000\n",
      "lambda_phys        0.844426\n",
      "batch_size       768.000000\n",
      "learning_rate      0.000267\n",
      "num_layers         4.000000\n",
      "embed_dim         96.000000\n",
      "avg_rsep_pitm      7.014223\n",
      "Name: 14, dtype: float64\n",
      "\n",
      "Rebuilding best model from random search:\n",
      "  Run number:   15\n",
      "  Window Size:  60\n",
      "  Num Layers:   4\n",
      "  Embed Dim:    96\n",
      "  lambda_phys:  0.8444\n",
      "\n",
      "‚úÖ Successfully loaded weights from: checkpoints/rs2_run15_best.h5\n",
      "\n",
      "Running final evaluation on all TEST cells...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells:   0%|                                        | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 680x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 1/2 [00:04<00:04,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved -> plots/PBROM_data_cell_28_pred_pct_BEST_RANDOM_SEARCH_MODEL.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 680x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test cells: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:24<00:00, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved -> plots/PBROM_data_cell_D5C78_pred_pct_BEST_RANDOM_SEARCH_MODEL.png\n",
      "\n",
      "üìä PITM Testing Results (per cell)\n",
      "  PBROM_data_cell_28.mat                 [PITM] MSE=6.975e-09 RSEP=7.48% MAPE=14.65%     \n",
      "  PBROM_data_cell_D5C78.mat              [PITM] MSE=2.427e-05 RSEP=6.54% MAPE=7.32%     \n",
      "\n",
      "==================================================\n",
      "Per-Cell Evaluation Complete.\n",
      "Average RSEP: 7.0142%\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Cell 11 ‚Äî Load Best Model from Random Search & Evaluate\n",
    "# ==========================================================\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RESULTS_CSV = os.path.join(\"ablation\", \"random_search_stage2_results.csv\")\n",
    "if not os.path.exists(RESULTS_CSV):\n",
    "    raise FileNotFoundError(f\"Random search results not found at: {RESULTS_CSV}\")\n",
    "\n",
    "df_results = pd.read_csv(RESULTS_CSV)\n",
    "\n",
    "# Sort by avg_rsep_pitm ascending (lower is better)\n",
    "df_sorted = df_results.sort_values(by=\"avg_rsep_pitm\", ascending=True)\n",
    "best_row = df_sorted.iloc[0]\n",
    "\n",
    "print(\"üèÜ  Best model found from Random Search (Stage 2)\")\n",
    "print(best_row)\n",
    "\n",
    "BEST_RUN_NUM   = int(best_row[\"run_num\"])\n",
    "BEST_WS        = int(best_row[\"window_size\"])\n",
    "BEST_LAYERS    = int(best_row[\"num_layers\"])\n",
    "BEST_EMBED     = int(best_row[\"embed_dim\"])\n",
    "BEST_LAMBDA_PHYS = float(best_row[\"lambda_phys\"])\n",
    "\n",
    "# Rebuild the model architecture with these hyperparameters\n",
    "print(f\"\\nRebuilding best model from random search:\")\n",
    "print(f\"  Run number:   {BEST_RUN_NUM}\")\n",
    "print(f\"  Window Size:  {BEST_WS}\")\n",
    "print(f\"  Num Layers:   {BEST_LAYERS}\")\n",
    "print(f\"  Embed Dim:    {BEST_EMBED}\")\n",
    "print(f\"  lambda_phys:  {BEST_LAMBDA_PHYS:.4f}\")\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_pitm_model(\n",
    "    window_size=BEST_WS,\n",
    "    num_groups=NUM_GROUPS,\n",
    "    embed_dim=BEST_EMBED,\n",
    "    num_heads=NUM_HEADS,\n",
    "    ff_dim=FF_DIM,\n",
    "    num_layers=BEST_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "# Load the best checkpoint from that run\n",
    "run_name = f\"rs2_run{BEST_RUN_NUM}\"\n",
    "CHECKPOINT_NAME = f\"{run_name}_best.h5\"\n",
    "MODEL_TO_TEST = os.path.join(\"checkpoints\", CHECKPOINT_NAME)\n",
    "\n",
    "if not os.path.exists(MODEL_TO_TEST):\n",
    "    raise FileNotFoundError(f\"Checkpoint not found: {MODEL_TO_TEST}\")\n",
    "else:\n",
    "    model.load_weights(MODEL_TO_TEST)\n",
    "    print(f\"\\n‚úÖ Successfully loaded weights from: {MODEL_TO_TEST}\")\n",
    "\n",
    "# Run full evaluation on TEST cells with plots\n",
    "print(\"\\nRunning final evaluation on all TEST cells...\")\n",
    "results = evaluate_model_on_test(\n",
    "    model,\n",
    "    window_size=BEST_WS,\n",
    "    stride=STRIDE,\n",
    "    plot_suffix=\"BEST_RANDOM_SEARCH_MODEL\",\n",
    "    do_plot=True\n",
    ")\n",
    "\n",
    "rsep_values = [res[3] for res in results if np.isfinite(res[3])]\n",
    "final_avg_rsep = np.mean(rsep_values) if rsep_values else np.nan\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Per-Cell Evaluation Complete.\")\n",
    "print(f\"Average RSEP: {final_avg_rsep:.4f}%\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "96c2bdf2-fea0-4470-9a67-457e3e759d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting curves for PBROM_data_cell_28 (group: PBROM_Cells_1) ...\n",
      "  ‚úì Saved ‚Üí saved_curves/PBROM_Cells_1_PBROM_data_cell_28_BEST_MODEL_CURVES.npz\n",
      "\n",
      "Extracting curves for PBROM_data_cell_D5C78 (group: D5_Cells_1) ...\n",
      "  ‚úì Saved ‚Üí saved_curves/D5_Cells_1_PBROM_data_cell_D5C78_BEST_MODEL_CURVES.npz\n",
      "\n",
      "‚úÖ Cell 12 complete: multi-group curves exported in consistent format.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Cell 12 ‚Äî Save per-cell curves for external plotting (corrected)\n",
    "# ==========================================================\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "SAVE_DIR = \"saved_curves\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "for fn in TEST_FILES:\n",
    "    base = os.path.splitext(os.path.basename(fn))[0]\n",
    "    group_label = FILE_TO_GROUP_MAP.get(fn, \"UnknownGroup\")\n",
    "    print(f\"\\nExtracting curves for {base} (group: {group_label}) ...\")\n",
    "\n",
    "    out = predict_cell(\n",
    "        model,\n",
    "        file_name=fn,\n",
    "        window_size=BEST_WS,\n",
    "        stride=STRIDE,\n",
    "    )\n",
    "\n",
    "    if out is None or len(out) < 7:\n",
    "        print(f\"  ‚ö† Skipping {base}: invalid predict_cell output\")\n",
    "        continue\n",
    "\n",
    "    t_dense, q_exp_norm_d, q_pb_norm_d, q_hat_norm_d, cap_nom, Time_s_full, t_exp = out\n",
    "\n",
    "    if t_dense.size == 0:\n",
    "        print(f\"  ‚ö† Skipping {base}: no windows produced.\")\n",
    "        continue\n",
    "\n",
    "    # ---- ALIGN EXPERIMENTAL (sparse) TO MODEL (dense) ----\n",
    "    # Restrict experimental timestamps to dense coverage\n",
    "    t_exp_use = t_exp[(t_exp >= t_dense[0]) & (t_exp <= t_dense[-1])]\n",
    "    if t_exp_use.size == 0:\n",
    "        print(f\"  ‚ö† No experimental times within model window for {fn}.\")\n",
    "        continue\n",
    "\n",
    "    # Nearest indices\n",
    "    idx = nearest_indices(t_dense, t_exp_use)\n",
    "    if idx.size == 0:\n",
    "        print(f\"  ‚ö† nearest_indices returned empty for {fn}.\")\n",
    "        continue\n",
    "\n",
    "    # Sparse experimental curves (correct!)\n",
    "    q_exp_norm_sparse = q_exp_norm_d[idx]\n",
    "\n",
    "    # Dense curves\n",
    "    t_dense_hours = t_dense / 3600.0\n",
    "    q_pb_pct_dense  = 100.0 * q_pb_norm_d\n",
    "    q_hat_pct_dense = 100.0 * q_hat_norm_d\n",
    "\n",
    "    # Sparse curves\n",
    "    t_exp_hours = t_exp_use / 3600.0\n",
    "    q_exp_pct_sparse = 100.0 * q_exp_norm_sparse\n",
    "\n",
    "    # ---- SAVE CONSISTENT FORMAT (same as single-group saving) ----\n",
    "    out_name = f\"{group_label}_{base}_BEST_MODEL_CURVES.npz\"\n",
    "    out_path = os.path.join(SAVE_DIR, out_name)\n",
    "\n",
    "    np.savez_compressed(\n",
    "        out_path,\n",
    "        # sparse\n",
    "        t_exp=t_exp_hours,\n",
    "        q_exp_pct=q_exp_pct_sparse,\n",
    "\n",
    "        # dense\n",
    "        t_dense=t_dense_hours,\n",
    "        q_pb_pct=q_pb_pct_dense,\n",
    "        q_hat_pct=q_hat_pct_dense,\n",
    "\n",
    "        # metadata\n",
    "        group_label=group_label,\n",
    "        file_name=fn,\n",
    "        cap_nom=cap_nom,\n",
    "        window_size=BEST_WS,\n",
    "        stride=STRIDE,\n",
    "    )\n",
    "\n",
    "    print(f\"  ‚úì Saved ‚Üí {out_path}\")\n",
    "\n",
    "print(\"\\n‚úÖ Cell 12 complete: multi-group curves exported in consistent format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7ecd1b-eec7-4d85-9407-1b52293d2c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfce744-64f3-4ad8-8cd6-bce5d0df1da7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env_2)",
   "language": "python",
   "name": "ml_env_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
